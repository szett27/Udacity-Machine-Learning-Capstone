{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Starbucks Capstone Challenge\n",
    "\n",
    "### Introduction\n",
    "\n",
    "This data set contains simulated data that mimics customer behavior on the Starbucks rewards mobile app. Once every few days, Starbucks sends out an offer to users of the mobile app. An offer can be merely an advertisement for a drink or an actual offer such as a discount or BOGO (buy one get one free). Some users might not receive any offer during certain weeks. \n",
    "\n",
    "Not all users receive the same offer, and that is the challenge to solve with this data set.\n",
    "\n",
    "Your task is to combine transaction, demographic and offer data to determine which demographic groups respond best to which offer type. This data set is a simplified version of the real Starbucks app because the underlying simulator only has one product whereas Starbucks actually sells dozens of products.\n",
    "\n",
    "Every offer has a validity period before the offer expires. As an example, a BOGO offer might be valid for only 5 days. You'll see in the data set that informational offers have a validity period even though these ads are merely providing information about a product; for example, if an informational offer has 7 days of validity, you can assume the customer is feeling the influence of the offer for 7 days after receiving the advertisement.\n",
    "\n",
    "You'll be given transactional data showing user purchases made on the app including the timestamp of purchase and the amount of money spent on a purchase. This transactional data also has a record for each offer that a user receives as well as a record for when a user actually views the offer. There are also records for when a user completes an offer. \n",
    "\n",
    "Keep in mind as well that someone using the app might make a purchase through the app without having received an offer or seen an offer.\n",
    "\n",
    "### Example\n",
    "\n",
    "To give an example, a user could receive a discount offer buy 10 dollars get 2 off on Monday. The offer is valid for 10 days from receipt. If the customer accumulates at least 10 dollars in purchases during the validity period, the customer completes the offer.\n",
    "\n",
    "However, there are a few things to watch out for in this data set. Customers do not opt into the offers that they receive; in other words, a user can receive an offer, never actually view the offer, and still complete the offer. For example, a user might receive the \"buy 10 dollars get 2 dollars off offer\", but the user never opens the offer during the 10 day validity period. The customer spends 15 dollars during those ten days. There will be an offer completion record in the data set; however, the customer was not influenced by the offer because the customer never viewed the offer.\n",
    "\n",
    "### Cleaning\n",
    "\n",
    "This makes data cleaning especially important and tricky.\n",
    "\n",
    "You'll also want to take into account that some demographic groups will make purchases even if they don't receive an offer. From a business perspective, if a customer is going to make a 10 dollar purchase without an offer anyway, you wouldn't want to send a buy 10 dollars get 2 dollars off offer. You'll want to try to assess what a certain demographic group will buy when not receiving any offers.\n",
    "\n",
    "### Final Advice\n",
    "\n",
    "Because this is a capstone project, you are free to analyze the data any way you see fit. For example, you could build a machine learning model that predicts how much someone will spend based on demographics and offer type. Or you could build a model that predicts whether or not someone will respond to an offer. Or, you don't need to build a machine learning model at all. You could develop a set of heuristics that determine what offer you should send to each customer (i.e., 75 percent of women customers who were 35 years old responded to offer A vs 40 percent from the same demographic to offer B, so send offer A)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Sets\n",
    "\n",
    "The data is contained in three files:\n",
    "\n",
    "* portfolio.json - containing offer ids and meta data about each offer (duration, type, etc.)\n",
    "* profile.json - demographic data for each customer\n",
    "* transcript.json - records for transactions, offers received, offers viewed, and offers completed\n",
    "\n",
    "Here is the schema and explanation of each variable in the files:\n",
    "\n",
    "**portfolio.json**\n",
    "* id (string) - offer id\n",
    "* offer_type (string) - type of offer ie BOGO, discount, informational\n",
    "* difficulty (int) - minimum required spend to complete an offer\n",
    "* reward (int) - reward given for completing an offer\n",
    "* duration (int) - time for offer to be open, in days\n",
    "* channels (list of strings)\n",
    "\n",
    "**profile.json**\n",
    "* age (int) - age of the customer \n",
    "* became_member_on (int) - date when customer created an app account\n",
    "* gender (str) - gender of the customer (note some entries contain 'O' for other rather than M or F)\n",
    "* id (str) - customer id\n",
    "* income (float) - customer's income\n",
    "\n",
    "**transcript.json**\n",
    "* event (str) - record description (ie transaction, offer received, offer viewed, etc.)\n",
    "* person (str) - customer id\n",
    "* time (int) - time in hours since start of test. The data begins at time t=0\n",
    "* value - (dict of strings) - either an offer id or transaction amount depending on the record\n",
    "\n",
    "**Note:** If you are using the workspace, you will need to go to the terminal and run the command `conda update pandas` before reading in the files. This is because the version of pandas in the workspace cannot read in the transcript.json file correctly, but the newest version of pandas can. You can access the termnal from the orange icon in the top left of this notebook.  \n",
    "\n",
    "You can see how to access the terminal and how the install works using the two images below.  First you need to access the terminal:\n",
    "\n",
    "<img src=\"pic1.png\"/>\n",
    "\n",
    "Then you will want to run the above command:\n",
    "\n",
    "<img src=\"pic2.png\"/>\n",
    "\n",
    "Finally, when you enter back into the notebook (use the jupyter icon again), you should be able to run the below cell without any errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This notebook will use the linearlearner alogorithim to create a benchmark model for the udacity capstone project. This \n",
    "#notebook will take a subset of the provided data and classify those that triggered the reward as those that did not. A \n",
    "#triggered reward is defined as a reward value of >0 from the value dictionary. The features that will be used for this \n",
    "#classification are age, income, and gender.\n",
    "\n",
    "\n",
    "#benchmark process is modified form the Fraud Detection Case Study\n",
    "\n",
    "#import key resources\n",
    "import io\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "#First the notebook will read in the three json files\n",
    "\n",
    "# read in the json files\n",
    "portfolio = pd.read_json('data/portfolio.json', orient='records', lines=True)\n",
    "profile = pd.read_json('data/profile.json', orient='records', lines=True)\n",
    "transcript = pd.read_json('data/transcript.json', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "#id is used in two of the file and the id in the profile dataframe will be renamed as 'customer_id'\n",
    "#reward is used is unpacked as part of the value dictionary and is \n",
    "profile.rename(columns={'id': 'customer_id'}, inplace=True)\n",
    "portfolio.rename(columns={'reward': 'reward type'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#become_member_on may be useful in terms of time a member had the app, however the data set is a few years old and the data\n",
    "#compared to today is most likely not useful. A more useful metric might be a count of how the user users the app, with data\n",
    "#such as how oftern the app is opened, location data -ie how often was a member close to a Starbucks, and how often\n",
    "#the member added money to the app, or actually did an action within the app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a complete dataframe merging the three files is constructed\n",
    "complete_df = pd.concat([portfolio, profile, transcript], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dummy variables are need for only gender in this classification model and it is then concated to the original dataframe\n",
    "gender_dummy = pd.get_dummies(complete_df['gender'])\n",
    "event_dummy = pd.get_dummies(complete_df['event'])\n",
    "offer_dummy = pd.get_dummies(complete_df['offer_type'])\n",
    "complete_df = pd.concat([complete_df, gender_dummy, event_dummy, offer_dummy], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we need to unpack the value dictionary into its different columns and the concat that into the original dataframe and drop the\n",
    "#value column\n",
    "from pandas.io.json import json_normalize\n",
    "value_df = json_normalize(complete_df['value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#break out channels used for offers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>channels</th>\n",
       "      <th>difficulty</th>\n",
       "      <th>duration</th>\n",
       "      <th>id</th>\n",
       "      <th>offer_type</th>\n",
       "      <th>reward type</th>\n",
       "      <th>age</th>\n",
       "      <th>became_member_on</th>\n",
       "      <th>gender</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>...</th>\n",
       "      <th>F</th>\n",
       "      <th>M</th>\n",
       "      <th>O</th>\n",
       "      <th>offer completed</th>\n",
       "      <th>offer received</th>\n",
       "      <th>offer viewed</th>\n",
       "      <th>transaction</th>\n",
       "      <th>bogo</th>\n",
       "      <th>discount</th>\n",
       "      <th>informational</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[email, mobile, social]</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>ae264e3637204a6fb9bb56bc8210ddfd</td>\n",
       "      <td>bogo</td>\n",
       "      <td>10.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>20170212.0</td>\n",
       "      <td>None</td>\n",
       "      <td>68be06ca386d4c31939f3a4f0e3dd783</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[web, email, mobile, social]</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4d5c57ea9a6940dd891ad53e9dbe8da0</td>\n",
       "      <td>bogo</td>\n",
       "      <td>10.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>20170715.0</td>\n",
       "      <td>F</td>\n",
       "      <td>0610b486422d4921ae7d2bf64640c50b</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[web, email, mobile]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3f207df678b143eea3cee63160fa8bed</td>\n",
       "      <td>informational</td>\n",
       "      <td>0.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>20180712.0</td>\n",
       "      <td>None</td>\n",
       "      <td>38fe809add3b4fcf9315a9694bb96ff5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[web, email, mobile]</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9b98b8c7a33c4b65b9aebfe6a799e6d9</td>\n",
       "      <td>bogo</td>\n",
       "      <td>5.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>20170509.0</td>\n",
       "      <td>F</td>\n",
       "      <td>78afa995795e4d85b5d9ceeca43f5fef</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[web, email]</td>\n",
       "      <td>20.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0b1e1539f2cc45b7b9fa7c272da2e1d7</td>\n",
       "      <td>discount</td>\n",
       "      <td>5.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>20170804.0</td>\n",
       "      <td>None</td>\n",
       "      <td>a03223e636434f42ac4c3df47e8bac43</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       channels  difficulty  duration  \\\n",
       "0       [email, mobile, social]        10.0       7.0   \n",
       "1  [web, email, mobile, social]        10.0       5.0   \n",
       "2          [web, email, mobile]         0.0       4.0   \n",
       "3          [web, email, mobile]         5.0       7.0   \n",
       "4                  [web, email]        20.0      10.0   \n",
       "\n",
       "                                 id     offer_type  reward type    age  \\\n",
       "0  ae264e3637204a6fb9bb56bc8210ddfd           bogo         10.0  118.0   \n",
       "1  4d5c57ea9a6940dd891ad53e9dbe8da0           bogo         10.0   55.0   \n",
       "2  3f207df678b143eea3cee63160fa8bed  informational          0.0  118.0   \n",
       "3  9b98b8c7a33c4b65b9aebfe6a799e6d9           bogo          5.0   75.0   \n",
       "4  0b1e1539f2cc45b7b9fa7c272da2e1d7       discount          5.0  118.0   \n",
       "\n",
       "   became_member_on gender                       customer_id  ...  F  M  O  \\\n",
       "0        20170212.0   None  68be06ca386d4c31939f3a4f0e3dd783  ...  0  0  0   \n",
       "1        20170715.0      F  0610b486422d4921ae7d2bf64640c50b  ...  1  0  0   \n",
       "2        20180712.0   None  38fe809add3b4fcf9315a9694bb96ff5  ...  0  0  0   \n",
       "3        20170509.0      F  78afa995795e4d85b5d9ceeca43f5fef  ...  1  0  0   \n",
       "4        20170804.0   None  a03223e636434f42ac4c3df47e8bac43  ...  0  0  0   \n",
       "\n",
       "   offer completed offer received  offer viewed  transaction  bogo  discount  \\\n",
       "0                0              1             0            0     1         0   \n",
       "1                0              1             0            0     1         0   \n",
       "2                0              1             0            0     0         0   \n",
       "3                0              1             0            0     1         0   \n",
       "4                0              1             0            0     0         1   \n",
       "\n",
       "   informational  \n",
       "0              0  \n",
       "1              0  \n",
       "2              1  \n",
       "3              0  \n",
       "4              0  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complete_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "#concat new dataframes into original\n",
    "complete_df = pd.concat([complete_df, value_df], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "#uneeded features are dropped \n",
    "complete_df = complete_df.drop(['person', 'id', 'gender', 'became_member_on', 'offer_type', 'event', 'customer_id', \n",
    "                               'channels', 'value'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>difficulty</th>\n",
       "      <th>duration</th>\n",
       "      <th>reward type</th>\n",
       "      <th>age</th>\n",
       "      <th>income</th>\n",
       "      <th>time</th>\n",
       "      <th>F</th>\n",
       "      <th>M</th>\n",
       "      <th>O</th>\n",
       "      <th>offer completed</th>\n",
       "      <th>offer received</th>\n",
       "      <th>offer viewed</th>\n",
       "      <th>transaction</th>\n",
       "      <th>bogo</th>\n",
       "      <th>discount</th>\n",
       "      <th>informational</th>\n",
       "      <th>amount</th>\n",
       "      <th>offer id</th>\n",
       "      <th>offer_id</th>\n",
       "      <th>reward</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9b98b8c7a33c4b65b9aebfe6a799e6d9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>112000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0b1e1539f2cc45b7b9fa7c272da2e1d7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2906b810c7d4411798c6938adc9daaa5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fafdcd668e3743c1bb461111dcafc2a4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4d5c57ea9a6940dd891ad53e9dbe8da0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   difficulty  duration  reward type    age    income  time  F  M  O  \\\n",
       "0        10.0       7.0         10.0  118.0       NaN     0  0  0  0   \n",
       "1        10.0       5.0         10.0   55.0  112000.0     0  1  0  0   \n",
       "2         0.0       4.0          0.0  118.0       NaN     0  0  0  0   \n",
       "3         5.0       7.0          5.0   75.0  100000.0     0  1  0  0   \n",
       "4        20.0      10.0          5.0  118.0       NaN     0  0  0  0   \n",
       "\n",
       "   offer completed  offer received  offer viewed  transaction  bogo  discount  \\\n",
       "0                0               1             0            0     1         0   \n",
       "1                0               1             0            0     1         0   \n",
       "2                0               1             0            0     0         0   \n",
       "3                0               1             0            0     1         0   \n",
       "4                0               1             0            0     0         1   \n",
       "\n",
       "   informational  amount                          offer id offer_id  reward  \n",
       "0              0     NaN  9b98b8c7a33c4b65b9aebfe6a799e6d9      NaN     NaN  \n",
       "1              0     NaN  0b1e1539f2cc45b7b9fa7c272da2e1d7      NaN     NaN  \n",
       "2              1     NaN  2906b810c7d4411798c6938adc9daaa5      NaN     NaN  \n",
       "3              0     NaN  fafdcd668e3743c1bb461111dcafc2a4      NaN     NaN  \n",
       "4              0     NaN  4d5c57ea9a6940dd891ad53e9dbe8da0      NaN     NaN  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#inspect the dataframe head to ensure we have the correct columns\n",
    "complete_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_df = complete_df.drop(['offer id', 'offer_id'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_df['reward'] = complete_df['reward'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_df['amount'] = complete_df['amount'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_df['income'] = complete_df['income'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>difficulty</th>\n",
       "      <th>duration</th>\n",
       "      <th>reward type</th>\n",
       "      <th>age</th>\n",
       "      <th>income</th>\n",
       "      <th>time</th>\n",
       "      <th>F</th>\n",
       "      <th>M</th>\n",
       "      <th>O</th>\n",
       "      <th>offer completed</th>\n",
       "      <th>offer received</th>\n",
       "      <th>offer viewed</th>\n",
       "      <th>transaction</th>\n",
       "      <th>bogo</th>\n",
       "      <th>discount</th>\n",
       "      <th>informational</th>\n",
       "      <th>amount</th>\n",
       "      <th>reward</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>112000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   difficulty  duration  reward type    age    income  time  F  M  O  \\\n",
       "0        10.0       7.0         10.0  118.0       0.0     0  0  0  0   \n",
       "1        10.0       5.0         10.0   55.0  112000.0     0  1  0  0   \n",
       "2         0.0       4.0          0.0  118.0       0.0     0  0  0  0   \n",
       "3         5.0       7.0          5.0   75.0  100000.0     0  1  0  0   \n",
       "4        20.0      10.0          5.0  118.0       0.0     0  0  0  0   \n",
       "\n",
       "   offer completed  offer received  offer viewed  transaction  bogo  discount  \\\n",
       "0                0               1             0            0     1         0   \n",
       "1                0               1             0            0     1         0   \n",
       "2                0               1             0            0     0         0   \n",
       "3                0               1             0            0     1         0   \n",
       "4                0               1             0            0     0         1   \n",
       "\n",
       "   informational  amount  reward  \n",
       "0              0     0.0     0.0  \n",
       "1              0     0.0     0.0  \n",
       "2              1     0.0     0.0  \n",
       "3              0     0.0     0.0  \n",
       "4              0     0.0     0.0  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complete_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete all rows with column 'Age' is 118 and 'income' is 0\n",
    "indexNames = complete_df[ (complete_df['age'] == 118) & (complete_df['income'] == 0) ].index\n",
    "complete_df.drop(indexNames , inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>c_1</th>\n",
       "      <th>c_2</th>\n",
       "      <th>c_3</th>\n",
       "      <th>c_4</th>\n",
       "      <th>c_5</th>\n",
       "      <th>c_6</th>\n",
       "      <th>c_7</th>\n",
       "      <th>c_8</th>\n",
       "      <th>c_9</th>\n",
       "      <th>c_10</th>\n",
       "      <th>c_11</th>\n",
       "      <th>c_12</th>\n",
       "      <th>c_13</th>\n",
       "      <th>c_14</th>\n",
       "      <th>c_15</th>\n",
       "      <th>c_16</th>\n",
       "      <th>c-17</th>\n",
       "      <th>c-18</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reward</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>112000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>53000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>51000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>57000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>46000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>71000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>52000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>40000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>71000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>71000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>69000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>88000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>52000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>59000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>41000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>96000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>52000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>89000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>33000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>57000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>68000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>63000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>40000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>30000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>33000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>80000.0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>62000.0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>34000.0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>51000.0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40.61</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>53000.0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>87000.0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>94000.0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.21</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>75000.0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>51000.0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>57000.0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>71000.0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>81000.0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>54000.0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>58000.0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>52000.0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>93000.0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>65000.0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>78000.0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12.89</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>55000.0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>63000.0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>40000.0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>51000.0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>39000.0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12.73</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>72000.0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15.86</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>113000.0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>54000.0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>72000.0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>73000.0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22.33</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>82000.0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14825 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         c_1  c_2   c_3   c_4       c_5  c_6  c_7  c_8  c_9  c_10  c_11  c_12  \\\n",
       "reward                                                                          \n",
       "0.0     10.0  5.0  10.0  55.0  112000.0    0    1    0    0     0     1     0   \n",
       "0.0      5.0  7.0   5.0  75.0  100000.0    0    1    0    0     0     1     0   \n",
       "0.0      7.0  7.0   3.0  68.0   70000.0    0    0    1    0     0     1     0   \n",
       "0.0      5.0  5.0   5.0  65.0   53000.0    0    0    1    0     0     1     0   \n",
       "0.0      0.0  0.0   0.0  58.0   51000.0    0    0    1    0     0     1     0   \n",
       "0.0      0.0  0.0   0.0  61.0   57000.0    0    1    0    0     0     1     0   \n",
       "0.0      0.0  0.0   0.0  26.0   46000.0    0    0    1    0     0     1     0   \n",
       "0.0      0.0  0.0   0.0  62.0   71000.0    0    1    0    0     0     1     0   \n",
       "0.0      0.0  0.0   0.0  49.0   52000.0    0    0    1    0     0     1     0   \n",
       "0.0      0.0  0.0   0.0  57.0   42000.0    0    0    1    0     0     1     0   \n",
       "0.0      0.0  0.0   0.0  61.0   40000.0    0    1    0    0     0     1     0   \n",
       "0.0      0.0  0.0   0.0  40.0   71000.0    0    1    0    0     0     1     0   \n",
       "0.0      0.0  0.0   0.0  64.0  100000.0    0    0    1    0     0     1     0   \n",
       "0.0      0.0  0.0   0.0  78.0   71000.0    0    1    0    0     0     1     0   \n",
       "0.0      0.0  0.0   0.0  42.0   69000.0    0    0    1    0     0     1     0   \n",
       "0.0      0.0  0.0   0.0  56.0   88000.0    0    1    0    0     0     1     0   \n",
       "0.0      0.0  0.0   0.0  33.0   52000.0    0    1    0    0     0     1     0   \n",
       "0.0      0.0  0.0   0.0  46.0   59000.0    0    1    0    0     0     1     0   \n",
       "0.0      0.0  0.0   0.0  59.0   41000.0    0    0    1    0     0     1     0   \n",
       "0.0      0.0  0.0   0.0  67.0   96000.0    0    0    1    0     0     1     0   \n",
       "0.0      0.0  0.0   0.0  53.0   52000.0    0    0    0    1     0     1     0   \n",
       "0.0      0.0  0.0   0.0  22.0   70000.0    0    0    1    0     0     1     0   \n",
       "0.0      0.0  0.0   0.0  96.0   89000.0    0    1    0    0     0     1     0   \n",
       "0.0      0.0  0.0   0.0  40.0   33000.0    0    0    1    0     0     1     0   \n",
       "0.0      0.0  0.0   0.0  69.0   57000.0    0    1    0    0     0     1     0   \n",
       "0.0      0.0  0.0   0.0  56.0   68000.0    0    0    1    0     0     1     0   \n",
       "0.0      0.0  0.0   0.0  26.0   63000.0    0    1    0    0     0     1     0   \n",
       "0.0      0.0  0.0   0.0  75.0   40000.0    0    0    1    0     0     1     0   \n",
       "0.0      0.0  0.0   0.0  20.0   30000.0    0    1    0    0     0     1     0   \n",
       "0.0      0.0  0.0   0.0  45.0   33000.0    0    0    1    0     0     1     0   \n",
       "...      ...  ...   ...   ...       ...  ...  ...  ...  ...   ...   ...   ...   \n",
       "0.0      0.0  0.0   0.0  62.0   80000.0    6    1    0    0     0     0     1   \n",
       "0.0      0.0  0.0   0.0  52.0   62000.0    6    0    1    0     0     0     1   \n",
       "0.0      0.0  0.0   0.0  52.0   34000.0    6    0    1    0     0     0     1   \n",
       "0.0      0.0  0.0   0.0  54.0   51000.0    6    0    1    0     0     0     0   \n",
       "5.0      0.0  0.0   0.0  54.0   53000.0    6    0    1    0     1     0     0   \n",
       "0.0      0.0  0.0   0.0  74.0   87000.0    6    0    1    0     0     0     1   \n",
       "0.0      0.0  0.0   0.0  67.0   94000.0    6    0    1    0     0     0     0   \n",
       "0.0      0.0  0.0   0.0  52.0   75000.0    6    1    0    0     0     0     1   \n",
       "0.0      0.0  0.0   0.0  44.0   51000.0    6    1    0    0     0     0     1   \n",
       "0.0      0.0  0.0   0.0  30.0   57000.0    6    0    1    0     0     0     1   \n",
       "0.0      0.0  0.0   0.0  59.0   71000.0    6    1    0    0     0     0     1   \n",
       "0.0      0.0  0.0   0.0  61.0   81000.0    6    1    0    0     0     0     1   \n",
       "0.0      0.0  0.0   0.0  39.0   54000.0    6    1    0    0     0     0     1   \n",
       "0.0      0.0  0.0   0.0  29.0   58000.0    6    1    0    0     0     0     1   \n",
       "0.0      0.0  0.0   0.0  63.0   52000.0    6    1    0    0     0     0     1   \n",
       "0.0      0.0  0.0   0.0  84.0   93000.0    6    0    1    0     0     0     1   \n",
       "0.0      0.0  0.0   0.0  72.0   65000.0    6    1    0    0     0     0     1   \n",
       "0.0      0.0  0.0   0.0  75.0   78000.0    6    1    0    0     0     0     0   \n",
       "0.0      0.0  0.0   0.0  26.0   55000.0    6    0    1    0     0     0     1   \n",
       "0.0      0.0  0.0   0.0  59.0   63000.0    6    1    0    0     0     0     1   \n",
       "0.0      0.0  0.0   0.0  57.0   40000.0    6    0    1    0     0     0     1   \n",
       "0.0      0.0  0.0   0.0  64.0   51000.0    6    0    1    0     0     0     1   \n",
       "0.0      0.0  0.0   0.0  70.0   39000.0    6    1    0    0     0     0     0   \n",
       "0.0      0.0  0.0   0.0  21.0   72000.0    6    1    0    0     0     0     0   \n",
       "2.0      0.0  0.0   0.0  60.0  113000.0    6    0    1    0     1     0     0   \n",
       "0.0      0.0  0.0   0.0  45.0   54000.0    6    1    0    0     0     0     1   \n",
       "0.0      0.0  0.0   0.0  61.0   72000.0    6    0    1    0     0     0     1   \n",
       "0.0      0.0  0.0   0.0  49.0   73000.0    6    0    1    0     0     0     0   \n",
       "5.0      0.0  0.0   0.0  83.0   50000.0    6    1    0    0     1     0     0   \n",
       "0.0      0.0  0.0   0.0  62.0   82000.0    6    1    0    0     0     0     1   \n",
       "\n",
       "        c_13  c_14  c_15  c_16   c-17  c-18  \n",
       "reward                                       \n",
       "0.0        0     1     0     0   0.00   0.0  \n",
       "0.0        0     1     0     0   0.00   0.0  \n",
       "0.0        0     0     1     0   0.00   0.0  \n",
       "0.0        0     1     0     0   0.00   0.0  \n",
       "0.0        0     0     0     0   0.00   0.0  \n",
       "0.0        0     0     0     0   0.00   0.0  \n",
       "0.0        0     0     0     0   0.00   0.0  \n",
       "0.0        0     0     0     0   0.00   0.0  \n",
       "0.0        0     0     0     0   0.00   0.0  \n",
       "0.0        0     0     0     0   0.00   0.0  \n",
       "0.0        0     0     0     0   0.00   0.0  \n",
       "0.0        0     0     0     0   0.00   0.0  \n",
       "0.0        0     0     0     0   0.00   0.0  \n",
       "0.0        0     0     0     0   0.00   0.0  \n",
       "0.0        0     0     0     0   0.00   0.0  \n",
       "0.0        0     0     0     0   0.00   0.0  \n",
       "0.0        0     0     0     0   0.00   0.0  \n",
       "0.0        0     0     0     0   0.00   0.0  \n",
       "0.0        0     0     0     0   0.00   0.0  \n",
       "0.0        0     0     0     0   0.00   0.0  \n",
       "0.0        0     0     0     0   0.00   0.0  \n",
       "0.0        0     0     0     0   0.00   0.0  \n",
       "0.0        0     0     0     0   0.00   0.0  \n",
       "0.0        0     0     0     0   0.00   0.0  \n",
       "0.0        0     0     0     0   0.00   0.0  \n",
       "0.0        0     0     0     0   0.00   0.0  \n",
       "0.0        0     0     0     0   0.00   0.0  \n",
       "0.0        0     0     0     0   0.00   0.0  \n",
       "0.0        0     0     0     0   0.00   0.0  \n",
       "0.0        0     0     0     0   0.00   0.0  \n",
       "...      ...   ...   ...   ...    ...   ...  \n",
       "0.0        0     0     0     0   0.00   0.0  \n",
       "0.0        0     0     0     0   0.00   0.0  \n",
       "0.0        0     0     0     0   0.00   0.0  \n",
       "0.0        1     0     0     0  40.61   0.0  \n",
       "5.0        0     0     0     0   0.00   5.0  \n",
       "0.0        0     0     0     0   0.00   0.0  \n",
       "0.0        1     0     0     0   1.21   0.0  \n",
       "0.0        0     0     0     0   0.00   0.0  \n",
       "0.0        0     0     0     0   0.00   0.0  \n",
       "0.0        0     0     0     0   0.00   0.0  \n",
       "0.0        0     0     0     0   0.00   0.0  \n",
       "0.0        0     0     0     0   0.00   0.0  \n",
       "0.0        0     0     0     0   0.00   0.0  \n",
       "0.0        0     0     0     0   0.00   0.0  \n",
       "0.0        0     0     0     0   0.00   0.0  \n",
       "0.0        0     0     0     0   0.00   0.0  \n",
       "0.0        0     0     0     0   0.00   0.0  \n",
       "0.0        1     0     0     0  12.89   0.0  \n",
       "0.0        0     0     0     0   0.00   0.0  \n",
       "0.0        0     0     0     0   0.00   0.0  \n",
       "0.0        0     0     0     0   0.00   0.0  \n",
       "0.0        0     0     0     0   0.00   0.0  \n",
       "0.0        1     0     0     0  12.73   0.0  \n",
       "0.0        1     0     0     0  15.86   0.0  \n",
       "2.0        0     0     0     0   0.00   2.0  \n",
       "0.0        0     0     0     0   0.00   0.0  \n",
       "0.0        0     0     0     0   0.00   0.0  \n",
       "0.0        1     0     0     0  22.33   0.0  \n",
       "5.0        0     0     0     0   0.00   5.0  \n",
       "0.0        0     0     0     0   0.00   0.0  \n",
       "\n",
       "[14825 rows x 18 columns]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complete_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_df['difficulty'] = complete_df['difficulty'].fillna(0)\n",
    "complete_df['duration'] = complete_df['duration'].fillna(0)\n",
    "complete_df['reward type'] = complete_df['reward type'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>difficulty</th>\n",
       "      <th>duration</th>\n",
       "      <th>reward type</th>\n",
       "      <th>age</th>\n",
       "      <th>income</th>\n",
       "      <th>time</th>\n",
       "      <th>F</th>\n",
       "      <th>M</th>\n",
       "      <th>O</th>\n",
       "      <th>offer completed</th>\n",
       "      <th>offer received</th>\n",
       "      <th>offer viewed</th>\n",
       "      <th>transaction</th>\n",
       "      <th>bogo</th>\n",
       "      <th>discount</th>\n",
       "      <th>informational</th>\n",
       "      <th>amount</th>\n",
       "      <th>reward</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>112000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>53000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>51000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    difficulty  duration  reward type   age    income  time  F  M  O  \\\n",
       "1         10.0       5.0         10.0  55.0  112000.0     0  1  0  0   \n",
       "3          5.0       7.0          5.0  75.0  100000.0     0  1  0  0   \n",
       "5          7.0       7.0          3.0  68.0   70000.0     0  0  1  0   \n",
       "8          5.0       5.0          5.0  65.0   53000.0     0  0  1  0   \n",
       "12         0.0       0.0          0.0  58.0   51000.0     0  0  1  0   \n",
       "\n",
       "    offer completed  offer received  offer viewed  transaction  bogo  \\\n",
       "1                 0               1             0            0     1   \n",
       "3                 0               1             0            0     1   \n",
       "5                 0               1             0            0     0   \n",
       "8                 0               1             0            0     1   \n",
       "12                0               1             0            0     0   \n",
       "\n",
       "    discount  informational  amount  reward  \n",
       "1          0              0     0.0     0.0  \n",
       "3          0              0     0.0     0.0  \n",
       "5          1              0     0.0     0.0  \n",
       "8          0              0     0.0     0.0  \n",
       "12         0              0     0.0     0.0  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complete_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_df = complete_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    11043\n",
       "0     3782\n",
       "Name: offer received, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complete_df['offer received'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "reward_income_df = complete_df.groupby('reward')['income'].mean().to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reward</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>65409.426032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>69487.804878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>63716.981132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.0</th>\n",
       "      <td>63010.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10.0</th>\n",
       "      <td>64493.506494</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              income\n",
       "reward              \n",
       "0.0     65409.426032\n",
       "2.0     69487.804878\n",
       "3.0     63716.981132\n",
       "5.0     63010.000000\n",
       "10.0    64493.506494"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reward_income_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f130ba8fe80>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    " complete_df.groupby('reward')['age'].mean().plot(kind = 'bar', color = 'lightblue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54.39352445193929"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complete_df['age'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Column not found: amount'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-98-6586c7ba24d0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcomplete_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'reward'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'amount'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'bar'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'lightblue'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/pandas/core/base.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    273\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 275\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Column not found: {key}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    276\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gotitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Column not found: amount'"
     ]
    }
   ],
   "source": [
    "complete_df.groupby('reward')['amount'].mean().plot(kind='bar',color='lightblue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f130b9f7940>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "complete_df.groupby('O')['amount'].mean().plot(kind='bar',color='lightblue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7609558178752107"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complete_df['amount'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "#need to normalize dataframe for 1st of three PCA analyses\n",
    "#1 - who views the offer\n",
    "#2 - who complete the offer\n",
    "#3 - who "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first we will reindex based on\n",
    "complete_df.index=complete_df['reward'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>difficulty</th>\n",
       "      <th>duration</th>\n",
       "      <th>reward type</th>\n",
       "      <th>age</th>\n",
       "      <th>income</th>\n",
       "      <th>time</th>\n",
       "      <th>F</th>\n",
       "      <th>M</th>\n",
       "      <th>O</th>\n",
       "      <th>offer completed</th>\n",
       "      <th>offer received</th>\n",
       "      <th>offer viewed</th>\n",
       "      <th>transaction</th>\n",
       "      <th>bogo</th>\n",
       "      <th>discount</th>\n",
       "      <th>informational</th>\n",
       "      <th>amount</th>\n",
       "      <th>reward</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reward</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>112000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>53000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>51000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        difficulty  duration  reward type   age    income  time  F  M  O  \\\n",
       "reward                                                                     \n",
       "0.0           10.0       5.0         10.0  55.0  112000.0     0  1  0  0   \n",
       "0.0            5.0       7.0          5.0  75.0  100000.0     0  1  0  0   \n",
       "0.0            7.0       7.0          3.0  68.0   70000.0     0  0  1  0   \n",
       "0.0            5.0       5.0          5.0  65.0   53000.0     0  0  1  0   \n",
       "0.0            0.0       0.0          0.0  58.0   51000.0     0  0  1  0   \n",
       "\n",
       "        offer completed  offer received  offer viewed  transaction  bogo  \\\n",
       "reward                                                                     \n",
       "0.0                   0               1             0            0     1   \n",
       "0.0                   0               1             0            0     1   \n",
       "0.0                   0               1             0            0     0   \n",
       "0.0                   0               1             0            0     1   \n",
       "0.0                   0               1             0            0     0   \n",
       "\n",
       "        discount  informational  amount  reward  \n",
       "reward                                           \n",
       "0.0            0              0     0.0     0.0  \n",
       "0.0            0              0     0.0     0.0  \n",
       "0.0            1              0     0.0     0.0  \n",
       "0.0            0              0     0.0     0.0  \n",
       "0.0            0              0     0.0     0.0  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complete_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>difficulty</th>\n",
       "      <th>duration</th>\n",
       "      <th>reward type</th>\n",
       "      <th>age</th>\n",
       "      <th>income</th>\n",
       "      <th>time</th>\n",
       "      <th>F</th>\n",
       "      <th>M</th>\n",
       "      <th>O</th>\n",
       "      <th>offer completed</th>\n",
       "      <th>offer received</th>\n",
       "      <th>offer viewed</th>\n",
       "      <th>transaction</th>\n",
       "      <th>bogo</th>\n",
       "      <th>discount</th>\n",
       "      <th>informational</th>\n",
       "      <th>amount</th>\n",
       "      <th>reward</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reward</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.445783</td>\n",
       "      <td>0.911111</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>0.5</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.686747</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>0.7</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.602410</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.566265</td>\n",
       "      <td>0.255556</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.481928</td>\n",
       "      <td>0.233333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        difficulty  duration  reward type       age    income  time    F    M  \\\n",
       "reward                                                                          \n",
       "0.0            1.0  0.714286          1.0  0.445783  0.911111   0.0  1.0  0.0   \n",
       "0.0            0.5  1.000000          0.5  0.686747  0.777778   0.0  1.0  0.0   \n",
       "0.0            0.7  1.000000          0.3  0.602410  0.444444   0.0  0.0  1.0   \n",
       "0.0            0.5  0.714286          0.5  0.566265  0.255556   0.0  0.0  1.0   \n",
       "0.0            0.0  0.000000          0.0  0.481928  0.233333   0.0  0.0  1.0   \n",
       "\n",
       "          O  offer completed  offer received  offer viewed  transaction  bogo  \\\n",
       "reward                                                                          \n",
       "0.0     0.0              0.0             1.0           0.0          0.0   1.0   \n",
       "0.0     0.0              0.0             1.0           0.0          0.0   1.0   \n",
       "0.0     0.0              0.0             1.0           0.0          0.0   0.0   \n",
       "0.0     0.0              0.0             1.0           0.0          0.0   1.0   \n",
       "0.0     0.0              0.0             1.0           0.0          0.0   0.0   \n",
       "\n",
       "        discount  informational  amount  reward  \n",
       "reward                                           \n",
       "0.0          0.0            0.0     0.0     0.0  \n",
       "0.0          0.0            0.0     0.0     0.0  \n",
       "0.0          1.0            0.0     0.0     0.0  \n",
       "0.0          0.0            0.0     0.0     0.0  \n",
       "0.0          0.0            0.0     0.0     0.0  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#now we need to normalize the data from 0-1\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler=MinMaxScaler()\n",
    "# store them in this dataframe\n",
    "complete_df_scaled=pd.DataFrame(scaler.fit_transform(complete_df.astype(float)))\n",
    "\n",
    "# get same features and State-County indices\n",
    "complete_df_scaled.columns=complete_df.columns\n",
    "complete_df_scaled.index=complete_df.index\n",
    "\n",
    "complete_df_scaled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arn:aws:iam::078540992053:role/service-role/AmazonSageMaker-ExecutionRole-20191219T082471\n"
     ]
    }
   ],
   "source": [
    "#start sagemaker PCA process\n",
    "import sagemaker\n",
    "import boto3\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "session = sagemaker.Session() # store the current SageMaker session\n",
    "\n",
    "# get IAM role\n",
    "role = get_execution_role()\n",
    "print(role)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker-us-east-1-078540992053\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# get default bucket\n",
    "bucket_name = session.default_bucket()\n",
    "print(bucket_name)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training artifacts will be uploaded to: s3://sagemaker-us-east-1-078540992053/PCA-K Means/\n"
     ]
    }
   ],
   "source": [
    "# define location to store model artifacts\n",
    "prefix = 'PCA-K Means'\n",
    "\n",
    "output_path='s3://{}/{}/'.format(bucket_name, prefix)\n",
    "\n",
    "print('Training artifacts will be uploaded to: {}'.format(output_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a PCA model\n",
    "from sagemaker import PCA\n",
    "\n",
    "# this is current features - 1\n",
    "# you'll select only a portion of these to use, later\n",
    "N_COMPONENTS=17\n",
    "\n",
    "pca_SM = PCA(role=role,\n",
    "             train_instance_count=1,\n",
    "             train_instance_type='ml.c4.xlarge',\n",
    "             output_path=output_path, # specified, above\n",
    "             num_components=N_COMPONENTS, \n",
    "             sagemaker_session=session)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert df to np array\n",
    "train_data_np = complete_df_scaled.values.astype('float32')\n",
    "\n",
    "# convert to RecordSet format\n",
    "formatted_train_data = pca_SM.record_set(train_data_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-01-22 02:47:25 Starting - Starting the training job...\n",
      "2020-01-22 02:47:27 Starting - Launching requested ML instances......\n",
      "2020-01-22 02:48:30 Starting - Preparing the instances for training......\n",
      "2020-01-22 02:49:52 Downloading - Downloading input data...\n",
      "2020-01-22 02:50:23 Training - Training image download completed. Training in progress.\n",
      "2020-01-22 02:50:23 Uploading - Uploading generated training model\u001b[34mDocker entrypoint called with argument(s): train\u001b[0m\n",
      "\u001b[34m[01/22/2020 02:50:21 INFO 139905571288896] Reading default configuration from /opt/amazon/lib/python2.7/site-packages/algorithm/resources/default-conf.json: {u'_num_gpus': u'auto', u'_log_level': u'info', u'subtract_mean': u'true', u'force_dense': u'true', u'epochs': 1, u'algorithm_mode': u'regular', u'extra_components': u'-1', u'_kvstore': u'dist_sync', u'_num_kv_servers': u'auto'}\u001b[0m\n",
      "\u001b[34m[01/22/2020 02:50:21 INFO 139905571288896] Reading provided configuration from /opt/ml/input/config/hyperparameters.json: {u'feature_dim': u'18', u'mini_batch_size': u'500', u'num_components': u'17'}\u001b[0m\n",
      "\u001b[34m[01/22/2020 02:50:21 INFO 139905571288896] Final configuration: {u'num_components': u'17', u'_num_gpus': u'auto', u'_log_level': u'info', u'subtract_mean': u'true', u'force_dense': u'true', u'epochs': 1, u'algorithm_mode': u'regular', u'feature_dim': u'18', u'extra_components': u'-1', u'_kvstore': u'dist_sync', u'_num_kv_servers': u'auto', u'mini_batch_size': u'500'}\u001b[0m\n",
      "\u001b[34m[01/22/2020 02:50:21 WARNING 139905571288896] Loggers have already been setup.\u001b[0m\n",
      "\u001b[34m[01/22/2020 02:50:22 INFO 139905571288896] Launching parameter server for role scheduler\u001b[0m\n",
      "\u001b[34m[01/22/2020 02:50:22 INFO 139905571288896] {'ECS_CONTAINER_METADATA_URI': 'http://169.254.170.2/v3/db10a9c3-2006-4878-a2a2-7102e3a77456', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION_VERSION': '2', 'PATH': '/opt/amazon/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/opt/amazon/bin:/opt/amazon/bin', 'SAGEMAKER_HTTP_PORT': '8080', 'HOME': '/root', 'PYTHONUNBUFFERED': 'TRUE', 'CANONICAL_ENVROOT': '/opt/amazon', 'LD_LIBRARY_PATH': '/opt/amazon/lib/python2.7/site-packages/cv2/../../../../lib:/usr/local/nvidia/lib64:/opt/amazon/lib', 'LANG': 'en_US.utf8', 'DMLC_INTERFACE': 'eth0', 'SHLVL': '1', 'AWS_REGION': 'us-east-1', 'NVIDIA_VISIBLE_DEVICES': 'void', 'TRAINING_JOB_NAME': 'pca-2020-01-22-02-47-25-525', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION': 'cpp', 'ENVROOT': '/opt/amazon', 'SAGEMAKER_DATA_PATH': '/opt/ml', 'NVIDIA_DRIVER_CAPABILITIES': 'compute,utility', 'NVIDIA_REQUIRE_CUDA': 'cuda>=9.0', 'OMP_NUM_THREADS': '2', 'HOSTNAME': 'ip-10-2-123-209.ec2.internal', 'AWS_CONTAINER_CREDENTIALS_RELATIVE_URI': '/v2/credentials/ad718564-927a-429c-bc56-437446d0e62f', 'PWD': '/', 'TRAINING_JOB_ARN': 'arn:aws:sagemaker:us-east-1:078540992053:training-job/pca-2020-01-22-02-47-25-525', 'AWS_EXECUTION_ENV': 'AWS_ECS_EC2'}\u001b[0m\n",
      "\u001b[34m[01/22/2020 02:50:22 INFO 139905571288896] envs={'ECS_CONTAINER_METADATA_URI': 'http://169.254.170.2/v3/db10a9c3-2006-4878-a2a2-7102e3a77456', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION_VERSION': '2', 'DMLC_NUM_WORKER': '1', 'DMLC_PS_ROOT_PORT': '9000', 'PATH': '/opt/amazon/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/opt/amazon/bin:/opt/amazon/bin', 'SAGEMAKER_HTTP_PORT': '8080', 'HOME': '/root', 'PYTHONUNBUFFERED': 'TRUE', 'CANONICAL_ENVROOT': '/opt/amazon', 'LD_LIBRARY_PATH': '/opt/amazon/lib/python2.7/site-packages/cv2/../../../../lib:/usr/local/nvidia/lib64:/opt/amazon/lib', 'LANG': 'en_US.utf8', 'DMLC_INTERFACE': 'eth0', 'SHLVL': '1', 'DMLC_PS_ROOT_URI': '10.2.123.209', 'AWS_REGION': 'us-east-1', 'NVIDIA_VISIBLE_DEVICES': 'void', 'TRAINING_JOB_NAME': 'pca-2020-01-22-02-47-25-525', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION': 'cpp', 'ENVROOT': '/opt/amazon', 'SAGEMAKER_DATA_PATH': '/opt/ml', 'NVIDIA_DRIVER_CAPABILITIES': 'compute,utility', 'NVIDIA_REQUIRE_CUDA': 'cuda>=9.0', 'OMP_NUM_THREADS': '2', 'HOSTNAME': 'ip-10-2-123-209.ec2.internal', 'AWS_CONTAINER_CREDENTIALS_RELATIVE_URI': '/v2/credentials/ad718564-927a-429c-bc56-437446d0e62f', 'DMLC_ROLE': 'scheduler', 'PWD': '/', 'DMLC_NUM_SERVER': '1', 'TRAINING_JOB_ARN': 'arn:aws:sagemaker:us-east-1:078540992053:training-job/pca-2020-01-22-02-47-25-525', 'AWS_EXECUTION_ENV': 'AWS_ECS_EC2'}\u001b[0m\n",
      "\u001b[34m[01/22/2020 02:50:22 INFO 139905571288896] Launching parameter server for role server\u001b[0m\n",
      "\u001b[34m[01/22/2020 02:50:22 INFO 139905571288896] {'ECS_CONTAINER_METADATA_URI': 'http://169.254.170.2/v3/db10a9c3-2006-4878-a2a2-7102e3a77456', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION_VERSION': '2', 'PATH': '/opt/amazon/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/opt/amazon/bin:/opt/amazon/bin', 'SAGEMAKER_HTTP_PORT': '8080', 'HOME': '/root', 'PYTHONUNBUFFERED': 'TRUE', 'CANONICAL_ENVROOT': '/opt/amazon', 'LD_LIBRARY_PATH': '/opt/amazon/lib/python2.7/site-packages/cv2/../../../../lib:/usr/local/nvidia/lib64:/opt/amazon/lib', 'LANG': 'en_US.utf8', 'DMLC_INTERFACE': 'eth0', 'SHLVL': '1', 'AWS_REGION': 'us-east-1', 'NVIDIA_VISIBLE_DEVICES': 'void', 'TRAINING_JOB_NAME': 'pca-2020-01-22-02-47-25-525', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION': 'cpp', 'ENVROOT': '/opt/amazon', 'SAGEMAKER_DATA_PATH': '/opt/ml', 'NVIDIA_DRIVER_CAPABILITIES': 'compute,utility', 'NVIDIA_REQUIRE_CUDA': 'cuda>=9.0', 'OMP_NUM_THREADS': '2', 'HOSTNAME': 'ip-10-2-123-209.ec2.internal', 'AWS_CONTAINER_CREDENTIALS_RELATIVE_URI': '/v2/credentials/ad718564-927a-429c-bc56-437446d0e62f', 'PWD': '/', 'TRAINING_JOB_ARN': 'arn:aws:sagemaker:us-east-1:078540992053:training-job/pca-2020-01-22-02-47-25-525', 'AWS_EXECUTION_ENV': 'AWS_ECS_EC2'}\u001b[0m\n",
      "\u001b[34m[01/22/2020 02:50:22 INFO 139905571288896] envs={'ECS_CONTAINER_METADATA_URI': 'http://169.254.170.2/v3/db10a9c3-2006-4878-a2a2-7102e3a77456', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION_VERSION': '2', 'DMLC_NUM_WORKER': '1', 'DMLC_PS_ROOT_PORT': '9000', 'PATH': '/opt/amazon/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/opt/amazon/bin:/opt/amazon/bin', 'SAGEMAKER_HTTP_PORT': '8080', 'HOME': '/root', 'PYTHONUNBUFFERED': 'TRUE', 'CANONICAL_ENVROOT': '/opt/amazon', 'LD_LIBRARY_PATH': '/opt/amazon/lib/python2.7/site-packages/cv2/../../../../lib:/usr/local/nvidia/lib64:/opt/amazon/lib', 'LANG': 'en_US.utf8', 'DMLC_INTERFACE': 'eth0', 'SHLVL': '1', 'DMLC_PS_ROOT_URI': '10.2.123.209', 'AWS_REGION': 'us-east-1', 'NVIDIA_VISIBLE_DEVICES': 'void', 'TRAINING_JOB_NAME': 'pca-2020-01-22-02-47-25-525', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION': 'cpp', 'ENVROOT': '/opt/amazon', 'SAGEMAKER_DATA_PATH': '/opt/ml', 'NVIDIA_DRIVER_CAPABILITIES': 'compute,utility', 'NVIDIA_REQUIRE_CUDA': 'cuda>=9.0', 'OMP_NUM_THREADS': '2', 'HOSTNAME': 'ip-10-2-123-209.ec2.internal', 'AWS_CONTAINER_CREDENTIALS_RELATIVE_URI': '/v2/credentials/ad718564-927a-429c-bc56-437446d0e62f', 'DMLC_ROLE': 'server', 'PWD': '/', 'DMLC_NUM_SERVER': '1', 'TRAINING_JOB_ARN': 'arn:aws:sagemaker:us-east-1:078540992053:training-job/pca-2020-01-22-02-47-25-525', 'AWS_EXECUTION_ENV': 'AWS_ECS_EC2'}\u001b[0m\n",
      "\u001b[34m[01/22/2020 02:50:22 INFO 139905571288896] Environment: {'ECS_CONTAINER_METADATA_URI': 'http://169.254.170.2/v3/db10a9c3-2006-4878-a2a2-7102e3a77456', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION_VERSION': '2', 'DMLC_PS_ROOT_PORT': '9000', 'DMLC_NUM_WORKER': '1', 'SAGEMAKER_HTTP_PORT': '8080', 'PATH': '/opt/amazon/bin:/usr/local/nvidia/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/opt/amazon/bin:/opt/amazon/bin', 'PYTHONUNBUFFERED': 'TRUE', 'CANONICAL_ENVROOT': '/opt/amazon', 'LD_LIBRARY_PATH': '/opt/amazon/lib/python2.7/site-packages/cv2/../../../../lib:/usr/local/nvidia/lib64:/opt/amazon/lib', 'LANG': 'en_US.utf8', 'DMLC_INTERFACE': 'eth0', 'SHLVL': '1', 'DMLC_PS_ROOT_URI': '10.2.123.209', 'AWS_REGION': 'us-east-1', 'NVIDIA_VISIBLE_DEVICES': 'void', 'TRAINING_JOB_NAME': 'pca-2020-01-22-02-47-25-525', 'HOME': '/root', 'PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION': 'cpp', 'ENVROOT': '/opt/amazon', 'SAGEMAKER_DATA_PATH': '/opt/ml', 'NVIDIA_DRIVER_CAPABILITIES': 'compute,utility', 'NVIDIA_REQUIRE_CUDA': 'cuda>=9.0', 'OMP_NUM_THREADS': '2', 'HOSTNAME': 'ip-10-2-123-209.ec2.internal', 'AWS_CONTAINER_CREDENTIALS_RELATIVE_URI': '/v2/credentials/ad718564-927a-429c-bc56-437446d0e62f', 'DMLC_ROLE': 'worker', 'PWD': '/', 'DMLC_NUM_SERVER': '1', 'TRAINING_JOB_ARN': 'arn:aws:sagemaker:us-east-1:078540992053:training-job/pca-2020-01-22-02-47-25-525', 'AWS_EXECUTION_ENV': 'AWS_ECS_EC2'}\u001b[0m\n",
      "\u001b[34mProcess 60 is a shell:scheduler.\u001b[0m\n",
      "\u001b[34mProcess 69 is a shell:server.\u001b[0m\n",
      "\u001b[34mProcess 1 is a worker.\u001b[0m\n",
      "\u001b[34m[01/22/2020 02:50:22 INFO 139905571288896] Using default worker.\u001b[0m\n",
      "\u001b[34m[01/22/2020 02:50:22 INFO 139905571288896] Loaded iterator creator application/x-recordio-protobuf for content type ('application/x-recordio-protobuf', '1.0')\u001b[0m\n",
      "\u001b[34m[01/22/2020 02:50:22 INFO 139905571288896] Loaded iterator creator application/x-labeled-vector-protobuf for content type ('application/x-labeled-vector-protobuf', '1.0')\u001b[0m\n",
      "\u001b[34m[01/22/2020 02:50:22 INFO 139905571288896] Loaded iterator creator protobuf for content type ('protobuf', '1.0')\u001b[0m\n",
      "\u001b[34m[01/22/2020 02:50:22 INFO 139905571288896] Create Store: dist_sync\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[01/22/2020 02:50:23 INFO 139905571288896] nvidia-smi took: 0.0252552032471 secs to identify 0 gpus\u001b[0m\n",
      "\u001b[34m[01/22/2020 02:50:23 INFO 139905571288896] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[01/22/2020 02:50:23 INFO 139905571288896] The default executor is <PCAExecutor on cpu(0)>.\u001b[0m\n",
      "\u001b[34m[01/22/2020 02:50:23 INFO 139905571288896] 18 feature(s) found in 'data'.\u001b[0m\n",
      "\u001b[34m[01/22/2020 02:50:23 INFO 139905571288896] <PCAExecutor on cpu(0)> is assigned to batch slice from 0 to 499.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"initialize.time\": {\"count\": 1, \"max\": 745.4428672790527, \"sum\": 745.4428672790527, \"min\": 745.4428672790527}}, \"EndTime\": 1579661423.069306, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"PCA\"}, \"StartTime\": 1579661422.315585}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Batches Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Records Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Reset Count\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}}, \"EndTime\": 1579661423.069517, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"init_train_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"PCA\"}, \"StartTime\": 1579661423.06948}\n",
      "\u001b[0m\n",
      "\u001b[34m[2020-01-22 02:50:23.069] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 0, \"duration\": 753, \"num_examples\": 1, \"num_bytes\": 48000}\u001b[0m\n",
      "\u001b[34m[2020-01-22 02:50:23.125] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 1, \"duration\": 47, \"num_examples\": 30, \"num_bytes\": 1423200}\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"epochs\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}, \"update.time\": {\"count\": 1, \"max\": 55.32503128051758, \"sum\": 55.32503128051758, \"min\": 55.32503128051758}}, \"EndTime\": 1579661423.125329, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"PCA\"}, \"StartTime\": 1579661423.069405}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/22/2020 02:50:23 INFO 139905571288896] #progress_metric: host=algo-1, completed 100 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 30, \"sum\": 30.0, \"min\": 30}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 30, \"sum\": 30.0, \"min\": 30}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 14825, \"sum\": 14825.0, \"min\": 14825}, \"Total Batches Seen\": {\"count\": 1, \"max\": 30, \"sum\": 30.0, \"min\": 30}, \"Total Records Seen\": {\"count\": 1, \"max\": 14825, \"sum\": 14825.0, \"min\": 14825}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 14825, \"sum\": 14825.0, \"min\": 14825}, \"Reset Count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1579661423.125608, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"PCA\", \"epoch\": 0}, \"StartTime\": 1579661423.069922}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/22/2020 02:50:23 INFO 139905571288896] #throughput_metric: host=algo-1, train throughput=265690.270644 records/second\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"finalize.time\": {\"count\": 1, \"max\": 20.34783363342285, \"sum\": 20.34783363342285, \"min\": 20.34783363342285}}, \"EndTime\": 1579661423.146271, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"PCA\"}, \"StartTime\": 1579661423.125404}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/22/2020 02:50:23 INFO 139905571288896] Test data is not provided.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"totaltime\": {\"count\": 1, \"max\": 1988.6960983276367, \"sum\": 1988.6960983276367, \"min\": 1988.6960983276367}, \"setuptime\": {\"count\": 1, \"max\": 1055.5000305175781, \"sum\": 1055.5000305175781, \"min\": 1055.5000305175781}}, \"EndTime\": 1579661423.152851, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"PCA\"}, \"StartTime\": 1579661423.146324}\n",
      "\u001b[0m\n",
      "\n",
      "2020-01-22 02:50:29 Completed - Training job completed\n",
      "Training seconds: 37\n",
      "Billable seconds: 37\n",
      "CPU times: user 460 ms, sys: 0 ns, total: 460 ms\n",
      "Wall time: 3min 42s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# train the PCA mode on the formatted data\n",
    "pca_SM.fit(formatted_train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA-K Means/pca-2020-01-22-02-47-25-525/output/model.tar.gz\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2304"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the name of the training job, it's suggested that you copy-paste\n",
    "# from the notebook or from a specific job in the AWS console\n",
    "training_job_name='pca-2020-01-22-02-47-25-525'\n",
    "\n",
    "# where the model is saved, by default\n",
    "model_key = os.path.join(prefix, training_job_name, 'output/model.tar.gz')\n",
    "print(model_key)\n",
    "\n",
    "# download and unzip model\n",
    "boto3.resource('s3').Bucket(bucket_name).download_file(model_key, 'model.tar.gz')\n",
    "\n",
    "# unzipping as model_algo-1\n",
    "os.system('tar -zxvf model.tar.gz')\n",
    "os.system('unzip model_algo-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features: \n",
      " ['difficulty' 'duration' 'reward type' 'age' 'income' 'time' 'F' 'M' 'O'\n",
      " 'offer completed' 'offer received' 'offer viewed' 'transaction' 'bogo'\n",
      " 'discount' 'informational' 'amount' 'reward']\n"
     ]
    }
   ],
   "source": [
    "# features\n",
    "features_list = complete_df_scaled.columns.values\n",
    "print('Features: \\n', features_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'s': \n",
      "[           nan 1.72234708e-04 1.09132174e-02 1.09385595e-01\n",
      " 5.25367200e-01 1.23154092e+00 1.81883895e+00 2.96477175e+00\n",
      " 4.87274313e+00 1.76945267e+01 2.14936275e+01 2.24093342e+01\n",
      " 2.68431320e+01 3.05509815e+01 3.73878517e+01 6.88603058e+01\n",
      " 8.48107376e+01]\n",
      "<NDArray 17 @cpu(0)>, 'v': \n",
      "[[-3.3269450e-16  6.8031740e-01  4.6998004e-05 -1.4874802e-02\n",
      "   5.4794443e-01  1.5447058e-01  8.2574770e-05 -4.6120602e-01\n",
      "   1.2548607e-04 -1.2685051e-04  3.5188466e-05 -2.2410227e-04\n",
      "   6.0137903e-05 -7.3086709e-04  4.1693631e-05  1.7978525e-04\n",
      "  -8.7095788e-05]\n",
      " [-4.2988383e-21  2.0927837e-06 -3.5267317e-06  5.2810085e-01\n",
      "  -5.4934031e-01  3.2196707e-01  5.2322637e-05 -5.6184608e-01\n",
      "   1.4920776e-04 -1.6972487e-04  9.4303119e-05  6.8173293e-05\n",
      "   7.2092749e-05 -8.8985480e-04  5.4943768e-05  2.3050584e-04\n",
      "  -7.2303985e-05]\n",
      " [ 3.3269278e-16 -6.8031675e-01 -4.7911697e-05  2.2163649e-01\n",
      "   5.4705036e-01 -1.4476046e-01  9.4929674e-05 -4.0950587e-01\n",
      "   1.2293115e-04 -1.0781880e-04  1.3038494e-05 -3.0697588e-04\n",
      "   5.1635470e-05 -6.4696517e-04  3.4149365e-05  1.5048077e-04\n",
      "  -1.1847781e-04]\n",
      " [-1.7365594e-22 -8.5126288e-09  5.8934114e-07  1.8315488e-05\n",
      "   2.1479405e-04 -2.5861966e-04 -1.0763997e-03  6.5161486e-04\n",
      "   1.3305286e-03 -9.1529582e-03  1.0968218e-01  8.2710463e-01\n",
      "  -2.5113206e-02 -5.4797196e-01  6.4307698e-03 -3.1675086e-03\n",
      "  -5.3152654e-02]\n",
      " [ 1.7619362e-22  9.9793214e-09 -4.0059322e-07 -4.7905301e-05\n",
      "  -1.6454210e-04  1.4610784e-04 -1.6255036e-04  1.4419535e-03\n",
      "   3.1686359e-04  2.1002341e-02 -6.4908437e-02 -5.4650187e-01\n",
      "   4.1791401e-03 -8.2970548e-01 -6.3466318e-03  4.5791044e-04\n",
      "  -9.0609737e-02]\n",
      " [ 1.8098994e-23  6.8566519e-10 -8.2037587e-08  5.9977509e-07\n",
      "   2.8415348e-06 -4.1866169e-06 -6.8426959e-04 -2.9035566e-06\n",
      "   4.7097895e-03 -7.0151445e-03  1.7533702e-01  8.4809188e-05\n",
      "   8.6541545e-01 -8.0598621e-03 -3.7234998e-01 -2.8533953e-01\n",
      "   1.0634356e-02]\n",
      " [-1.3714689e-16 -7.2765560e-03  3.8423076e-01 -5.7742809e-06\n",
      "  -1.0759471e-05  8.8082597e-05  1.7734239e-04  1.4316133e-04\n",
      "   6.5918511e-04 -4.1199383e-01 -9.1719925e-03 -2.9834202e-03\n",
      "  -3.1261295e-03  6.8795711e-02 -3.7015283e-03 -2.8214509e-02\n",
      "  -7.0091504e-01]\n",
      " [-1.3714688e-16 -7.2765551e-03  3.8423073e-01  1.4271653e-05\n",
      "   1.5466027e-05 -9.4714989e-05  9.4038282e-05  1.0673092e-04\n",
      "  -8.0513052e-04 -4.0413773e-01 -7.0026768e-03 -1.0846542e-02\n",
      "  -6.5342418e-04 -7.9452433e-02  2.0942411e-03  2.9392870e-02\n",
      "   7.0426601e-01]\n",
      " [-1.3714689e-16 -7.2765551e-03  3.8423094e-01  3.7790744e-06\n",
      "  -5.3157355e-06  6.8502604e-06 -2.7025279e-04 -2.4980385e-04\n",
      "   1.4688549e-04  8.1613147e-01  1.6174592e-02  1.3828177e-02\n",
      "   3.7797578e-03  1.0656417e-02  1.6073186e-03 -1.1783298e-03\n",
      "  -3.3509850e-03]\n",
      " [ 3.6066206e-17  5.5727949e-03  3.7319607e-01  2.5603081e-06\n",
      "  -3.7239924e-06 -1.6198597e-06  1.5830914e-02 -2.1550538e-04\n",
      "  -3.6911741e-01  1.3220019e-02 -7.6254624e-01  1.0165828e-01\n",
      "   1.0123490e-01 -6.1446712e-03 -9.8367013e-02 -3.9331786e-02\n",
      "   2.4802161e-03]\n",
      " [ 3.6066266e-17  5.5727945e-03  3.7319547e-01  2.0658108e-06\n",
      "   7.1987779e-06 -2.1185999e-05  1.4775544e-02  4.1952202e-04\n",
      "   1.2305191e-01 -5.0677387e-03  2.3976840e-01 -2.3731895e-02\n",
      "   2.7745971e-01  7.3979417e-04  1.8228520e-01  7.5186729e-01\n",
      "  -3.2331415e-02]\n",
      " [ 3.6066263e-17  5.5727945e-03  3.7319550e-01 -1.0363054e-07\n",
      "  -3.4336144e-06  1.3081701e-05  1.4986345e-02 -9.7808530e-05\n",
      "   1.2263879e-01 -5.7764216e-03  2.1980464e-01 -3.5065044e-02\n",
      "   2.0753799e-02 -1.2109990e-03  5.9465516e-01 -5.7505441e-01\n",
      "   2.0583615e-02]\n",
      " [ 3.6066243e-17  5.5727940e-03  3.7319565e-01 -3.0760918e-07\n",
      "  -3.2631911e-07  9.7328430e-06 -4.5592099e-02 -1.0625109e-04\n",
      "   1.2342814e-01 -2.3761531e-03  3.0297324e-01 -4.2861428e-02\n",
      "  -3.9944828e-01  6.6161533e-03 -6.7857331e-01 -1.3748106e-01\n",
      "   9.2676021e-03]\n",
      " [ 4.6075806e-21 -2.1286071e-06  3.5192461e-06 -5.6760180e-01\n",
      "  -3.1418616e-01 -5.4027778e-01  1.1800444e-04 -5.3592384e-01\n",
      "   1.6637048e-04 -1.4976654e-04  4.4965309e-05 -1.9387854e-04\n",
      "   6.4421154e-05 -7.9319661e-04  4.5073710e-05  1.9569759e-04\n",
      "  -1.6235893e-04]\n",
      " [ 1.3308267e-16 -2.7212924e-01 -1.5032306e-05 -5.9126449e-01\n",
      "   2.2347227e-03  7.4807769e-01 -3.0888928e-05 -1.2925042e-01\n",
      "   6.3857515e-06 -4.7579571e-05  5.5374669e-05  2.0718340e-04\n",
      "   2.1255955e-05 -2.0975494e-04  1.8860619e-05  7.3261101e-05\n",
      "   7.8455036e-05]\n",
      " [-1.0000000e+00 -4.8225313e-16  0.0000000e+00  0.0000000e+00\n",
      "   0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00\n",
      "   0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00\n",
      "   0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00\n",
      "   0.0000000e+00]\n",
      " [ 1.2704095e-22  3.8276315e-09 -6.9900977e-07  1.1972700e-06\n",
      "  -3.1143551e-05  7.1470022e-05  9.9861139e-01  1.6071449e-04\n",
      "   8.8772550e-03  1.7264196e-04  1.8827472e-02 -1.8202284e-03\n",
      "  -2.3631372e-02 -3.2882285e-04 -4.1349363e-02 -8.3681233e-03\n",
      "   5.4875395e-04]\n",
      " [ 6.3019441e-23 -1.7076509e-09 -7.7928939e-07 -5.7870184e-06\n",
      "  -3.9083425e-06  3.7843831e-05 -1.1558356e-03  1.9154701e-04\n",
      "   9.0456164e-01  7.0403833e-03 -4.1616330e-01  5.4296426e-02\n",
      "   5.1019683e-02 -2.3268880e-03 -5.0625838e-02 -1.9986669e-02\n",
      "   2.5424357e-03]]\n",
      "<NDArray 18x17 @cpu(0)>, 'mean': \n",
      "[[1.82124786e-04 2.31269572e-04 1.55143338e-04 4.38476235e-01\n",
      "  3.93388778e-01 8.35075900e-02 4.13423270e-01 5.72276533e-01\n",
      "  1.43001685e-02 2.10455321e-02 7.44890392e-01 1.69713318e-01\n",
      "  6.43507615e-02 2.02360883e-04 6.74536277e-05 0.00000000e+00\n",
      "  3.89754074e-03 1.07453624e-02]]\n",
      "<NDArray 1x18 @cpu(0)>}\n"
     ]
    }
   ],
   "source": [
    "import mxnet as mx\n",
    "\n",
    "# loading the unzipped artifacts\n",
    "pca_model_params = mx.ndarray.load('model_algo-1')\n",
    "\n",
    "# what are the params\n",
    "print(pca_model_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get selected params\n",
    "s=pd.DataFrame(pca_model_params['s'].asnumpy())\n",
    "v=pd.DataFrame(pca_model_params['v'].asnumpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "def display_component(v, features_list, component_num, n_weights=10):\n",
    "    \n",
    "    # get index of component (last row - component_num)\n",
    "    row_idx = N_COMPONENTS-component_num\n",
    "\n",
    "    # get the list of weights from a row in v, dataframe\n",
    "    v_1_row = v.iloc[:, row_idx]\n",
    "    v_1 = np.squeeze(v_1_row.values)\n",
    "\n",
    "    # match weights to features in counties_scaled dataframe, using list comporehension\n",
    "    comps = pd.DataFrame(list(zip(v_1, features_list)), \n",
    "                         columns=['weights', 'features'])\n",
    "\n",
    "    # we'll want to sort by the largest n_weights\n",
    "    # weights can be neg/pos and we'll sort by magnitude\n",
    "    comps['abs_weights']=comps['weights'].apply(lambda x: np.abs(x))\n",
    "    sorted_weight_data = comps.sort_values('abs_weights', ascending=False).head(n_weights)\n",
    "\n",
    "    # display using seaborn\n",
    "    ax=plt.subplots(figsize=(10,6))\n",
    "    ax=sns.barplot(data=sorted_weight_data, \n",
    "                   x=\"weights\", \n",
    "                   y=\"features\", \n",
    "                   palette=\"Blues_d\")\n",
    "    ax.set_title(\"PCA Component Makeup, Component #\" + str(component_num))\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# display makeup of first component\n",
    "num=2\n",
    "display_component(v, complete_df_scaled.columns.values, component_num=num, n_weights=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------------------------------------------------!CPU times: user 641 ms, sys: 39.6 ms, total: 681 ms\n",
      "Wall time: 10min 23s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# this takes a little while, around 7mins\n",
    "pca_predictor = pca_SM.deploy(initial_instance_count=1, \n",
    "                              instance_type='ml.t2.medium')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pass np train data to the PCA model\n",
    "train_pca = pca_predictor.predict(train_data_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label {\n",
      "  key: \"projection\"\n",
      "  value {\n",
      "    float32_tensor {\n",
      "      values: -1.1249656330721176e-22\n",
      "      values: 2.1187588572502136e-08\n",
      "      values: -1.1920928955078125e-07\n",
      "      values: 0.016339972615242004\n",
      "      values: 0.38833218812942505\n",
      "      values: -0.3004414737224579\n",
      "      values: 0.0002990206703543663\n",
      "      values: -1.8066493272781372\n",
      "      values: 0.0017964541912078857\n",
      "      values: -0.011685609817504883\n",
      "      values: -0.024074971675872803\n",
      "      values: -0.27337726950645447\n",
      "      values: 0.018803760409355164\n",
      "      values: -0.3498995900154114\n",
      "      values: 0.01664651930332184\n",
      "      values: 0.29070350527763367\n",
      "      values: -0.8751534223556519\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# check out the first item in the produced training features\n",
    "data_idx = 0\n",
    "print(train_pca[data_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dimensionality-reduced data\n",
    "def create_transformed_df(train_pca, complete_df_scaled, n_top_components):\n",
    "    ''' Return a dataframe of data points with component features. \n",
    "        The dataframe should be indexed by State-County and contain component values.\n",
    "        :param train_pca: A list of pca training data, returned by a PCA model.\n",
    "        :param counties_scaled: A dataframe of normalized, original features.\n",
    "        :param n_top_components: An integer, the number of top components to use.\n",
    "        :return: A dataframe, indexed by State-County, with n_top_component values as columns.        \n",
    "     '''\n",
    "    # create new dataframe to add data to\n",
    "    complete_df_transformed=pd.DataFrame()\n",
    "\n",
    "    # for each of our new, transformed data points\n",
    "    # append the component values to the dataframe\n",
    "    for data in train_pca:\n",
    "        # get component values for each data point\n",
    "        components=data.label['projection'].float32_tensor.values\n",
    "        complete_df_transformed=complete_df_transformed.append([list(components)])\n",
    "\n",
    "    # index by county, just like counties_scaled\n",
    "    complete_df_transformed.index=complete_df_scaled.index\n",
    "\n",
    "    # keep only the top n components\n",
    "    start_idx = N_COMPONENTS - n_top_components\n",
    "    complete_df_transformed = complete_df_transformed.iloc[:,start_idx:]\n",
    "    \n",
    "    # reverse columns, component order     \n",
    "    return complete_df_transformed.iloc[:, ::-1]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>16</th>\n",
       "      <th>15</th>\n",
       "      <th>14</th>\n",
       "      <th>13</th>\n",
       "      <th>12</th>\n",
       "      <th>11</th>\n",
       "      <th>10</th>\n",
       "      <th>9</th>\n",
       "      <th>8</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reward</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>-0.875153</td>\n",
       "      <td>0.290704</td>\n",
       "      <td>0.016647</td>\n",
       "      <td>-0.349900</td>\n",
       "      <td>0.018804</td>\n",
       "      <td>-0.273377</td>\n",
       "      <td>-0.024075</td>\n",
       "      <td>-0.011686</td>\n",
       "      <td>0.001796</td>\n",
       "      <td>-1.806649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>-0.875798</td>\n",
       "      <td>0.289780</td>\n",
       "      <td>0.019020</td>\n",
       "      <td>-0.370879</td>\n",
       "      <td>0.012160</td>\n",
       "      <td>-0.000923</td>\n",
       "      <td>0.011012</td>\n",
       "      <td>-0.016623</td>\n",
       "      <td>0.001993</td>\n",
       "      <td>-1.531856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>0.564316</td>\n",
       "      <td>0.347385</td>\n",
       "      <td>0.026364</td>\n",
       "      <td>-0.195777</td>\n",
       "      <td>0.015316</td>\n",
       "      <td>0.104043</td>\n",
       "      <td>0.025582</td>\n",
       "      <td>-0.014897</td>\n",
       "      <td>0.000152</td>\n",
       "      <td>-1.136095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>0.583126</td>\n",
       "      <td>0.347464</td>\n",
       "      <td>0.027340</td>\n",
       "      <td>-0.019561</td>\n",
       "      <td>0.015455</td>\n",
       "      <td>0.176939</td>\n",
       "      <td>0.033836</td>\n",
       "      <td>-0.018583</td>\n",
       "      <td>0.000161</td>\n",
       "      <td>-1.372197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>0.589939</td>\n",
       "      <td>0.347195</td>\n",
       "      <td>0.026816</td>\n",
       "      <td>0.047209</td>\n",
       "      <td>0.017309</td>\n",
       "      <td>0.119738</td>\n",
       "      <td>0.025892</td>\n",
       "      <td>-0.017890</td>\n",
       "      <td>-0.000356</td>\n",
       "      <td>0.000315</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              16        15        14        13        12        11        10  \\\n",
       "reward                                                                         \n",
       "0.0    -0.875153  0.290704  0.016647 -0.349900  0.018804 -0.273377 -0.024075   \n",
       "0.0    -0.875798  0.289780  0.019020 -0.370879  0.012160 -0.000923  0.011012   \n",
       "0.0     0.564316  0.347385  0.026364 -0.195777  0.015316  0.104043  0.025582   \n",
       "0.0     0.583126  0.347464  0.027340 -0.019561  0.015455  0.176939  0.033836   \n",
       "0.0     0.589939  0.347195  0.026816  0.047209  0.017309  0.119738  0.025892   \n",
       "\n",
       "              9         8         7   \n",
       "reward                                \n",
       "0.0    -0.011686  0.001796 -1.806649  \n",
       "0.0    -0.016623  0.001993 -1.531856  \n",
       "0.0    -0.014897  0.000152 -1.136095  \n",
       "0.0    -0.018583  0.000161 -1.372197  \n",
       "0.0    -0.017890 -0.000356  0.000315  "
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# specify top n\n",
    "top_n = 10\n",
    "\n",
    "# call your function and create a new dataframe\n",
    "complete_df_transformed = create_transformed_df(train_pca, complete_df_scaled, n_top_components=top_n)\n",
    "\n",
    "# add descriptive columns\n",
    "PCA_list=['c_1', 'c_2', 'c_3', 'c_4', 'c_5', 'c_6', 'c_7', 'c_8','c_9', 'c_10', 'c_11', 'c_12',\n",
    "         'c_13', 'c_14', 'c_15', 'c_16', 'c-17', 'c-18']\n",
    "complete_df.columns=PCA_list \n",
    "\n",
    "# print result\n",
    "complete_df_transformed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "ename": "ClientError",
     "evalue": "An error occurred (ValidationException) when calling the DeleteEndpoint operation: Could not find endpoint \"arn:aws:sagemaker:us-east-1:078540992053:endpoint/pca-2020-01-22-02-47-25-525\".",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mClientError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-90-0e46c8f1291c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete_endpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpca_predictor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/sagemaker/session.py\u001b[0m in \u001b[0;36mdelete_endpoint\u001b[0;34m(self, endpoint_name)\u001b[0m\n\u001b[1;32m   2377\u001b[0m         \"\"\"\n\u001b[1;32m   2378\u001b[0m         \u001b[0mLOGGER\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Deleting endpoint with name: %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mendpoint_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2379\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete_endpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEndpointName\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mendpoint_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2380\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2381\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdelete_endpoint_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mendpoint_config_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_api_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    355\u001b[0m                     \"%s() only accepts keyword arguments.\" % py_operation_name)\n\u001b[1;32m    356\u001b[0m             \u001b[0;31m# The \"self\" in this scope is referring to the BaseClient.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_api_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperation_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m         \u001b[0m_api_call\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpy_operation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_make_api_call\u001b[0;34m(self, operation_name, api_params)\u001b[0m\n\u001b[1;32m    659\u001b[0m             \u001b[0merror_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsed_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Error\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Code\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    660\u001b[0m             \u001b[0merror_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 661\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0merror_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparsed_response\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    662\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    663\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mparsed_response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mClientError\u001b[0m: An error occurred (ValidationException) when calling the DeleteEndpoint operation: Could not find endpoint \"arn:aws:sagemaker:us-east-1:078540992053:endpoint/pca-2020-01-22-02-47-25-525\"."
     ]
    }
   ],
   "source": [
    "session.delete_endpoint(pca_predictor.endpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>16</th>\n",
       "      <th>15</th>\n",
       "      <th>14</th>\n",
       "      <th>13</th>\n",
       "      <th>12</th>\n",
       "      <th>11</th>\n",
       "      <th>10</th>\n",
       "      <th>9</th>\n",
       "      <th>8</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reward</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>-0.001229</td>\n",
       "      <td>0.012851</td>\n",
       "      <td>0.009474</td>\n",
       "      <td>0.000395</td>\n",
       "      <td>-0.005026</td>\n",
       "      <td>-0.003518</td>\n",
       "      <td>0.024273</td>\n",
       "      <td>-0.000285</td>\n",
       "      <td>0.000604</td>\n",
       "      <td>1.306037e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>0.030312</td>\n",
       "      <td>-0.607465</td>\n",
       "      <td>-0.444868</td>\n",
       "      <td>-0.058464</td>\n",
       "      <td>0.263505</td>\n",
       "      <td>0.126265</td>\n",
       "      <td>-0.992725</td>\n",
       "      <td>0.029620</td>\n",
       "      <td>-0.308729</td>\n",
       "      <td>2.065682e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>0.006646</td>\n",
       "      <td>-0.615001</td>\n",
       "      <td>-0.454918</td>\n",
       "      <td>-0.032553</td>\n",
       "      <td>0.279748</td>\n",
       "      <td>0.210777</td>\n",
       "      <td>-1.022304</td>\n",
       "      <td>-0.001629</td>\n",
       "      <td>-0.218129</td>\n",
       "      <td>-2.646264e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.0</th>\n",
       "      <td>-0.053651</td>\n",
       "      <td>-0.581267</td>\n",
       "      <td>-0.413485</td>\n",
       "      <td>0.029592</td>\n",
       "      <td>0.170364</td>\n",
       "      <td>0.153626</td>\n",
       "      <td>-1.139407</td>\n",
       "      <td>0.001043</td>\n",
       "      <td>-0.037930</td>\n",
       "      <td>-5.463313e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10.0</th>\n",
       "      <td>0.264509</td>\n",
       "      <td>-0.596979</td>\n",
       "      <td>-0.461871</td>\n",
       "      <td>-0.028247</td>\n",
       "      <td>0.252919</td>\n",
       "      <td>0.183936</td>\n",
       "      <td>-1.334439</td>\n",
       "      <td>0.021978</td>\n",
       "      <td>0.414357</td>\n",
       "      <td>6.236663e-05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              16        15        14        13        12        11        10  \\\n",
       "reward                                                                         \n",
       "0.0    -0.001229  0.012851  0.009474  0.000395 -0.005026 -0.003518  0.024273   \n",
       "2.0     0.030312 -0.607465 -0.444868 -0.058464  0.263505  0.126265 -0.992725   \n",
       "3.0     0.006646 -0.615001 -0.454918 -0.032553  0.279748  0.210777 -1.022304   \n",
       "5.0    -0.053651 -0.581267 -0.413485  0.029592  0.170364  0.153626 -1.139407   \n",
       "10.0    0.264509 -0.596979 -0.461871 -0.028247  0.252919  0.183936 -1.334439   \n",
       "\n",
       "              9         8             7   \n",
       "reward                                    \n",
       "0.0    -0.000285  0.000604  1.306037e-07  \n",
       "2.0     0.029620 -0.308729  2.065682e-06  \n",
       "3.0    -0.001629 -0.218129 -2.646264e-05  \n",
       "5.0     0.001043 -0.037930 -5.463313e-05  \n",
       "10.0    0.021978  0.414357  6.236663e-05  "
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complete_df_transformed.groupby(['reward']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['difficulty', 'duration', 'reward type', 'age', 'income', 'time',\n",
       "       'F', 'M', 'O', 'offer completed', 'offer received', 'offer viewed',\n",
       "       'transaction', 'bogo', 'discount', 'informational', 'amount',\n",
       "       'reward'], dtype=object)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using the top 7 components, we can develop a multi-classification model using the XGBOOST algorithmn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>difficulty</th>\n",
       "      <th>duration</th>\n",
       "      <th>reward type</th>\n",
       "      <th>age</th>\n",
       "      <th>income</th>\n",
       "      <th>time</th>\n",
       "      <th>F</th>\n",
       "      <th>M</th>\n",
       "      <th>O</th>\n",
       "      <th>offer completed</th>\n",
       "      <th>offer received</th>\n",
       "      <th>offer viewed</th>\n",
       "      <th>transaction</th>\n",
       "      <th>bogo</th>\n",
       "      <th>discount</th>\n",
       "      <th>informational</th>\n",
       "      <th>amount</th>\n",
       "      <th>reward</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>112000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>53000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>51000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    difficulty  duration  reward type   age    income  time  F  M  O  \\\n",
       "1         10.0       5.0         10.0  55.0  112000.0     0  1  0  0   \n",
       "3          5.0       7.0          5.0  75.0  100000.0     0  1  0  0   \n",
       "5          7.0       7.0          3.0  68.0   70000.0     0  0  1  0   \n",
       "8          5.0       5.0          5.0  65.0   53000.0     0  0  1  0   \n",
       "12         0.0       0.0          0.0  58.0   51000.0     0  0  1  0   \n",
       "\n",
       "    offer completed  offer received  offer viewed  transaction  bogo  \\\n",
       "1                 0               1             0            0     1   \n",
       "3                 0               1             0            0     1   \n",
       "5                 0               1             0            0     0   \n",
       "8                 0               1             0            0     1   \n",
       "12                0               1             0            0     0   \n",
       "\n",
       "    discount  informational  amount  reward  \n",
       "1          0              0     0.0     0.0  \n",
       "3          0              0     0.0     0.0  \n",
       "5          1              0     0.0     0.0  \n",
       "8          0              0     0.0     0.0  \n",
       "12         0              0     0.0     0.0  "
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#we can use the same transformed dataframe from the PCA analysis or go back to the original dataframe and use that with only\n",
    "#the top 7 features. These are\"\n",
    "#offer completed\n",
    "#offer received\n",
    "#offer viewed\n",
    "#transaction\n",
    "#bogo\n",
    "#discount\n",
    "#informaitonal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop uneeded data\n",
    "complete_df_mC = complete_df[['offer completed', 'offer received', 'offer viewed', 'transaction', 'bogo', 'discount', \n",
    "                              'informational', 'reward']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>offer completed</th>\n",
       "      <th>offer received</th>\n",
       "      <th>offer viewed</th>\n",
       "      <th>transaction</th>\n",
       "      <th>bogo</th>\n",
       "      <th>discount</th>\n",
       "      <th>informational</th>\n",
       "      <th>reward</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16963</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16964</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16965</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16966</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16967</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16968</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16970</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16971</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16972</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16973</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16974</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16975</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16976</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16978</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16979</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16981</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16983</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16984</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16985</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16986</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16987</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16988</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16990</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16992</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16993</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16995</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16996</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16997</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16998</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16999</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14825 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       offer completed  offer received  offer viewed  transaction  bogo  \\\n",
       "1                    0               1             0            0     1   \n",
       "3                    0               1             0            0     1   \n",
       "5                    0               1             0            0     0   \n",
       "8                    0               1             0            0     1   \n",
       "12                   0               1             0            0     0   \n",
       "13                   0               1             0            0     0   \n",
       "14                   0               1             0            0     0   \n",
       "15                   0               1             0            0     0   \n",
       "16                   0               1             0            0     0   \n",
       "18                   0               1             0            0     0   \n",
       "19                   0               1             0            0     0   \n",
       "20                   0               1             0            0     0   \n",
       "21                   0               1             0            0     0   \n",
       "22                   0               1             0            0     0   \n",
       "24                   0               1             0            0     0   \n",
       "25                   0               1             0            0     0   \n",
       "27                   0               1             0            0     0   \n",
       "28                   0               1             0            0     0   \n",
       "29                   0               1             0            0     0   \n",
       "30                   0               1             0            0     0   \n",
       "31                   0               1             0            0     0   \n",
       "32                   0               1             0            0     0   \n",
       "33                   0               1             0            0     0   \n",
       "34                   0               1             0            0     0   \n",
       "35                   0               1             0            0     0   \n",
       "37                   0               1             0            0     0   \n",
       "38                   0               1             0            0     0   \n",
       "40                   0               1             0            0     0   \n",
       "41                   0               1             0            0     0   \n",
       "42                   0               1             0            0     0   \n",
       "...                ...             ...           ...          ...   ...   \n",
       "16963                0               0             1            0     0   \n",
       "16964                0               0             1            0     0   \n",
       "16965                0               0             1            0     0   \n",
       "16966                0               0             0            1     0   \n",
       "16967                1               0             0            0     0   \n",
       "16968                0               0             1            0     0   \n",
       "16970                0               0             0            1     0   \n",
       "16971                0               0             1            0     0   \n",
       "16972                0               0             1            0     0   \n",
       "16973                0               0             1            0     0   \n",
       "16974                0               0             1            0     0   \n",
       "16975                0               0             1            0     0   \n",
       "16976                0               0             1            0     0   \n",
       "16978                0               0             1            0     0   \n",
       "16979                0               0             1            0     0   \n",
       "16981                0               0             1            0     0   \n",
       "16983                0               0             1            0     0   \n",
       "16984                0               0             0            1     0   \n",
       "16985                0               0             1            0     0   \n",
       "16986                0               0             1            0     0   \n",
       "16987                0               0             1            0     0   \n",
       "16988                0               0             1            0     0   \n",
       "16990                0               0             0            1     0   \n",
       "16992                0               0             0            1     0   \n",
       "16993                1               0             0            0     0   \n",
       "16995                0               0             1            0     0   \n",
       "16996                0               0             1            0     0   \n",
       "16997                0               0             0            1     0   \n",
       "16998                1               0             0            0     0   \n",
       "16999                0               0             1            0     0   \n",
       "\n",
       "       discount  informational  reward  \n",
       "1             0              0     0.0  \n",
       "3             0              0     0.0  \n",
       "5             1              0     0.0  \n",
       "8             0              0     0.0  \n",
       "12            0              0     0.0  \n",
       "13            0              0     0.0  \n",
       "14            0              0     0.0  \n",
       "15            0              0     0.0  \n",
       "16            0              0     0.0  \n",
       "18            0              0     0.0  \n",
       "19            0              0     0.0  \n",
       "20            0              0     0.0  \n",
       "21            0              0     0.0  \n",
       "22            0              0     0.0  \n",
       "24            0              0     0.0  \n",
       "25            0              0     0.0  \n",
       "27            0              0     0.0  \n",
       "28            0              0     0.0  \n",
       "29            0              0     0.0  \n",
       "30            0              0     0.0  \n",
       "31            0              0     0.0  \n",
       "32            0              0     0.0  \n",
       "33            0              0     0.0  \n",
       "34            0              0     0.0  \n",
       "35            0              0     0.0  \n",
       "37            0              0     0.0  \n",
       "38            0              0     0.0  \n",
       "40            0              0     0.0  \n",
       "41            0              0     0.0  \n",
       "42            0              0     0.0  \n",
       "...         ...            ...     ...  \n",
       "16963         0              0     0.0  \n",
       "16964         0              0     0.0  \n",
       "16965         0              0     0.0  \n",
       "16966         0              0     0.0  \n",
       "16967         0              0     5.0  \n",
       "16968         0              0     0.0  \n",
       "16970         0              0     0.0  \n",
       "16971         0              0     0.0  \n",
       "16972         0              0     0.0  \n",
       "16973         0              0     0.0  \n",
       "16974         0              0     0.0  \n",
       "16975         0              0     0.0  \n",
       "16976         0              0     0.0  \n",
       "16978         0              0     0.0  \n",
       "16979         0              0     0.0  \n",
       "16981         0              0     0.0  \n",
       "16983         0              0     0.0  \n",
       "16984         0              0     0.0  \n",
       "16985         0              0     0.0  \n",
       "16986         0              0     0.0  \n",
       "16987         0              0     0.0  \n",
       "16988         0              0     0.0  \n",
       "16990         0              0     0.0  \n",
       "16992         0              0     0.0  \n",
       "16993         0              0     2.0  \n",
       "16995         0              0     0.0  \n",
       "16996         0              0     0.0  \n",
       "16997         0              0     0.0  \n",
       "16998         0              0     5.0  \n",
       "16999         0              0     0.0  \n",
       "\n",
       "[14825 rows x 8 columns]"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check dataframe\n",
    "complete_df_mC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0     14513\n",
       "5.0       100\n",
       "2.0        82\n",
       "10.0       77\n",
       "3.0        53\n",
       "Name: reward, dtype: int64"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complete_df_mC['reward'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/ipykernel/__main__.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    14513\n",
       "3      100\n",
       "1       82\n",
       "4       77\n",
       "2       53\n",
       "Name: reward, dtype: int64"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#organize classes into sequential integers (0 = 0, 1 = 2, 2 = 3, 3 = 5, 4 = 10)\n",
    "complete_df_mC['reward'] = complete_df_mC['reward'].apply(lambda x: 4 if x==10 else 1 if x == 2 else 2 if x==3 else\n",
    "                                                   3 if x == 5 else 0)\n",
    "complete_df_mC['reward'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/ipykernel/__main__.py:3: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "#this modified a template from here: https://aws.amazon.com/blogs/machine-learning/build-multiclass-classifiers-with-amazon-sagemaker-linear-learner/\n",
    "\n",
    "r_type = complete_df_mC.as_matrix().astype(np.float32)\n",
    "r_type_features, r_labels = r_type[:, 7], r_type[:, :7]\n",
    "# shuffle and split into train and test sets\n",
    "np.random.seed(0)\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(\n",
    "    r_type_features, r_labels, test_size=0.2)\n",
    "# further split the test set into validation and test sets\n",
    "val_features, test_features, val_labels, test_labels = train_test_split(\n",
    "    test_features, test_labels, test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 353,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker.amazon.amazon_estimator import RecordSet\n",
    "import boto3\n",
    "\n",
    "# instantiate the LinearLearner estimator object\n",
    "multiclass_estimator = sagemaker.LinearLearner(role=sagemaker.get_execution_role(),\n",
    "                                               train_instance_count=1,\n",
    "                                               train_instance_type='ml.m4.xlarge',\n",
    "                                               predictor_type='multiclass_classifier',\n",
    "                                               num_classes=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "#wrap data in RecordSet objects\n",
    "train_records = multiclass_estimator.record_set(train_features, train_labels, channel='train')\n",
    "val_records = multiclass_estimator.record_set(val_features, val_labels, channel='validation')\n",
    "test_records = multiclass_estimator.record_set(test_features, test_labels, channel='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f130493eac8>"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# assign label names and count label frequencies\n",
    "label_map = {0:'$0 Reward', 1:'$2 Reward', 2:'$3 Reward', 3:'$5 Reward', \n",
    "             4:'$10 Reward'}\n",
    "label_counts = pd.DataFrame(data=train_labels)[0].map(label_map).value_counts(sort=False).sort_index(ascending=False)\n",
    "label_counts.plot('barh', color='tomato', title='Label Counts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-01-29 18:33:06 Starting - Starting the training job......\n",
      "2020-01-29 18:33:37 Starting - Launching requested ML instances......\n",
      "2020-01-29 18:34:48 Starting - Preparing the instances for training......\n",
      "2020-01-29 18:35:54 Downloading - Downloading input data...\n",
      "2020-01-29 18:36:32 Training - Downloading the training image...\n",
      "2020-01-29 18:37:03 Uploading - Uploading generated training model\u001b[34mDocker entrypoint called with argument(s): train\u001b[0m\n",
      "\u001b[34m[01/29/2020 18:36:55 INFO 139893492320064] Reading default configuration from /opt/amazon/lib/python2.7/site-packages/algorithm/resources/default-input.json: {u'loss_insensitivity': u'0.01', u'epochs': u'15', u'feature_dim': u'auto', u'init_bias': u'0.0', u'lr_scheduler_factor': u'auto', u'num_calibration_samples': u'10000000', u'accuracy_top_k': u'3', u'_num_kv_servers': u'auto', u'use_bias': u'true', u'num_point_for_scaler': u'10000', u'_log_level': u'info', u'quantile': u'0.5', u'bias_lr_mult': u'auto', u'lr_scheduler_step': u'auto', u'init_method': u'uniform', u'init_sigma': u'0.01', u'lr_scheduler_minimum_lr': u'auto', u'target_recall': u'0.8', u'num_models': u'auto', u'early_stopping_patience': u'3', u'momentum': u'auto', u'unbias_label': u'auto', u'wd': u'auto', u'optimizer': u'auto', u'_tuning_objective_metric': u'', u'early_stopping_tolerance': u'0.001', u'learning_rate': u'auto', u'_kvstore': u'auto', u'normalize_data': u'true', u'binary_classifier_model_selection_criteria': u'accuracy', u'use_lr_scheduler': u'true', u'target_precision': u'0.8', u'unbias_data': u'auto', u'init_scale': u'0.07', u'bias_wd_mult': u'auto', u'f_beta': u'1.0', u'mini_batch_size': u'1000', u'huber_delta': u'1.0', u'num_classes': u'1', u'beta_1': u'auto', u'loss': u'auto', u'beta_2': u'auto', u'_enable_profiler': u'false', u'normalize_label': u'auto', u'_num_gpus': u'auto', u'balance_multiclass_weights': u'false', u'positive_example_weight_mult': u'1.0', u'l1': u'auto', u'margin': u'1.0'}\u001b[0m\n",
      "\u001b[34m[01/29/2020 18:36:55 INFO 139893492320064] Reading provided configuration from /opt/ml/input/config/hyperparameters.json: {u'feature_dim': u'7', u'mini_batch_size': u'1000', u'predictor_type': u'multiclass_classifier', u'num_classes': u'5'}\u001b[0m\n",
      "\u001b[34m[01/29/2020 18:36:55 INFO 139893492320064] Final configuration: {u'loss_insensitivity': u'0.01', u'epochs': u'15', u'feature_dim': u'7', u'init_bias': u'0.0', u'lr_scheduler_factor': u'auto', u'num_calibration_samples': u'10000000', u'accuracy_top_k': u'3', u'_num_kv_servers': u'auto', u'use_bias': u'true', u'num_point_for_scaler': u'10000', u'_log_level': u'info', u'quantile': u'0.5', u'bias_lr_mult': u'auto', u'lr_scheduler_step': u'auto', u'init_method': u'uniform', u'init_sigma': u'0.01', u'lr_scheduler_minimum_lr': u'auto', u'target_recall': u'0.8', u'num_models': u'auto', u'early_stopping_patience': u'3', u'momentum': u'auto', u'unbias_label': u'auto', u'wd': u'auto', u'optimizer': u'auto', u'_tuning_objective_metric': u'', u'early_stopping_tolerance': u'0.001', u'learning_rate': u'auto', u'_kvstore': u'auto', u'normalize_data': u'true', u'binary_classifier_model_selection_criteria': u'accuracy', u'use_lr_scheduler': u'true', u'target_precision': u'0.8', u'unbias_data': u'auto', u'init_scale': u'0.07', u'bias_wd_mult': u'auto', u'f_beta': u'1.0', u'mini_batch_size': u'1000', u'huber_delta': u'1.0', u'num_classes': u'5', u'predictor_type': u'multiclass_classifier', u'beta_1': u'auto', u'loss': u'auto', u'beta_2': u'auto', u'_enable_profiler': u'false', u'normalize_label': u'auto', u'_num_gpus': u'auto', u'balance_multiclass_weights': u'false', u'positive_example_weight_mult': u'1.0', u'l1': u'auto', u'margin': u'1.0'}\u001b[0m\n",
      "\u001b[34m[01/29/2020 18:36:55 WARNING 139893492320064] Loggers have already been setup.\u001b[0m\n",
      "\u001b[34mProcess 1 is a worker.\u001b[0m\n",
      "\u001b[34m[01/29/2020 18:36:55 INFO 139893492320064] Using default worker.\u001b[0m\n",
      "\u001b[34m[2020-01-29 18:36:55.742] [tensorio] [warning] TensorIO is already initialized; ignoring the initialization routine.\u001b[0m\n",
      "\u001b[34m[2020-01-29 18:36:55.745] [tensorio] [warning] TensorIO is already initialized; ignoring the initialization routine.\u001b[0m\n",
      "\u001b[34m[2020-01-29 18:36:55.766] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 0, \"duration\": 27, \"num_examples\": 1, \"num_bytes\": 72000}\u001b[0m\n",
      "\u001b[34m[01/29/2020 18:36:55 INFO 139893492320064] Create Store: local\u001b[0m\n",
      "\u001b[34m[2020-01-29 18:36:55.808] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 1, \"duration\": 41, \"num_examples\": 11, \"num_bytes\": 792000}\u001b[0m\n",
      "\u001b[34m[01/29/2020 18:36:55 INFO 139893492320064] Scaler algorithm parameters\n",
      " <algorithm.scaler.ScalerAlgorithmStable object at 0x7f3b2ca97410>\u001b[0m\n",
      "\u001b[34m[01/29/2020 18:36:55 INFO 139893492320064] Scaling model computed with parameters:\n",
      " {'stdev_weight': \u001b[0m\n",
      "\u001b[34m[0.14185676 0.43555418 0.375233   0.24539958 0.0165122  0.00953419\n",
      " 1.        ]\u001b[0m\n",
      "\u001b[34m<NDArray 7 @cpu(0)>, 'stdev_label': None, 'mean_label': None, 'mean_weight': \u001b[0m\n",
      "\u001b[34m[2.0545455e-02 7.4554539e-01 1.6954546e-01 6.4363636e-02 2.7272728e-04\n",
      " 9.0909089e-05 0.0000000e+00]\u001b[0m\n",
      "\u001b[34m<NDArray 7 @cpu(0)>}\u001b[0m\n",
      "\u001b[34m[01/29/2020 18:36:55 INFO 139893492320064] nvidia-smi took: 0.0251820087433 secs to identify 0 gpus\u001b[0m\n",
      "\u001b[34m[01/29/2020 18:36:55 INFO 139893492320064] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 11, \"sum\": 11.0, \"min\": 11}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Batches Seen\": {\"count\": 1, \"max\": 12, \"sum\": 12.0, \"min\": 12}, \"Total Records Seen\": {\"count\": 1, \"max\": 12000, \"sum\": 12000.0, \"min\": 12000}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 11000, \"sum\": 11000.0, \"min\": 11000}, \"Reset Count\": {\"count\": 1, \"max\": 2, \"sum\": 2.0, \"min\": 2}}, \"EndTime\": 1580323015.908249, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"init_train_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\"}, \"StartTime\": 1580323015.908211}\n",
      "\u001b[0m\n",
      "\u001b[34m[2020-01-29 18:36:56.205] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 3, \"duration\": 296, \"num_examples\": 12, \"num_bytes\": 853920}\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.6306527488014915, \"sum\": 0.6306527488014915, \"min\": 0.6306527488014915}}, \"EndTime\": 1580323016.205213, \"Dimensions\": {\"model\": 0, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 0}, \"StartTime\": 1580323016.205149}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 1.2195177112926137, \"sum\": 1.2195177112926137, \"min\": 1.2195177112926137}}, \"EndTime\": 1580323016.205315, \"Dimensions\": {\"model\": 1, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 0}, \"StartTime\": 1580323016.205299}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 1.2009885531338778, \"sum\": 1.2009885531338778, \"min\": 1.2009885531338778}}, \"EndTime\": 1580323016.205375, \"Dimensions\": {\"model\": 2, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 0}, \"StartTime\": 1580323016.205362}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 1.140935263893821, \"sum\": 1.140935263893821, \"min\": 1.140935263893821}}, \"EndTime\": 1580323016.205423, \"Dimensions\": {\"model\": 3, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 0}, \"StartTime\": 1580323016.205411}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 1.398394864169034, \"sum\": 1.398394864169034, \"min\": 1.398394864169034}}, \"EndTime\": 1580323016.205475, \"Dimensions\": {\"model\": 4, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 0}, \"StartTime\": 1580323016.205462}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.4853929054953835, \"sum\": 0.4853929054953835, \"min\": 0.4853929054953835}}, \"EndTime\": 1580323016.205524, \"Dimensions\": {\"model\": 5, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 0}, \"StartTime\": 1580323016.205513}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 1.2954177634499289, \"sum\": 1.2954177634499289, \"min\": 1.2954177634499289}}, \"EndTime\": 1580323016.20557, \"Dimensions\": {\"model\": 6, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 0}, \"StartTime\": 1580323016.205559}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 1.4792570245916192, \"sum\": 1.4792570245916192, \"min\": 1.4792570245916192}}, \"EndTime\": 1580323016.20562, \"Dimensions\": {\"model\": 7, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 0}, \"StartTime\": 1580323016.205608}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.2282693679115989, \"sum\": 0.2282693679115989, \"min\": 0.2282693679115989}}, \"EndTime\": 1580323016.205666, \"Dimensions\": {\"model\": 8, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 0}, \"StartTime\": 1580323016.205655}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.502622876253995, \"sum\": 0.502622876253995, \"min\": 0.502622876253995}}, \"EndTime\": 1580323016.205711, \"Dimensions\": {\"model\": 9, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 0}, \"StartTime\": 1580323016.2057}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 1.502889892578125, \"sum\": 1.502889892578125, \"min\": 1.502889892578125}}, \"EndTime\": 1580323016.205761, \"Dimensions\": {\"model\": 10, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 0}, \"StartTime\": 1580323016.205749}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.8233177989612926, \"sum\": 0.8233177989612926, \"min\": 0.8233177989612926}}, \"EndTime\": 1580323016.205806, \"Dimensions\": {\"model\": 11, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 0}, \"StartTime\": 1580323016.205795}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.58912165555087, \"sum\": 0.58912165555087, \"min\": 0.58912165555087}}, \"EndTime\": 1580323016.205857, \"Dimensions\": {\"model\": 12, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 0}, \"StartTime\": 1580323016.205845}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 1.1915836348100142, \"sum\": 1.1915836348100142, \"min\": 1.1915836348100142}}, \"EndTime\": 1580323016.205901, \"Dimensions\": {\"model\": 13, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 0}, \"StartTime\": 1580323016.20589}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.8290439730557528, \"sum\": 0.8290439730557528, \"min\": 0.8290439730557528}}, \"EndTime\": 1580323016.205945, \"Dimensions\": {\"model\": 14, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 0}, \"StartTime\": 1580323016.205934}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/29/2020 18:36:56 INFO 139893492320064] #quality_metric: host=algo-1, epoch=0, train multiclass_cross_entropy_objective <loss>=0.630652748801\u001b[0m\n",
      "\u001b[34m[2020-01-29 18:36:56.214] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/validation\", \"epoch\": 0, \"duration\": 472, \"num_examples\": 1, \"num_bytes\": 72000}\u001b[0m\n",
      "\u001b[34m[2020-01-29 18:36:56.239] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/validation\", \"epoch\": 2, \"duration\": 24, \"num_examples\": 2, \"num_bytes\": 106704}\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.1105917159684113, \"sum\": 0.1105917159684113, \"min\": 0.1105917159684113}}, \"EndTime\": 1580323016.242308, \"Dimensions\": {\"model\": 0, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 0}, \"StartTime\": 1580323016.242269}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.9234449667164832, \"sum\": 0.9234449667164832, \"min\": 0.9234449667164832}}, \"EndTime\": 1580323016.242372, \"Dimensions\": {\"model\": 1, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 0}, \"StartTime\": 1580323016.242358}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.7762252045707342, \"sum\": 0.7762252045707342, \"min\": 0.7762252045707342}}, \"EndTime\": 1580323016.242414, \"Dimensions\": {\"model\": 2, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 0}, \"StartTime\": 1580323016.242404}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.790799077866692, \"sum\": 0.790799077866692, \"min\": 0.790799077866692}}, \"EndTime\": 1580323016.242448, \"Dimensions\": {\"model\": 3, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 0}, \"StartTime\": 1580323016.242439}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 1.162286632295884, \"sum\": 1.162286632295884, \"min\": 1.162286632295884}}, \"EndTime\": 1580323016.24249, \"Dimensions\": {\"model\": 4, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 0}, \"StartTime\": 1580323016.242476}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.14409391889687975, \"sum\": 0.14409391889687975, \"min\": 0.14409391889687975}}, \"EndTime\": 1580323016.242553, \"Dimensions\": {\"model\": 5, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 0}, \"StartTime\": 1580323016.242537}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.9547288408163588, \"sum\": 0.9547288408163588, \"min\": 0.9547288408163588}}, \"EndTime\": 1580323016.242616, \"Dimensions\": {\"model\": 6, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 0}, \"StartTime\": 1580323016.242598}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 1.3129211096306723, \"sum\": 1.3129211096306723, \"min\": 1.3129211096306723}}, \"EndTime\": 1580323016.242686, \"Dimensions\": {\"model\": 7, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 0}, \"StartTime\": 1580323016.242668}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.04413283112560689, \"sum\": 0.04413283112560689, \"min\": 0.04413283112560689}}, \"EndTime\": 1580323016.242756, \"Dimensions\": {\"model\": 8, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 0}, \"StartTime\": 1580323016.242738}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.15056401097018388, \"sum\": 0.15056401097018388, \"min\": 0.15056401097018388}}, \"EndTime\": 1580323016.242828, \"Dimensions\": {\"model\": 9, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 0}, \"StartTime\": 1580323016.242809}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 1.3700635655206224, \"sum\": 1.3700635655206224, \"min\": 1.3700635655206224}}, \"EndTime\": 1580323016.24289, \"Dimensions\": {\"model\": 10, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 0}, \"StartTime\": 1580323016.242873}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.4081121591421274, \"sum\": 0.4081121591421274, \"min\": 0.4081121591421274}}, \"EndTime\": 1580323016.242949, \"Dimensions\": {\"model\": 11, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 0}, \"StartTime\": 1580323016.242938}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.0973352723115208, \"sum\": 0.0973352723115208, \"min\": 0.0973352723115208}}, \"EndTime\": 1580323016.243005, \"Dimensions\": {\"model\": 12, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 0}, \"StartTime\": 1580323016.242989}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.8727008031930036, \"sum\": 0.8727008031930036, \"min\": 0.8727008031930036}}, \"EndTime\": 1580323016.243066, \"Dimensions\": {\"model\": 13, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 0}, \"StartTime\": 1580323016.24305}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.254523489639344, \"sum\": 0.254523489639344, \"min\": 0.254523489639344}}, \"EndTime\": 1580323016.243135, \"Dimensions\": {\"model\": 14, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 0}, \"StartTime\": 1580323016.243117}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/29/2020 18:36:56 INFO 139893492320064] #quality_metric: host=algo-1, epoch=0, validation multiclass_cross_entropy_objective <loss>=0.110591715968\u001b[0m\n",
      "\u001b[34m[01/29/2020 18:36:56 INFO 139893492320064] #early_stopping_criteria_metric: host=algo-1, epoch=0, criteria=multiclass_cross_entropy_objective, value=0.0441328311256\u001b[0m\n",
      "\u001b[34m[01/29/2020 18:36:56 INFO 139893492320064] Epoch 0: Loss improved. Updating best model\u001b[0m\n",
      "\u001b[34m[01/29/2020 18:36:56 INFO 139893492320064] #progress_metric: host=algo-1, completed 6 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 12, \"sum\": 12.0, \"min\": 12}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 12, \"sum\": 12.0, \"min\": 12}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 11860, \"sum\": 11860.0, \"min\": 11860}, \"Total Batches Seen\": {\"count\": 1, \"max\": 24, \"sum\": 24.0, \"min\": 24}, \"Total Records Seen\": {\"count\": 1, \"max\": 23860, \"sum\": 23860.0, \"min\": 23860}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 11860, \"sum\": 11860.0, \"min\": 11860}, \"Reset Count\": {\"count\": 1, \"max\": 3, \"sum\": 3.0, \"min\": 3}}, \"EndTime\": 1580323016.244631, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 0}, \"StartTime\": 1580323015.908441}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/29/2020 18:36:56 INFO 139893492320064] #throughput_metric: host=algo-1, train throughput=35266.3423266 records/second\u001b[0m\n",
      "\u001b[34m[2020-01-29 18:36:56.496] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 5, \"duration\": 251, \"num_examples\": 12, \"num_bytes\": 853920}\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.0662231164412065, \"sum\": 0.0662231164412065, \"min\": 0.0662231164412065}}, \"EndTime\": 1580323016.496785, \"Dimensions\": {\"model\": 0, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 1}, \"StartTime\": 1580323016.496723}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.7786490256569603, \"sum\": 0.7786490256569603, \"min\": 0.7786490256569603}}, \"EndTime\": 1580323016.496876, \"Dimensions\": {\"model\": 1, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 1}, \"StartTime\": 1580323016.496859}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.5620783580433238, \"sum\": 0.5620783580433238, \"min\": 0.5620783580433238}}, \"EndTime\": 1580323016.496929, \"Dimensions\": {\"model\": 2, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 1}, \"StartTime\": 1580323016.496916}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.6412420654296875, \"sum\": 0.6412420654296875, \"min\": 0.6412420654296875}}, \"EndTime\": 1580323016.496978, \"Dimensions\": {\"model\": 3, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 1}, \"StartTime\": 1580323016.496966}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.9992504272460937, \"sum\": 0.9992504272460937, \"min\": 0.9992504272460937}}, \"EndTime\": 1580323016.497024, \"Dimensions\": {\"model\": 4, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 1}, \"StartTime\": 1580323016.497012}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.10042519656094638, \"sum\": 0.10042519656094638, \"min\": 0.10042519656094638}}, \"EndTime\": 1580323016.497074, \"Dimensions\": {\"model\": 5, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 1}, \"StartTime\": 1580323016.497062}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.7491186800870029, \"sum\": 0.7491186800870029, \"min\": 0.7491186800870029}}, \"EndTime\": 1580323016.497123, \"Dimensions\": {\"model\": 6, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 1}, \"StartTime\": 1580323016.497111}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 1.1927854669744318, \"sum\": 1.1927854669744318, \"min\": 1.1927854669744318}}, \"EndTime\": 1580323016.497169, \"Dimensions\": {\"model\": 7, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 1}, \"StartTime\": 1580323016.497157}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.041798426368019795, \"sum\": 0.041798426368019795, \"min\": 0.041798426368019795}}, \"EndTime\": 1580323016.49722, \"Dimensions\": {\"model\": 8, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 1}, \"StartTime\": 1580323016.497208}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.10724603826349431, \"sum\": 0.10724603826349431, \"min\": 0.10724603826349431}}, \"EndTime\": 1580323016.497272, \"Dimensions\": {\"model\": 9, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 1}, \"StartTime\": 1580323016.49726}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 1.2708525834517046, \"sum\": 1.2708525834517046, \"min\": 1.2708525834517046}}, \"EndTime\": 1580323016.497318, \"Dimensions\": {\"model\": 10, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 1}, \"StartTime\": 1580323016.497307}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.2923381250554865, \"sum\": 0.2923381250554865, \"min\": 0.2923381250554865}}, \"EndTime\": 1580323016.497363, \"Dimensions\": {\"model\": 11, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 1}, \"StartTime\": 1580323016.497352}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.061670759027654475, \"sum\": 0.061670759027654475, \"min\": 0.061670759027654475}}, \"EndTime\": 1580323016.497413, \"Dimensions\": {\"model\": 12, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 1}, \"StartTime\": 1580323016.497401}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.7273576993075284, \"sum\": 0.7273576993075284, \"min\": 0.7273576993075284}}, \"EndTime\": 1580323016.497464, \"Dimensions\": {\"model\": 13, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 1}, \"StartTime\": 1580323016.497452}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.14344870549982244, \"sum\": 0.14344870549982244, \"min\": 0.14344870549982244}}, \"EndTime\": 1580323016.497511, \"Dimensions\": {\"model\": 14, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 1}, \"StartTime\": 1580323016.4975}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/29/2020 18:36:56 INFO 139893492320064] #quality_metric: host=algo-1, epoch=1, train multiclass_cross_entropy_objective <loss>=0.0662231164412\u001b[0m\n",
      "\u001b[34m[2020-01-29 18:36:56.534] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/validation\", \"epoch\": 5, \"duration\": 27, \"num_examples\": 2, \"num_bytes\": 106704}\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.04854070738098721, \"sum\": 0.04854070738098721, \"min\": 0.04854070738098721}}, \"EndTime\": 1580323016.53921, \"Dimensions\": {\"model\": 0, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 1}, \"StartTime\": 1580323016.539167}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.6303923654491924, \"sum\": 0.6303923654491924, \"min\": 0.6303923654491924}}, \"EndTime\": 1580323016.539319, \"Dimensions\": {\"model\": 1, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 1}, \"StartTime\": 1580323016.539301}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.3565987652612601, \"sum\": 0.3565987652612601, \"min\": 0.3565987652612601}}, \"EndTime\": 1580323016.539395, \"Dimensions\": {\"model\": 2, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 1}, \"StartTime\": 1580323016.539374}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.4860453225983943, \"sum\": 0.4860453225983943, \"min\": 0.4860453225983943}}, \"EndTime\": 1580323016.539465, \"Dimensions\": {\"model\": 3, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 1}, \"StartTime\": 1580323016.539445}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.8250932783572137, \"sum\": 0.8250932783572137, \"min\": 0.8250932783572137}}, \"EndTime\": 1580323016.539533, \"Dimensions\": {\"model\": 4, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 1}, \"StartTime\": 1580323016.539514}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.07634284396564107, \"sum\": 0.07634284396564107, \"min\": 0.07634284396564107}}, \"EndTime\": 1580323016.539593, \"Dimensions\": {\"model\": 5, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 1}, \"StartTime\": 1580323016.539577}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.5432646593101594, \"sum\": 0.5432646593101594, \"min\": 0.5432646593101594}}, \"EndTime\": 1580323016.539634, \"Dimensions\": {\"model\": 6, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 1}, \"StartTime\": 1580323016.539619}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 1.0506941657639064, \"sum\": 1.0506941657639064, \"min\": 1.0506941657639064}}, \"EndTime\": 1580323016.539753, \"Dimensions\": {\"model\": 7, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 1}, \"StartTime\": 1580323016.539733}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.04172723978637201, \"sum\": 0.04172723978637201, \"min\": 0.04172723978637201}}, \"EndTime\": 1580323016.539815, \"Dimensions\": {\"model\": 8, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 1}, \"StartTime\": 1580323016.539798}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.08206099022416129, \"sum\": 0.08206099022416129, \"min\": 0.08206099022416129}}, \"EndTime\": 1580323016.539877, \"Dimensions\": {\"model\": 9, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 1}, \"StartTime\": 1580323016.539859}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 1.1562640438517418, \"sum\": 1.1562640438517418, \"min\": 1.1562640438517418}}, \"EndTime\": 1580323016.539938, \"Dimensions\": {\"model\": 10, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 1}, \"StartTime\": 1580323016.539921}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.20643695517268418, \"sum\": 0.20643695517268418, \"min\": 0.20643695517268418}}, \"EndTime\": 1580323016.539996, \"Dimensions\": {\"model\": 11, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 1}, \"StartTime\": 1580323016.539983}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.05045619120321132, \"sum\": 0.05045619120321132, \"min\": 0.05045619120321132}}, \"EndTime\": 1580323016.540076, \"Dimensions\": {\"model\": 12, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 1}, \"StartTime\": 1580323016.540058}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.5713878224896677, \"sum\": 0.5713878224896677, \"min\": 0.5713878224896677}}, \"EndTime\": 1580323016.540137, \"Dimensions\": {\"model\": 13, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 1}, \"StartTime\": 1580323016.54012}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.07850588542407984, \"sum\": 0.07850588542407984, \"min\": 0.07850588542407984}}, \"EndTime\": 1580323016.540194, \"Dimensions\": {\"model\": 14, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 1}, \"StartTime\": 1580323016.540177}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/29/2020 18:36:56 INFO 139893492320064] #quality_metric: host=algo-1, epoch=1, validation multiclass_cross_entropy_objective <loss>=0.048540707381\u001b[0m\n",
      "\u001b[34m[01/29/2020 18:36:56 INFO 139893492320064] #early_stopping_criteria_metric: host=algo-1, epoch=1, criteria=multiclass_cross_entropy_objective, value=0.0417272397864\u001b[0m\n",
      "\u001b[34m[01/29/2020 18:36:56 INFO 139893492320064] Epoch 1: Loss improved. Updating best model\u001b[0m\n",
      "\u001b[34m[01/29/2020 18:36:56 INFO 139893492320064] #progress_metric: host=algo-1, completed 13 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 12, \"sum\": 12.0, \"min\": 12}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 12, \"sum\": 12.0, \"min\": 12}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 11860, \"sum\": 11860.0, \"min\": 11860}, \"Total Batches Seen\": {\"count\": 1, \"max\": 36, \"sum\": 36.0, \"min\": 36}, \"Total Records Seen\": {\"count\": 1, \"max\": 35720, \"sum\": 35720.0, \"min\": 35720}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 11860, \"sum\": 11860.0, \"min\": 11860}, \"Reset Count\": {\"count\": 1, \"max\": 4, \"sum\": 4.0, \"min\": 4}}, \"EndTime\": 1580323016.541816, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 1}, \"StartTime\": 1580323016.244877}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/29/2020 18:36:56 INFO 139893492320064] #throughput_metric: host=algo-1, train throughput=39910.7547545 records/second\u001b[0m\n",
      "\u001b[34m[2020-01-29 18:36:56.822] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 7, \"duration\": 280, \"num_examples\": 12, \"num_bytes\": 853920}\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.039722972869873044, \"sum\": 0.039722972869873044, \"min\": 0.039722972869873044}}, \"EndTime\": 1580323016.823107, \"Dimensions\": {\"model\": 0, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 2}, \"StartTime\": 1580323016.823037}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.5370736222700639, \"sum\": 0.5370736222700639, \"min\": 0.5370736222700639}}, \"EndTime\": 1580323016.823197, \"Dimensions\": {\"model\": 1, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 2}, \"StartTime\": 1580323016.823181}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.2760055195201527, \"sum\": 0.2760055195201527, \"min\": 0.2760055195201527}}, \"EndTime\": 1580323016.823248, \"Dimensions\": {\"model\": 2, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 2}, \"StartTime\": 1580323016.823236}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.4052204756303267, \"sum\": 0.4052204756303267, \"min\": 0.4052204756303267}}, \"EndTime\": 1580323016.823294, \"Dimensions\": {\"model\": 3, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 2}, \"StartTime\": 1580323016.823283}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.7093851706764914, \"sum\": 0.7093851706764914, \"min\": 0.7093851706764914}}, \"EndTime\": 1580323016.823339, \"Dimensions\": {\"model\": 4, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 2}, \"StartTime\": 1580323016.823328}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.060012053749778055, \"sum\": 0.060012053749778055, \"min\": 0.060012053749778055}}, \"EndTime\": 1580323016.823382, \"Dimensions\": {\"model\": 5, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 2}, \"StartTime\": 1580323016.823372}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.43035178167169746, \"sum\": 0.43035178167169746, \"min\": 0.43035178167169746}}, \"EndTime\": 1580323016.823426, \"Dimensions\": {\"model\": 6, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 2}, \"StartTime\": 1580323016.823416}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.9494902898615056, \"sum\": 0.9494902898615056, \"min\": 0.9494902898615056}}, \"EndTime\": 1580323016.823474, \"Dimensions\": {\"model\": 7, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 2}, \"StartTime\": 1580323016.823462}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.03755639041553844, \"sum\": 0.03755639041553844, \"min\": 0.03755639041553844}}, \"EndTime\": 1580323016.823527, \"Dimensions\": {\"model\": 8, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 2}, \"StartTime\": 1580323016.823515}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.06530101984197444, \"sum\": 0.06530101984197444, \"min\": 0.06530101984197444}}, \"EndTime\": 1580323016.823579, \"Dimensions\": {\"model\": 9, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 2}, \"StartTime\": 1580323016.823567}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 1.0688679421164773, \"sum\": 1.0688679421164773, \"min\": 1.0688679421164773}}, \"EndTime\": 1580323016.82363, \"Dimensions\": {\"model\": 10, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 2}, \"StartTime\": 1580323016.823618}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.16104947038130327, \"sum\": 0.16104947038130327, \"min\": 0.16104947038130327}}, \"EndTime\": 1580323016.823682, \"Dimensions\": {\"model\": 11, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 2}, \"StartTime\": 1580323016.82367}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.04211597806757147, \"sum\": 0.04211597806757147, \"min\": 0.04211597806757147}}, \"EndTime\": 1580323016.823729, \"Dimensions\": {\"model\": 12, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 2}, \"StartTime\": 1580323016.823718}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.4872386835271662, \"sum\": 0.4872386835271662, \"min\": 0.4872386835271662}}, \"EndTime\": 1580323016.82378, \"Dimensions\": {\"model\": 13, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 2}, \"StartTime\": 1580323016.823768}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.06208254692771218, \"sum\": 0.06208254692771218, \"min\": 0.06208254692771218}}, \"EndTime\": 1580323016.823831, \"Dimensions\": {\"model\": 14, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 2}, \"StartTime\": 1580323016.823819}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/29/2020 18:36:56 INFO 139893492320064] #quality_metric: host=algo-1, epoch=2, train multiclass_cross_entropy_objective <loss>=0.0397229728699\u001b[0m\n",
      "\u001b[34m[2020-01-29 18:36:56.861] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/validation\", \"epoch\": 8, \"duration\": 27, \"num_examples\": 2, \"num_bytes\": 106704}\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.039922751556684774, \"sum\": 0.039922751556684774, \"min\": 0.039922751556684774}}, \"EndTime\": 1580323016.864214, \"Dimensions\": {\"model\": 0, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 2}, \"StartTime\": 1580323016.864174}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.4434024949788082, \"sum\": 0.4434024949788082, \"min\": 0.4434024949788082}}, \"EndTime\": 1580323016.864288, \"Dimensions\": {\"model\": 1, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 2}, \"StartTime\": 1580323016.86427}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.19572772027349022, \"sum\": 0.19572772027349022, \"min\": 0.19572772027349022}}, \"EndTime\": 1580323016.864356, \"Dimensions\": {\"model\": 2, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 2}, \"StartTime\": 1580323016.86434}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.31656203997119076, \"sum\": 0.31656203997119076, \"min\": 0.31656203997119076}}, \"EndTime\": 1580323016.86442, \"Dimensions\": {\"model\": 3, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 2}, \"StartTime\": 1580323016.864402}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.5906270962816823, \"sum\": 0.5906270962816823, \"min\": 0.5906270962816823}}, \"EndTime\": 1580323016.864483, \"Dimensions\": {\"model\": 4, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 2}, \"StartTime\": 1580323016.864466}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.055808692808575956, \"sum\": 0.055808692808575956, \"min\": 0.055808692808575956}}, \"EndTime\": 1580323016.864738, \"Dimensions\": {\"model\": 5, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 2}, \"StartTime\": 1580323016.864535}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.3270889570516774, \"sum\": 0.3270889570516774, \"min\": 0.3270889570516774}}, \"EndTime\": 1580323016.864806, \"Dimensions\": {\"model\": 6, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 2}, \"StartTime\": 1580323016.864786}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.8331264439221175, \"sum\": 0.8331264439221175, \"min\": 0.8331264439221175}}, \"EndTime\": 1580323016.864868, \"Dimensions\": {\"model\": 7, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 2}, \"StartTime\": 1580323016.86485}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.04148192026032771, \"sum\": 0.04148192026032771, \"min\": 0.04148192026032771}}, \"EndTime\": 1580323016.864931, \"Dimensions\": {\"model\": 8, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 2}, \"StartTime\": 1580323016.864914}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.059792700084114844, \"sum\": 0.059792700084114844, \"min\": 0.059792700084114844}}, \"EndTime\": 1580323016.864989, \"Dimensions\": {\"model\": 9, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 2}, \"StartTime\": 1580323016.864972}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.9708836152646867, \"sum\": 0.9708836152646867, \"min\": 0.9708836152646867}}, \"EndTime\": 1580323016.865052, \"Dimensions\": {\"model\": 10, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 2}, \"StartTime\": 1580323016.865035}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.13475874721923498, \"sum\": 0.13475874721923498, \"min\": 0.13475874721923498}}, \"EndTime\": 1580323016.865121, \"Dimensions\": {\"model\": 11, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 2}, \"StartTime\": 1580323016.865103}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.04305069263164814, \"sum\": 0.04305069263164814, \"min\": 0.04305069263164814}}, \"EndTime\": 1580323016.865182, \"Dimensions\": {\"model\": 12, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 2}, \"StartTime\": 1580323016.865167}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.39394587672512865, \"sum\": 0.39394587672512865, \"min\": 0.39394587672512865}}, \"EndTime\": 1580323016.865241, \"Dimensions\": {\"model\": 13, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 2}, \"StartTime\": 1580323016.865227}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.05286301163687558, \"sum\": 0.05286301163687558, \"min\": 0.05286301163687558}}, \"EndTime\": 1580323016.865308, \"Dimensions\": {\"model\": 14, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 2}, \"StartTime\": 1580323016.86529}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/29/2020 18:36:56 INFO 139893492320064] #quality_metric: host=algo-1, epoch=2, validation multiclass_cross_entropy_objective <loss>=0.0399227515567\u001b[0m\n",
      "\u001b[34m[01/29/2020 18:36:56 INFO 139893492320064] #early_stopping_criteria_metric: host=algo-1, epoch=2, criteria=multiclass_cross_entropy_objective, value=0.0399227515567\u001b[0m\n",
      "\u001b[34m[01/29/2020 18:36:56 INFO 139893492320064] Epoch 2: Loss improved. Updating best model\u001b[0m\n",
      "\u001b[34m[01/29/2020 18:36:56 INFO 139893492320064] #progress_metric: host=algo-1, completed 20 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 12, \"sum\": 12.0, \"min\": 12}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 12, \"sum\": 12.0, \"min\": 12}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 11860, \"sum\": 11860.0, \"min\": 11860}, \"Total Batches Seen\": {\"count\": 1, \"max\": 48, \"sum\": 48.0, \"min\": 48}, \"Total Records Seen\": {\"count\": 1, \"max\": 47580, \"sum\": 47580.0, \"min\": 47580}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 11860, \"sum\": 11860.0, \"min\": 11860}, \"Reset Count\": {\"count\": 1, \"max\": 5, \"sum\": 5.0, \"min\": 5}}, \"EndTime\": 1580323016.866625, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 2}, \"StartTime\": 1580323016.542197}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/29/2020 18:36:56 INFO 139893492320064] #throughput_metric: host=algo-1, train throughput=36540.4189065 records/second\u001b[0m\n",
      "\u001b[34m[2020-01-29 18:36:57.123] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 9, \"duration\": 256, \"num_examples\": 12, \"num_bytes\": 853920}\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.0351697602705522, \"sum\": 0.0351697602705522, \"min\": 0.0351697602705522}}, \"EndTime\": 1580323017.123599, \"Dimensions\": {\"model\": 0, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 3}, \"StartTime\": 1580323017.123535}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.37905288141424004, \"sum\": 0.37905288141424004, \"min\": 0.37905288141424004}}, \"EndTime\": 1580323017.123672, \"Dimensions\": {\"model\": 1, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 3}, \"StartTime\": 1580323017.123652}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.1658267156427557, \"sum\": 0.1658267156427557, \"min\": 0.1658267156427557}}, \"EndTime\": 1580323017.123741, \"Dimensions\": {\"model\": 2, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 3}, \"StartTime\": 1580323017.123722}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.2695648928555575, \"sum\": 0.2695648928555575, \"min\": 0.2695648928555575}}, \"EndTime\": 1580323017.123809, \"Dimensions\": {\"model\": 3, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 3}, \"StartTime\": 1580323017.12379}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.5135922629616477, \"sum\": 0.5135922629616477, \"min\": 0.5135922629616477}}, \"EndTime\": 1580323017.123873, \"Dimensions\": {\"model\": 4, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 3}, \"StartTime\": 1580323017.123854}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.045562551671808414, \"sum\": 0.045562551671808414, \"min\": 0.045562551671808414}}, \"EndTime\": 1580323017.123935, \"Dimensions\": {\"model\": 5, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 3}, \"StartTime\": 1580323017.123918}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.27114160433682527, \"sum\": 0.27114160433682527, \"min\": 0.27114160433682527}}, \"EndTime\": 1580323017.123999, \"Dimensions\": {\"model\": 6, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 3}, \"StartTime\": 1580323017.123981}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.7508437999378551, \"sum\": 0.7508437999378551, \"min\": 0.7508437999378551}}, \"EndTime\": 1580323017.12409, \"Dimensions\": {\"model\": 7, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 3}, \"StartTime\": 1580323017.12407}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.03774834268743341, \"sum\": 0.03774834268743341, \"min\": 0.03774834268743341}}, \"EndTime\": 1580323017.124151, \"Dimensions\": {\"model\": 8, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 3}, \"StartTime\": 1580323017.124136}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.05177313163063743, \"sum\": 0.05177313163063743, \"min\": 0.05177313163063743}}, \"EndTime\": 1580323017.124213, \"Dimensions\": {\"model\": 9, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 3}, \"StartTime\": 1580323017.124195}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.8964544344815341, \"sum\": 0.8964544344815341, \"min\": 0.8964544344815341}}, \"EndTime\": 1580323017.12427, \"Dimensions\": {\"model\": 10, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 3}, \"StartTime\": 1580323017.124253}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.10974308568781073, \"sum\": 0.10974308568781073, \"min\": 0.10974308568781073}}, \"EndTime\": 1580323017.124334, \"Dimensions\": {\"model\": 11, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 3}, \"StartTime\": 1580323017.124316}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.03871932896700772, \"sum\": 0.03871932896700772, \"min\": 0.03871932896700772}}, \"EndTime\": 1580323017.124395, \"Dimensions\": {\"model\": 12, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 3}, \"StartTime\": 1580323017.124378}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.34216397094726564, \"sum\": 0.34216397094726564, \"min\": 0.34216397094726564}}, \"EndTime\": 1580323017.124457, \"Dimensions\": {\"model\": 13, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 3}, \"StartTime\": 1580323017.124439}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.04791817509044301, \"sum\": 0.04791817509044301, \"min\": 0.04791817509044301}}, \"EndTime\": 1580323017.124518, \"Dimensions\": {\"model\": 14, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 3}, \"StartTime\": 1580323017.124501}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/29/2020 18:36:57 INFO 139893492320064] #quality_metric: host=algo-1, epoch=3, train multiclass_cross_entropy_objective <loss>=0.0351697602706\u001b[0m\n",
      "\u001b[34m[2020-01-29 18:36:57.172] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/validation\", \"epoch\": 11, \"duration\": 33, \"num_examples\": 2, \"num_bytes\": 106704}\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.03782310434359449, \"sum\": 0.03782310434359449, \"min\": 0.03782310434359449}}, \"EndTime\": 1580323017.177378, \"Dimensions\": {\"model\": 0, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 3}, \"StartTime\": 1580323017.177315}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.3184801685987053, \"sum\": 0.3184801685987053, \"min\": 0.3184801685987053}}, \"EndTime\": 1580323017.177507, \"Dimensions\": {\"model\": 1, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 3}, \"StartTime\": 1580323017.177455}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.13426358818846998, \"sum\": 0.13426358818846998, \"min\": 0.13426358818846998}}, \"EndTime\": 1580323017.17775, \"Dimensions\": {\"model\": 2, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 3}, \"StartTime\": 1580323017.1777}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.21584368974734575, \"sum\": 0.21584368974734575, \"min\": 0.21584368974734575}}, \"EndTime\": 1580323017.177992, \"Dimensions\": {\"model\": 3, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 3}, \"StartTime\": 1580323017.177941}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.4369466475307861, \"sum\": 0.4369466475307861, \"min\": 0.4369466475307861}}, \"EndTime\": 1580323017.178248, \"Dimensions\": {\"model\": 4, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 3}, \"StartTime\": 1580323017.17819}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.0469696003737559, \"sum\": 0.0469696003737559, \"min\": 0.0469696003737559}}, \"EndTime\": 1580323017.178485, \"Dimensions\": {\"model\": 5, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 3}, \"StartTime\": 1580323017.178455}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.22315399849463088, \"sum\": 0.22315399849463088, \"min\": 0.22315399849463088}}, \"EndTime\": 1580323017.178543, \"Dimensions\": {\"model\": 6, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 3}, \"StartTime\": 1580323017.178526}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.6603977754209367, \"sum\": 0.6603977754209367, \"min\": 0.6603977754209367}}, \"EndTime\": 1580323017.178611, \"Dimensions\": {\"model\": 7, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 3}, \"StartTime\": 1580323017.178592}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.04048017998616866, \"sum\": 0.04048017998616866, \"min\": 0.04048017998616866}}, \"EndTime\": 1580323017.178676, \"Dimensions\": {\"model\": 8, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 3}, \"StartTime\": 1580323017.178657}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.05068387998099591, \"sum\": 0.05068387998099591, \"min\": 0.05068387998099591}}, \"EndTime\": 1580323017.178737, \"Dimensions\": {\"model\": 9, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 3}, \"StartTime\": 1580323017.178721}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.8151051550902496, \"sum\": 0.8151051550902496, \"min\": 0.8151051550902496}}, \"EndTime\": 1580323017.178821, \"Dimensions\": {\"model\": 10, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 3}, \"StartTime\": 1580323017.178782}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.10173745354821002, \"sum\": 0.10173745354821002, \"min\": 0.10173745354821002}}, \"EndTime\": 1580323017.178885, \"Dimensions\": {\"model\": 11, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 3}, \"StartTime\": 1580323017.178868}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.04237332775203483, \"sum\": 0.04237332775203483, \"min\": 0.04237332775203483}}, \"EndTime\": 1580323017.178945, \"Dimensions\": {\"model\": 12, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 3}, \"StartTime\": 1580323017.178928}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.2806136508380514, \"sum\": 0.2806136508380514, \"min\": 0.2806136508380514}}, \"EndTime\": 1580323017.17901, \"Dimensions\": {\"model\": 13, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 3}, \"StartTime\": 1580323017.178992}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.047085994972712916, \"sum\": 0.047085994972712916, \"min\": 0.047085994972712916}}, \"EndTime\": 1580323017.179071, \"Dimensions\": {\"model\": 14, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 3}, \"StartTime\": 1580323017.179054}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/29/2020 18:36:57 INFO 139893492320064] #quality_metric: host=algo-1, epoch=3, validation multiclass_cross_entropy_objective <loss>=0.0378231043436\u001b[0m\n",
      "\u001b[34m[01/29/2020 18:36:57 INFO 139893492320064] #early_stopping_criteria_metric: host=algo-1, epoch=3, criteria=multiclass_cross_entropy_objective, value=0.0378231043436\u001b[0m\n",
      "\u001b[34m[01/29/2020 18:36:57 INFO 139893492320064] Epoch 3: Loss improved. Updating best model\u001b[0m\n",
      "\u001b[34m[01/29/2020 18:36:57 INFO 139893492320064] #progress_metric: host=algo-1, completed 26 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 12, \"sum\": 12.0, \"min\": 12}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 12, \"sum\": 12.0, \"min\": 12}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 11860, \"sum\": 11860.0, \"min\": 11860}, \"Total Batches Seen\": {\"count\": 1, \"max\": 60, \"sum\": 60.0, \"min\": 60}, \"Total Records Seen\": {\"count\": 1, \"max\": 59440, \"sum\": 59440.0, \"min\": 59440}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 11860, \"sum\": 11860.0, \"min\": 11860}, \"Reset Count\": {\"count\": 1, \"max\": 6, \"sum\": 6.0, \"min\": 6}}, \"EndTime\": 1580323017.180552, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 3}, \"StartTime\": 1580323016.866922}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/29/2020 18:36:57 INFO 139893492320064] #throughput_metric: host=algo-1, train throughput=37801.7413084 records/second\u001b[0m\n",
      "\u001b[34m[2020-01-29 18:36:57.495] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 11, \"duration\": 312, \"num_examples\": 12, \"num_bytes\": 853920}\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.03408861576427113, \"sum\": 0.03408861576427113, \"min\": 0.03408861576427113}}, \"EndTime\": 1580323017.495886, \"Dimensions\": {\"model\": 0, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 4}, \"StartTime\": 1580323017.495806}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.27251472611860794, \"sum\": 0.27251472611860794, \"min\": 0.27251472611860794}}, \"EndTime\": 1580323017.495987, \"Dimensions\": {\"model\": 1, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 4}, \"StartTime\": 1580323017.495965}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.11761690937389027, \"sum\": 0.11761690937389027, \"min\": 0.11761690937389027}}, \"EndTime\": 1580323017.496083, \"Dimensions\": {\"model\": 2, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 4}, \"StartTime\": 1580323017.496063}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.18751801508123225, \"sum\": 0.18751801508123225, \"min\": 0.18751801508123225}}, \"EndTime\": 1580323017.496155, \"Dimensions\": {\"model\": 3, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 4}, \"StartTime\": 1580323017.496136}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.38542901611328123, \"sum\": 0.38542901611328123, \"min\": 0.38542901611328123}}, \"EndTime\": 1580323017.496222, \"Dimensions\": {\"model\": 4, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 4}, \"StartTime\": 1580323017.496203}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.03884721287814054, \"sum\": 0.03884721287814054, \"min\": 0.03884721287814054}}, \"EndTime\": 1580323017.496286, \"Dimensions\": {\"model\": 5, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 4}, \"StartTime\": 1580323017.496269}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.19318454118208453, \"sum\": 0.19318454118208453, \"min\": 0.19318454118208453}}, \"EndTime\": 1580323017.496351, \"Dimensions\": {\"model\": 6, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 4}, \"StartTime\": 1580323017.496332}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.5983010087446733, \"sum\": 0.5983010087446733, \"min\": 0.5983010087446733}}, \"EndTime\": 1580323017.496413, \"Dimensions\": {\"model\": 7, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 4}, \"StartTime\": 1580323017.496395}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.037591846466064456, \"sum\": 0.037591846466064456, \"min\": 0.037591846466064456}}, \"EndTime\": 1580323017.496474, \"Dimensions\": {\"model\": 8, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 4}, \"StartTime\": 1580323017.496457}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.04552808449485085, \"sum\": 0.04552808449485085, \"min\": 0.04552808449485085}}, \"EndTime\": 1580323017.49656, \"Dimensions\": {\"model\": 9, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 4}, \"StartTime\": 1580323017.49654}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.7530880404385654, \"sum\": 0.7530880404385654, \"min\": 0.7530880404385654}}, \"EndTime\": 1580323017.496624, \"Dimensions\": {\"model\": 10, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 4}, \"StartTime\": 1580323017.496606}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.08579602466930043, \"sum\": 0.08579602466930043, \"min\": 0.08579602466930043}}, \"EndTime\": 1580323017.496683, \"Dimensions\": {\"model\": 11, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 4}, \"StartTime\": 1580323017.496666}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.03833043219826438, \"sum\": 0.03833043219826438, \"min\": 0.03833043219826438}}, \"EndTime\": 1580323017.496744, \"Dimensions\": {\"model\": 12, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 4}, \"StartTime\": 1580323017.496727}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.24673357876864346, \"sum\": 0.24673357876864346, \"min\": 0.24673357876864346}}, \"EndTime\": 1580323017.496806, \"Dimensions\": {\"model\": 13, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 4}, \"StartTime\": 1580323017.496789}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.045817917216907846, \"sum\": 0.045817917216907846, \"min\": 0.045817917216907846}}, \"EndTime\": 1580323017.496867, \"Dimensions\": {\"model\": 14, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 4}, \"StartTime\": 1580323017.49685}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/29/2020 18:36:57 INFO 139893492320064] #quality_metric: host=algo-1, epoch=4, train multiclass_cross_entropy_objective <loss>=0.0340886157643\u001b[0m\n",
      "\u001b[34m[2020-01-29 18:36:57.543] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/validation\", \"epoch\": 14, \"duration\": 30, \"num_examples\": 2, \"num_bytes\": 106704}\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.03766022294799969, \"sum\": 0.03766022294799969, \"min\": 0.03766022294799969}}, \"EndTime\": 1580323017.54789, \"Dimensions\": {\"model\": 0, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 4}, \"StartTime\": 1580323017.547848}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.23376692901899618, \"sum\": 0.23376692901899618, \"min\": 0.23376692901899618}}, \"EndTime\": 1580323017.54797, \"Dimensions\": {\"model\": 1, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 4}, \"StartTime\": 1580323017.547949}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.10680574476316712, \"sum\": 0.10680574476316712, \"min\": 0.10680574476316712}}, \"EndTime\": 1580323017.548229, \"Dimensions\": {\"model\": 2, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 4}, \"StartTime\": 1580323017.54818}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.1534903316523543, \"sum\": 0.1534903316523543, \"min\": 0.1534903316523543}}, \"EndTime\": 1580323017.548409, \"Dimensions\": {\"model\": 3, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 4}, \"StartTime\": 1580323017.548384}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.3361465927721196, \"sum\": 0.3361465927721196, \"min\": 0.3361465927721196}}, \"EndTime\": 1580323017.548572, \"Dimensions\": {\"model\": 4, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 4}, \"StartTime\": 1580323017.548546}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.04270432481238073, \"sum\": 0.04270432481238073, \"min\": 0.04270432481238073}}, \"EndTime\": 1580323017.548741, \"Dimensions\": {\"model\": 5, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 4}, \"StartTime\": 1580323017.548716}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.16926582943894442, \"sum\": 0.16926582943894442, \"min\": 0.16926582943894442}}, \"EndTime\": 1580323017.548932, \"Dimensions\": {\"model\": 6, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 4}, \"StartTime\": 1580323017.548909}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.5311029411037924, \"sum\": 0.5311029411037924, \"min\": 0.5311029411037924}}, \"EndTime\": 1580323017.549183, \"Dimensions\": {\"model\": 7, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 4}, \"StartTime\": 1580323017.549086}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.039853328957087916, \"sum\": 0.039853328957087916, \"min\": 0.039853328957087916}}, \"EndTime\": 1580323017.549251, \"Dimensions\": {\"model\": 8, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 4}, \"StartTime\": 1580323017.54923}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.04729682520816201, \"sum\": 0.04729682520816201, \"min\": 0.04729682520816201}}, \"EndTime\": 1580323017.54932, \"Dimensions\": {\"model\": 9, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 4}, \"StartTime\": 1580323017.549301}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.6872367086680794, \"sum\": 0.6872367086680794, \"min\": 0.6872367086680794}}, \"EndTime\": 1580323017.549551, \"Dimensions\": {\"model\": 10, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 4}, \"StartTime\": 1580323017.549528}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.08814027402725941, \"sum\": 0.08814027402725941, \"min\": 0.08814027402725941}}, \"EndTime\": 1580323017.549703, \"Dimensions\": {\"model\": 11, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 4}, \"StartTime\": 1580323017.5496}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.04226395250492894, \"sum\": 0.04226395250492894, \"min\": 0.04226395250492894}}, \"EndTime\": 1580323017.549847, \"Dimensions\": {\"model\": 12, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 4}, \"StartTime\": 1580323017.549824}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.205492562771487, \"sum\": 0.205492562771487, \"min\": 0.205492562771487}}, \"EndTime\": 1580323017.549912, \"Dimensions\": {\"model\": 13, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 4}, \"StartTime\": 1580323017.549894}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.04833078191347933, \"sum\": 0.04833078191347933, \"min\": 0.04833078191347933}}, \"EndTime\": 1580323017.550174, \"Dimensions\": {\"model\": 14, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 4}, \"StartTime\": 1580323017.55005}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/29/2020 18:36:57 INFO 139893492320064] #quality_metric: host=algo-1, epoch=4, validation multiclass_cross_entropy_objective <loss>=0.037660222948\u001b[0m\n",
      "\u001b[34m[01/29/2020 18:36:57 INFO 139893492320064] #early_stopping_criteria_metric: host=algo-1, epoch=4, criteria=multiclass_cross_entropy_objective, value=0.037660222948\u001b[0m\n",
      "\u001b[34m[01/29/2020 18:36:57 INFO 139893492320064] Epoch 4: Loss improved. Updating best model\u001b[0m\n",
      "\u001b[34m[01/29/2020 18:36:57 INFO 139893492320064] #progress_metric: host=algo-1, completed 33 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 12, \"sum\": 12.0, \"min\": 12}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 12, \"sum\": 12.0, \"min\": 12}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 11860, \"sum\": 11860.0, \"min\": 11860}, \"Total Batches Seen\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Total Records Seen\": {\"count\": 1, \"max\": 71300, \"sum\": 71300.0, \"min\": 71300}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 11860, \"sum\": 11860.0, \"min\": 11860}, \"Reset Count\": {\"count\": 1, \"max\": 7, \"sum\": 7.0, \"min\": 7}}, \"EndTime\": 1580323017.551831, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 4}, \"StartTime\": 1580323017.180957}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/29/2020 18:36:57 INFO 139893492320064] #throughput_metric: host=algo-1, train throughput=31967.6505491 records/second\u001b[0m\n",
      "\u001b[34m[2020-01-29 18:36:57.890] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 13, \"duration\": 338, \"num_examples\": 12, \"num_bytes\": 853920}\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.03394004960493608, \"sum\": 0.03394004960493608, \"min\": 0.03394004960493608}}, \"EndTime\": 1580323017.891004, \"Dimensions\": {\"model\": 0, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 5}, \"StartTime\": 1580323017.890925}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.20054222523082385, \"sum\": 0.20054222523082385, \"min\": 0.20054222523082385}}, \"EndTime\": 1580323017.891119, \"Dimensions\": {\"model\": 1, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 5}, \"StartTime\": 1580323017.891097}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.09619864931973544, \"sum\": 0.09619864931973544, \"min\": 0.09619864931973544}}, \"EndTime\": 1580323017.891201, \"Dimensions\": {\"model\": 2, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 5}, \"StartTime\": 1580323017.891181}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.13598407398570667, \"sum\": 0.13598407398570667, \"min\": 0.13598407398570667}}, \"EndTime\": 1580323017.891293, \"Dimensions\": {\"model\": 3, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 5}, \"StartTime\": 1580323017.891272}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.300868691184304, \"sum\": 0.300868691184304, \"min\": 0.300868691184304}}, \"EndTime\": 1580323017.891369, \"Dimensions\": {\"model\": 4, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 5}, \"StartTime\": 1580323017.891349}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.03541875509782271, \"sum\": 0.03541875509782271, \"min\": 0.03541875509782271}}, \"EndTime\": 1580323017.891442, \"Dimensions\": {\"model\": 5, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 5}, \"StartTime\": 1580323017.891424}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.1512533028342507, \"sum\": 0.1512533028342507, \"min\": 0.1512533028342507}}, \"EndTime\": 1580323017.891513, \"Dimensions\": {\"model\": 6, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 5}, \"StartTime\": 1580323017.891495}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.48370222889293324, \"sum\": 0.48370222889293324, \"min\": 0.48370222889293324}}, \"EndTime\": 1580323017.891606, \"Dimensions\": {\"model\": 7, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 5}, \"StartTime\": 1580323017.891589}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.03652721196954901, \"sum\": 0.03652721196954901, \"min\": 0.03652721196954901}}, \"EndTime\": 1580323017.891673, \"Dimensions\": {\"model\": 8, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 5}, \"StartTime\": 1580323017.891656}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.0430873518857089, \"sum\": 0.0430873518857089, \"min\": 0.0430873518857089}}, \"EndTime\": 1580323017.891742, \"Dimensions\": {\"model\": 9, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 5}, \"StartTime\": 1580323017.891724}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.6364426879882813, \"sum\": 0.6364426879882813, \"min\": 0.6364426879882813}}, \"EndTime\": 1580323017.891807, \"Dimensions\": {\"model\": 10, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 5}, \"StartTime\": 1580323017.891789}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.07525633551857688, \"sum\": 0.07525633551857688, \"min\": 0.07525633551857688}}, \"EndTime\": 1580323017.891879, \"Dimensions\": {\"model\": 11, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 5}, \"StartTime\": 1580323017.891861}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.03804264450073242, \"sum\": 0.03804264450073242, \"min\": 0.03804264450073242}}, \"EndTime\": 1580323017.89195, \"Dimensions\": {\"model\": 12, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 5}, \"StartTime\": 1580323017.891932}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.18118121754039418, \"sum\": 0.18118121754039418, \"min\": 0.18118121754039418}}, \"EndTime\": 1580323017.892021, \"Dimensions\": {\"model\": 13, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 5}, \"StartTime\": 1580323017.892003}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.04302356026389382, \"sum\": 0.04302356026389382, \"min\": 0.04302356026389382}}, \"EndTime\": 1580323017.892114, \"Dimensions\": {\"model\": 14, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 5}, \"StartTime\": 1580323017.892095}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/29/2020 18:36:57 INFO 139893492320064] #quality_metric: host=algo-1, epoch=5, train multiclass_cross_entropy_objective <loss>=0.0339400496049\u001b[0m\n",
      "\u001b[34m[2020-01-29 18:36:57.938] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/validation\", \"epoch\": 17, \"duration\": 30, \"num_examples\": 2, \"num_bytes\": 106704}\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.037521771573827335, \"sum\": 0.037521771573827335, \"min\": 0.037521771573827335}}, \"EndTime\": 1580323017.943058, \"Dimensions\": {\"model\": 0, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 5}, \"StartTime\": 1580323017.943012}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.17614506709913494, \"sum\": 0.17614506709913494, \"min\": 0.17614506709913494}}, \"EndTime\": 1580323017.943138, \"Dimensions\": {\"model\": 1, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 5}, \"StartTime\": 1580323017.943116}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.091067907459501, \"sum\": 0.091067907459501, \"min\": 0.091067907459501}}, \"EndTime\": 1580323017.943231, \"Dimensions\": {\"model\": 2, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 5}, \"StartTime\": 1580323017.943191}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.11380452504846571, \"sum\": 0.11380452504846571, \"min\": 0.11380452504846571}}, \"EndTime\": 1580323017.943325, \"Dimensions\": {\"model\": 3, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 5}, \"StartTime\": 1580323017.943286}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.26895274420981463, \"sum\": 0.26895274420981463, \"min\": 0.26895274420981463}}, \"EndTime\": 1580323017.943398, \"Dimensions\": {\"model\": 4, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 5}, \"StartTime\": 1580323017.943378}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.0406857386291751, \"sum\": 0.0406857386291751, \"min\": 0.0406857386291751}}, \"EndTime\": 1580323017.943465, \"Dimensions\": {\"model\": 5, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 5}, \"StartTime\": 1580323017.943446}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.13851255347371583, \"sum\": 0.13851255347371583, \"min\": 0.13851255347371583}}, \"EndTime\": 1580323017.943528, \"Dimensions\": {\"model\": 6, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 5}, \"StartTime\": 1580323017.943511}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.43309863215355093, \"sum\": 0.43309863215355093, \"min\": 0.43309863215355093}}, \"EndTime\": 1580323017.943592, \"Dimensions\": {\"model\": 7, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 5}, \"StartTime\": 1580323017.943575}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.039191477694492105, \"sum\": 0.039191477694492105, \"min\": 0.039191477694492105}}, \"EndTime\": 1580323017.943656, \"Dimensions\": {\"model\": 8, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 5}, \"StartTime\": 1580323017.943638}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.045330855849622556, \"sum\": 0.045330855849622556, \"min\": 0.045330855849622556}}, \"EndTime\": 1580323017.94372, \"Dimensions\": {\"model\": 9, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 5}, \"StartTime\": 1580323017.943702}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.5838683175976299, \"sum\": 0.5838683175976299, \"min\": 0.5838683175976299}}, \"EndTime\": 1580323017.943785, \"Dimensions\": {\"model\": 10, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 5}, \"StartTime\": 1580323017.943766}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.08280391667375037, \"sum\": 0.08280391667375037, \"min\": 0.08280391667375037}}, \"EndTime\": 1580323017.943847, \"Dimensions\": {\"model\": 11, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 5}, \"StartTime\": 1580323017.94383}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.041797466767139926, \"sum\": 0.041797466767139926, \"min\": 0.041797466767139926}}, \"EndTime\": 1580323017.943909, \"Dimensions\": {\"model\": 12, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 5}, \"StartTime\": 1580323017.943892}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.1562868084823876, \"sum\": 0.1562868084823876, \"min\": 0.1562868084823876}}, \"EndTime\": 1580323017.943971, \"Dimensions\": {\"model\": 13, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 5}, \"StartTime\": 1580323017.943954}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.0429942971459928, \"sum\": 0.0429942971459928, \"min\": 0.0429942971459928}}, \"EndTime\": 1580323017.944058, \"Dimensions\": {\"model\": 14, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 5}, \"StartTime\": 1580323017.944015}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/29/2020 18:36:57 INFO 139893492320064] #quality_metric: host=algo-1, epoch=5, validation multiclass_cross_entropy_objective <loss>=0.0375217715738\u001b[0m\n",
      "\u001b[34m[01/29/2020 18:36:57 INFO 139893492320064] #early_stopping_criteria_metric: host=algo-1, epoch=5, criteria=multiclass_cross_entropy_objective, value=0.0375217715738\u001b[0m\n",
      "\u001b[34m[01/29/2020 18:36:57 INFO 139893492320064] Epoch 5: Loss improved. Updating best model\u001b[0m\n",
      "\u001b[34m[01/29/2020 18:36:57 INFO 139893492320064] #progress_metric: host=algo-1, completed 40 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 12, \"sum\": 12.0, \"min\": 12}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 12, \"sum\": 12.0, \"min\": 12}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 11860, \"sum\": 11860.0, \"min\": 11860}, \"Total Batches Seen\": {\"count\": 1, \"max\": 84, \"sum\": 84.0, \"min\": 84}, \"Total Records Seen\": {\"count\": 1, \"max\": 83160, \"sum\": 83160.0, \"min\": 83160}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 11860, \"sum\": 11860.0, \"min\": 11860}, \"Reset Count\": {\"count\": 1, \"max\": 8, \"sum\": 8.0, \"min\": 8}}, \"EndTime\": 1580323017.945747, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 5}, \"StartTime\": 1580323017.55212}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/29/2020 18:36:57 INFO 139893492320064] #throughput_metric: host=algo-1, train throughput=30119.2707598 records/second\u001b[0m\n",
      "\u001b[34m[2020-01-29 18:36:58.250] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 15, \"duration\": 302, \"num_examples\": 12, \"num_bytes\": 853920}\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.03381054791537198, \"sum\": 0.03381054791537198, \"min\": 0.03381054791537198}}, \"EndTime\": 1580323018.250234, \"Dimensions\": {\"model\": 0, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 6}, \"StartTime\": 1580323018.250157}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.15168998163396663, \"sum\": 0.15168998163396663, \"min\": 0.15168998163396663}}, \"EndTime\": 1580323018.250337, \"Dimensions\": {\"model\": 1, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 6}, \"StartTime\": 1580323018.250318}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.08344830669056286, \"sum\": 0.08344830669056286, \"min\": 0.08344830669056286}}, \"EndTime\": 1580323018.250554, \"Dimensions\": {\"model\": 2, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 6}, \"StartTime\": 1580323018.25053}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.09731173497980292, \"sum\": 0.09731173497980292, \"min\": 0.09731173497980292}}, \"EndTime\": 1580323018.250622, \"Dimensions\": {\"model\": 3, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 6}, \"StartTime\": 1580323018.250604}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.24361110895330257, \"sum\": 0.24361110895330257, \"min\": 0.24361110895330257}}, \"EndTime\": 1580323018.250785, \"Dimensions\": {\"model\": 4, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 6}, \"StartTime\": 1580323018.250762}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.033611086585304956, \"sum\": 0.033611086585304956, \"min\": 0.033611086585304956}}, \"EndTime\": 1580323018.250944, \"Dimensions\": {\"model\": 5, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 6}, \"StartTime\": 1580323018.250918}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.1259773809259588, \"sum\": 0.1259773809259588, \"min\": 0.1259773809259588}}, \"EndTime\": 1580323018.251103, \"Dimensions\": {\"model\": 6, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 6}, \"StartTime\": 1580323018.25108}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.39730078679865055, \"sum\": 0.39730078679865055, \"min\": 0.39730078679865055}}, \"EndTime\": 1580323018.25125, \"Dimensions\": {\"model\": 7, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 6}, \"StartTime\": 1580323018.251153}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.03572869526256214, \"sum\": 0.03572869526256214, \"min\": 0.03572869526256214}}, \"EndTime\": 1580323018.251385, \"Dimensions\": {\"model\": 8, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 6}, \"StartTime\": 1580323018.251359}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.04150294702703303, \"sum\": 0.04150294702703303, \"min\": 0.04150294702703303}}, \"EndTime\": 1580323018.251453, \"Dimensions\": {\"model\": 9, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 6}, \"StartTime\": 1580323018.251435}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.5425220753062855, \"sum\": 0.5425220753062855, \"min\": 0.5425220753062855}}, \"EndTime\": 1580323018.251651, \"Dimensions\": {\"model\": 10, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 6}, \"StartTime\": 1580323018.251626}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.07059866991910067, \"sum\": 0.07059866991910067, \"min\": 0.07059866991910067}}, \"EndTime\": 1580323018.251721, \"Dimensions\": {\"model\": 11, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 6}, \"StartTime\": 1580323018.251703}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.03769460626081987, \"sum\": 0.03769460626081987, \"min\": 0.03769460626081987}}, \"EndTime\": 1580323018.251905, \"Dimensions\": {\"model\": 12, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 6}, \"StartTime\": 1580323018.25188}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.13410630104758522, \"sum\": 0.13410630104758522, \"min\": 0.13410630104758522}}, \"EndTime\": 1580323018.251976, \"Dimensions\": {\"model\": 13, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 6}, \"StartTime\": 1580323018.251958}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.03976784255287864, \"sum\": 0.03976784255287864, \"min\": 0.03976784255287864}}, \"EndTime\": 1580323018.252179, \"Dimensions\": {\"model\": 14, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 6}, \"StartTime\": 1580323018.252158}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/29/2020 18:36:58 INFO 139893492320064] #quality_metric: host=algo-1, epoch=6, train multiclass_cross_entropy_objective <loss>=0.0338105479154\u001b[0m\n",
      "\u001b[34m[2020-01-29 18:36:58.305] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/validation\", \"epoch\": 20, \"duration\": 36, \"num_examples\": 2, \"num_bytes\": 106704}\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.037286790598098404, \"sum\": 0.037286790598098404, \"min\": 0.037286790598098404}}, \"EndTime\": 1580323018.30919, \"Dimensions\": {\"model\": 0, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 6}, \"StartTime\": 1580323018.309144}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.13670937027204053, \"sum\": 0.13670937027204053, \"min\": 0.13670937027204053}}, \"EndTime\": 1580323018.30927, \"Dimensions\": {\"model\": 1, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 6}, \"StartTime\": 1580323018.309249}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.08108513043155233, \"sum\": 0.08108513043155233, \"min\": 0.08108513043155233}}, \"EndTime\": 1580323018.309343, \"Dimensions\": {\"model\": 2, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 6}, \"StartTime\": 1580323018.309324}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.08816756121060143, \"sum\": 0.08816756121060143, \"min\": 0.08816756121060143}}, \"EndTime\": 1580323018.30941, \"Dimensions\": {\"model\": 3, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 6}, \"StartTime\": 1580323018.309391}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.2224133963848737, \"sum\": 0.2224133963848737, \"min\": 0.2224133963848737}}, \"EndTime\": 1580323018.309528, \"Dimensions\": {\"model\": 4, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 6}, \"StartTime\": 1580323018.309506}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.03983298776603421, \"sum\": 0.03983298776603421, \"min\": 0.03983298776603421}}, \"EndTime\": 1580323018.309604, \"Dimensions\": {\"model\": 5, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 6}, \"StartTime\": 1580323018.309586}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.11852197737185417, \"sum\": 0.11852197737185417, \"min\": 0.11852197737185417}}, \"EndTime\": 1580323018.309677, \"Dimensions\": {\"model\": 6, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 6}, \"StartTime\": 1580323018.309658}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.3595050394776379, \"sum\": 0.3595050394776379, \"min\": 0.3595050394776379}}, \"EndTime\": 1580323018.309739, \"Dimensions\": {\"model\": 7, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 6}, \"StartTime\": 1580323018.309721}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.03823175057064988, \"sum\": 0.03823175057064988, \"min\": 0.03823175057064988}}, \"EndTime\": 1580323018.3098, \"Dimensions\": {\"model\": 8, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 6}, \"StartTime\": 1580323018.309784}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.04497192810099778, \"sum\": 0.04497192810099778, \"min\": 0.04497192810099778}}, \"EndTime\": 1580323018.309858, \"Dimensions\": {\"model\": 9, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 6}, \"StartTime\": 1580323018.309841}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.5010043516171928, \"sum\": 0.5010043516171928, \"min\": 0.5010043516171928}}, \"EndTime\": 1580323018.309929, \"Dimensions\": {\"model\": 10, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 6}, \"StartTime\": 1580323018.309911}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.08062034225978672, \"sum\": 0.08062034225978672, \"min\": 0.08062034225978672}}, \"EndTime\": 1580323018.309992, \"Dimensions\": {\"model\": 11, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 6}, \"StartTime\": 1580323018.309975}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.041638621434509034, \"sum\": 0.041638621434509034, \"min\": 0.041638621434509034}}, \"EndTime\": 1580323018.310055, \"Dimensions\": {\"model\": 12, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 6}, \"StartTime\": 1580323018.310038}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.12128508718390214, \"sum\": 0.12128508718390214, \"min\": 0.12128508718390214}}, \"EndTime\": 1580323018.310125, \"Dimensions\": {\"model\": 13, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 6}, \"StartTime\": 1580323018.310107}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.04209609552916245, \"sum\": 0.04209609552916245, \"min\": 0.04209609552916245}}, \"EndTime\": 1580323018.310194, \"Dimensions\": {\"model\": 14, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 6}, \"StartTime\": 1580323018.310177}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/29/2020 18:36:58 INFO 139893492320064] #quality_metric: host=algo-1, epoch=6, validation multiclass_cross_entropy_objective <loss>=0.0372867905981\u001b[0m\n",
      "\u001b[34m[01/29/2020 18:36:58 INFO 139893492320064] #early_stopping_criteria_metric: host=algo-1, epoch=6, criteria=multiclass_cross_entropy_objective, value=0.0372867905981\u001b[0m\n",
      "\u001b[34m[01/29/2020 18:36:58 INFO 139893492320064] Epoch 6: Loss improved. Updating best model\u001b[0m\n",
      "\u001b[34m[01/29/2020 18:36:58 INFO 139893492320064] #progress_metric: host=algo-1, completed 46 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 12, \"sum\": 12.0, \"min\": 12}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 12, \"sum\": 12.0, \"min\": 12}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 11860, \"sum\": 11860.0, \"min\": 11860}, \"Total Batches Seen\": {\"count\": 1, \"max\": 96, \"sum\": 96.0, \"min\": 96}, \"Total Records Seen\": {\"count\": 1, \"max\": 95020, \"sum\": 95020.0, \"min\": 95020}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 11860, \"sum\": 11860.0, \"min\": 11860}, \"Reset Count\": {\"count\": 1, \"max\": 9, \"sum\": 9.0, \"min\": 9}}, \"EndTime\": 1580323018.311825, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 6}, \"StartTime\": 1580323017.946046}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/29/2020 18:36:58 INFO 139893492320064] #throughput_metric: host=algo-1, train throughput=32410.8377264 records/second\u001b[0m\n",
      "\u001b[34m[2020-01-29 18:36:58.624] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 17, \"duration\": 312, \"num_examples\": 12, \"num_bytes\": 853920}\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.033605480367487124, \"sum\": 0.033605480367487124, \"min\": 0.033605480367487124}}, \"EndTime\": 1580323018.624749, \"Dimensions\": {\"model\": 0, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 7}, \"StartTime\": 1580323018.624665}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.11754346257990057, \"sum\": 0.11754346257990057, \"min\": 0.11754346257990057}}, \"EndTime\": 1580323018.624863, \"Dimensions\": {\"model\": 1, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 7}, \"StartTime\": 1580323018.624841}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.0749125941883434, \"sum\": 0.0749125941883434, \"min\": 0.0749125941883434}}, \"EndTime\": 1580323018.624936, \"Dimensions\": {\"model\": 2, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 7}, \"StartTime\": 1580323018.624917}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.07343553820523349, \"sum\": 0.07343553820523349, \"min\": 0.07343553820523349}}, \"EndTime\": 1580323018.625, \"Dimensions\": {\"model\": 3, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 7}, \"StartTime\": 1580323018.624983}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.2032149727561257, \"sum\": 0.2032149727561257, \"min\": 0.2032149727561257}}, \"EndTime\": 1580323018.625065, \"Dimensions\": {\"model\": 4, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 7}, \"StartTime\": 1580323018.625047}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.032684002789584075, \"sum\": 0.032684002789584075, \"min\": 0.032684002789584075}}, \"EndTime\": 1580323018.625128, \"Dimensions\": {\"model\": 5, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 7}, \"StartTime\": 1580323018.62511}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.10893795984441584, \"sum\": 0.10893795984441584, \"min\": 0.10893795984441584}}, \"EndTime\": 1580323018.625248, \"Dimensions\": {\"model\": 6, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 7}, \"StartTime\": 1580323018.625225}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.3322879333496094, \"sum\": 0.3322879333496094, \"min\": 0.3322879333496094}}, \"EndTime\": 1580323018.62537, \"Dimensions\": {\"model\": 7, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 7}, \"StartTime\": 1580323018.625345}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.035413467927412554, \"sum\": 0.035413467927412554, \"min\": 0.035413467927412554}}, \"EndTime\": 1580323018.625673, \"Dimensions\": {\"model\": 8, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 7}, \"StartTime\": 1580323018.625646}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.04155268443714489, \"sum\": 0.04155268443714489, \"min\": 0.04155268443714489}}, \"EndTime\": 1580323018.625938, \"Dimensions\": {\"model\": 9, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 7}, \"StartTime\": 1580323018.625912}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.4676765830300071, \"sum\": 0.4676765830300071, \"min\": 0.4676765830300071}}, \"EndTime\": 1580323018.626213, \"Dimensions\": {\"model\": 10, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 7}, \"StartTime\": 1580323018.626187}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.06855711815573952, \"sum\": 0.06855711815573952, \"min\": 0.06855711815573952}}, \"EndTime\": 1580323018.626517, \"Dimensions\": {\"model\": 11, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 7}, \"StartTime\": 1580323018.626492}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.037703740553422405, \"sum\": 0.037703740553422405, \"min\": 0.037703740553422405}}, \"EndTime\": 1580323018.62663, \"Dimensions\": {\"model\": 12, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 7}, \"StartTime\": 1580323018.626608}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.1041799677068537, \"sum\": 0.1041799677068537, \"min\": 0.1041799677068537}}, \"EndTime\": 1580323018.626697, \"Dimensions\": {\"model\": 13, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 7}, \"StartTime\": 1580323018.626678}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.039538178704001684, \"sum\": 0.039538178704001684, \"min\": 0.039538178704001684}}, \"EndTime\": 1580323018.62676, \"Dimensions\": {\"model\": 14, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 7}, \"StartTime\": 1580323018.626742}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/29/2020 18:36:58 INFO 139893492320064] #quality_metric: host=algo-1, epoch=7, train multiclass_cross_entropy_objective <loss>=0.0336054803675\u001b[0m\n",
      "\u001b[34m[2020-01-29 18:36:58.676] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/validation\", \"epoch\": 23, \"duration\": 35, \"num_examples\": 2, \"num_bytes\": 106704}\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.03709713167507156, \"sum\": 0.03709713167507156, \"min\": 0.03709713167507156}}, \"EndTime\": 1580323018.680933, \"Dimensions\": {\"model\": 0, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 7}, \"StartTime\": 1580323018.680869}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.10849028624664595, \"sum\": 0.10849028624664595, \"min\": 0.10849028624664595}}, \"EndTime\": 1580323018.681032, \"Dimensions\": {\"model\": 1, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 7}, \"StartTime\": 1580323018.681011}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.07402254019671606, \"sum\": 0.07402254019671606, \"min\": 0.07402254019671606}}, \"EndTime\": 1580323018.681097, \"Dimensions\": {\"model\": 2, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 7}, \"StartTime\": 1580323018.68108}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.07130544484868223, \"sum\": 0.07130544484868223, \"min\": 0.07130544484868223}}, \"EndTime\": 1580323018.681155, \"Dimensions\": {\"model\": 3, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 7}, \"StartTime\": 1580323018.681139}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.18872298370649618, \"sum\": 0.18872298370649618, \"min\": 0.18872298370649618}}, \"EndTime\": 1580323018.681236, \"Dimensions\": {\"model\": 4, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 7}, \"StartTime\": 1580323018.681219}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.03952483899197598, \"sum\": 0.03952483899197598, \"min\": 0.03952483899197598}}, \"EndTime\": 1580323018.68129, \"Dimensions\": {\"model\": 5, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 7}, \"StartTime\": 1580323018.681275}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.10459474931683457, \"sum\": 0.10459474931683457, \"min\": 0.10459474931683457}}, \"EndTime\": 1580323018.681351, \"Dimensions\": {\"model\": 6, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 7}, \"StartTime\": 1580323018.681334}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.30428160797407433, \"sum\": 0.30428160797407433, \"min\": 0.30428160797407433}}, \"EndTime\": 1580323018.681412, \"Dimensions\": {\"model\": 7, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 7}, \"StartTime\": 1580323018.681395}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.03831695963335745, \"sum\": 0.03831695963335745, \"min\": 0.03831695963335745}}, \"EndTime\": 1580323018.681467, \"Dimensions\": {\"model\": 8, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 7}, \"StartTime\": 1580323018.681453}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.04446489125610846, \"sum\": 0.04446489125610846, \"min\": 0.04446489125610846}}, \"EndTime\": 1580323018.681524, \"Dimensions\": {\"model\": 9, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 7}, \"StartTime\": 1580323018.681509}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.4351759381622438, \"sum\": 0.4351759381622438, \"min\": 0.4351759381622438}}, \"EndTime\": 1580323018.681577, \"Dimensions\": {\"model\": 10, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 7}, \"StartTime\": 1580323018.681562}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.08070716137184628, \"sum\": 0.08070716137184628, \"min\": 0.08070716137184628}}, \"EndTime\": 1580323018.681629, \"Dimensions\": {\"model\": 11, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 7}, \"StartTime\": 1580323018.681616}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.04174210088938354, \"sum\": 0.04174210088938354, \"min\": 0.04174210088938354}}, \"EndTime\": 1580323018.681679, \"Dimensions\": {\"model\": 12, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 7}, \"StartTime\": 1580323018.681666}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.0979091036818449, \"sum\": 0.0979091036818449, \"min\": 0.0979091036818449}}, \"EndTime\": 1580323018.681729, \"Dimensions\": {\"model\": 13, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 7}, \"StartTime\": 1580323018.681716}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.04132293464362058, \"sum\": 0.04132293464362058, \"min\": 0.04132293464362058}}, \"EndTime\": 1580323018.681779, \"Dimensions\": {\"model\": 14, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 7}, \"StartTime\": 1580323018.681766}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/29/2020 18:36:58 INFO 139893492320064] #quality_metric: host=algo-1, epoch=7, validation multiclass_cross_entropy_objective <loss>=0.0370971316751\u001b[0m\n",
      "\u001b[34m[01/29/2020 18:36:58 INFO 139893492320064] #early_stopping_criteria_metric: host=algo-1, epoch=7, criteria=multiclass_cross_entropy_objective, value=0.0370971316751\u001b[0m\n",
      "\u001b[34m[01/29/2020 18:36:58 INFO 139893492320064] Epoch 7: Loss improved. Updating best model\u001b[0m\n",
      "\u001b[34m[01/29/2020 18:36:58 INFO 139893492320064] #progress_metric: host=algo-1, completed 53 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 12, \"sum\": 12.0, \"min\": 12}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 12, \"sum\": 12.0, \"min\": 12}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 11860, \"sum\": 11860.0, \"min\": 11860}, \"Total Batches Seen\": {\"count\": 1, \"max\": 108, \"sum\": 108.0, \"min\": 108}, \"Total Records Seen\": {\"count\": 1, \"max\": 106880, \"sum\": 106880.0, \"min\": 106880}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 11860, \"sum\": 11860.0, \"min\": 11860}, \"Reset Count\": {\"count\": 1, \"max\": 10, \"sum\": 10.0, \"min\": 10}}, \"EndTime\": 1580323018.684102, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 7}, \"StartTime\": 1580323018.312133}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/29/2020 18:36:58 INFO 139893492320064] #throughput_metric: host=algo-1, train throughput=31863.1387447 records/second\u001b[0m\n",
      "\u001b[34m[2020-01-29 18:36:58.989] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 19, \"duration\": 304, \"num_examples\": 12, \"num_bytes\": 853920}\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.03344407948580655, \"sum\": 0.03344407948580655, \"min\": 0.03344407948580655}}, \"EndTime\": 1580323018.989517, \"Dimensions\": {\"model\": 0, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 8}, \"StartTime\": 1580323018.989438}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.09280934489857066, \"sum\": 0.09280934489857066, \"min\": 0.09280934489857066}}, \"EndTime\": 1580323018.989616, \"Dimensions\": {\"model\": 1, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 8}, \"StartTime\": 1580323018.989595}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.06865732470425692, \"sum\": 0.06865732470425692, \"min\": 0.06865732470425692}}, \"EndTime\": 1580323018.989697, \"Dimensions\": {\"model\": 2, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 8}, \"StartTime\": 1580323018.989676}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.059396569685502484, \"sum\": 0.059396569685502484, \"min\": 0.059396569685502484}}, \"EndTime\": 1580323018.989758, \"Dimensions\": {\"model\": 3, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 8}, \"StartTime\": 1580323018.989743}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.17343424294211648, \"sum\": 0.17343424294211648, \"min\": 0.17343424294211648}}, \"EndTime\": 1580323018.989816, \"Dimensions\": {\"model\": 4, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 8}, \"StartTime\": 1580323018.989801}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.03225133323669434, \"sum\": 0.03225133323669434, \"min\": 0.03225133323669434}}, \"EndTime\": 1580323018.98987, \"Dimensions\": {\"model\": 5, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 8}, \"StartTime\": 1580323018.989856}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.09671224282004616, \"sum\": 0.09671224282004616, \"min\": 0.09671224282004616}}, \"EndTime\": 1580323018.989927, \"Dimensions\": {\"model\": 6, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 8}, \"StartTime\": 1580323018.989911}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.2838702586780895, \"sum\": 0.2838702586780895, \"min\": 0.2838702586780895}}, \"EndTime\": 1580323018.98998, \"Dimensions\": {\"model\": 7, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 8}, \"StartTime\": 1580323018.989967}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.036191551902077415, \"sum\": 0.036191551902077415, \"min\": 0.036191551902077415}}, \"EndTime\": 1580323018.990034, \"Dimensions\": {\"model\": 8, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 8}, \"StartTime\": 1580323018.99002}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.041367087104103785, \"sum\": 0.041367087104103785, \"min\": 0.041367087104103785}}, \"EndTime\": 1580323018.990087, \"Dimensions\": {\"model\": 9, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 8}, \"StartTime\": 1580323018.990073}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.4077165610573509, \"sum\": 0.4077165610573509, \"min\": 0.4077165610573509}}, \"EndTime\": 1580323018.99014, \"Dimensions\": {\"model\": 10, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 8}, \"StartTime\": 1580323018.990126}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.06805293482000177, \"sum\": 0.06805293482000177, \"min\": 0.06805293482000177}}, \"EndTime\": 1580323018.990197, \"Dimensions\": {\"model\": 11, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 8}, \"StartTime\": 1580323018.990182}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.037924157922918145, \"sum\": 0.037924157922918145, \"min\": 0.037924157922918145}}, \"EndTime\": 1580323018.990253, \"Dimensions\": {\"model\": 12, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 8}, \"StartTime\": 1580323018.990239}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.08423411490700462, \"sum\": 0.08423411490700462, \"min\": 0.08423411490700462}}, \"EndTime\": 1580323018.990307, \"Dimensions\": {\"model\": 13, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 8}, \"StartTime\": 1580323018.990293}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.038443457690152255, \"sum\": 0.038443457690152255, \"min\": 0.038443457690152255}}, \"EndTime\": 1580323018.99036, \"Dimensions\": {\"model\": 14, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 8}, \"StartTime\": 1580323018.990346}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/29/2020 18:36:58 INFO 139893492320064] #quality_metric: host=algo-1, epoch=8, train multiclass_cross_entropy_objective <loss>=0.0334440794858\u001b[0m\n",
      "\u001b[34m[2020-01-29 18:36:59.034] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/validation\", \"epoch\": 26, \"duration\": 30, \"num_examples\": 2, \"num_bytes\": 106704}\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.03694476901117446, \"sum\": 0.03694476901117446, \"min\": 0.03694476901117446}}, \"EndTime\": 1580323019.038254, \"Dimensions\": {\"model\": 0, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 8}, \"StartTime\": 1580323019.038209}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.0880386285614549, \"sum\": 0.0880386285614549, \"min\": 0.0880386285614549}}, \"EndTime\": 1580323019.038336, \"Dimensions\": {\"model\": 1, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 8}, \"StartTime\": 1580323019.038314}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.0685868179588987, \"sum\": 0.0685868179588987, \"min\": 0.0685868179588987}}, \"EndTime\": 1580323019.038407, \"Dimensions\": {\"model\": 2, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 8}, \"StartTime\": 1580323019.038387}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.060220902426201, \"sum\": 0.060220902426201, \"min\": 0.060220902426201}}, \"EndTime\": 1580323019.038581, \"Dimensions\": {\"model\": 3, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 8}, \"StartTime\": 1580323019.038556}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.16344168247320714, \"sum\": 0.16344168247320714, \"min\": 0.16344168247320714}}, \"EndTime\": 1580323019.038754, \"Dimensions\": {\"model\": 4, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 8}, \"StartTime\": 1580323019.038732}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.039437008290155694, \"sum\": 0.039437008290155694, \"min\": 0.039437008290155694}}, \"EndTime\": 1580323019.038821, \"Dimensions\": {\"model\": 5, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 8}, \"StartTime\": 1580323019.038803}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.09429102548864367, \"sum\": 0.09429102548864367, \"min\": 0.09429102548864367}}, \"EndTime\": 1580323019.038886, \"Dimensions\": {\"model\": 6, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 8}, \"StartTime\": 1580323019.038868}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.2630593355207147, \"sum\": 0.2630593355207147, \"min\": 0.2630593355207147}}, \"EndTime\": 1580323019.038954, \"Dimensions\": {\"model\": 7, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 8}, \"StartTime\": 1580323019.038937}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.039978552443778466, \"sum\": 0.039978552443778466, \"min\": 0.039978552443778466}}, \"EndTime\": 1580323019.039022, \"Dimensions\": {\"model\": 8, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 8}, \"StartTime\": 1580323019.039004}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.04478755750154194, \"sum\": 0.04478755750154194, \"min\": 0.04478755750154194}}, \"EndTime\": 1580323019.039084, \"Dimensions\": {\"model\": 9, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 8}, \"StartTime\": 1580323019.039067}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.3819633102931796, \"sum\": 0.3819633102931796, \"min\": 0.3819633102931796}}, \"EndTime\": 1580323019.039147, \"Dimensions\": {\"model\": 10, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 8}, \"StartTime\": 1580323019.039129}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.08035542929542532, \"sum\": 0.08035542929542532, \"min\": 0.08035542929542532}}, \"EndTime\": 1580323019.03921, \"Dimensions\": {\"model\": 11, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 8}, \"StartTime\": 1580323019.039193}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.042012508098895736, \"sum\": 0.042012508098895736, \"min\": 0.042012508098895736}}, \"EndTime\": 1580323019.039274, \"Dimensions\": {\"model\": 12, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 8}, \"StartTime\": 1580323019.039256}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.08146217027012957, \"sum\": 0.08146217027012957, \"min\": 0.08146217027012957}}, \"EndTime\": 1580323019.039336, \"Dimensions\": {\"model\": 13, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 8}, \"StartTime\": 1580323019.039318}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.04013741836856734, \"sum\": 0.04013741836856734, \"min\": 0.04013741836856734}}, \"EndTime\": 1580323019.039399, \"Dimensions\": {\"model\": 14, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 8}, \"StartTime\": 1580323019.039383}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/29/2020 18:36:59 INFO 139893492320064] #quality_metric: host=algo-1, epoch=8, validation multiclass_cross_entropy_objective <loss>=0.0369447690112\u001b[0m\n",
      "\u001b[34m[01/29/2020 18:36:59 INFO 139893492320064] #early_stopping_criteria_metric: host=algo-1, epoch=8, criteria=multiclass_cross_entropy_objective, value=0.0369447690112\u001b[0m\n",
      "\u001b[34m[01/29/2020 18:36:59 INFO 139893492320064] Epoch 8: Loss improved. Updating best model\u001b[0m\n",
      "\u001b[34m[01/29/2020 18:36:59 INFO 139893492320064] #progress_metric: host=algo-1, completed 60 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 12, \"sum\": 12.0, \"min\": 12}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 12, \"sum\": 12.0, \"min\": 12}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 11860, \"sum\": 11860.0, \"min\": 11860}, \"Total Batches Seen\": {\"count\": 1, \"max\": 120, \"sum\": 120.0, \"min\": 120}, \"Total Records Seen\": {\"count\": 1, \"max\": 118740, \"sum\": 118740.0, \"min\": 118740}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 11860, \"sum\": 11860.0, \"min\": 11860}, \"Reset Count\": {\"count\": 1, \"max\": 11, \"sum\": 11.0, \"min\": 11}}, \"EndTime\": 1580323019.040947, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 8}, \"StartTime\": 1580323018.684668}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/29/2020 18:36:59 INFO 139893492320064] #throughput_metric: host=algo-1, train throughput=33276.5698361 records/second\u001b[0m\n",
      "\u001b[34m[2020-01-29 18:36:59.338] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 21, \"duration\": 296, \"num_examples\": 12, \"num_bytes\": 853920}\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.033336092342029916, \"sum\": 0.033336092342029916, \"min\": 0.033336092342029916}}, \"EndTime\": 1580323019.338206, \"Dimensions\": {\"model\": 0, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 9}, \"StartTime\": 1580323019.338108}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.07454009662974964, \"sum\": 0.07454009662974964, \"min\": 0.07454009662974964}}, \"EndTime\": 1580323019.33832, \"Dimensions\": {\"model\": 1, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 9}, \"StartTime\": 1580323019.338272}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.06372680733420633, \"sum\": 0.06372680733420633, \"min\": 0.06372680733420633}}, \"EndTime\": 1580323019.338421, \"Dimensions\": {\"model\": 2, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 9}, \"StartTime\": 1580323019.338399}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.049996051441539416, \"sum\": 0.049996051441539416, \"min\": 0.049996051441539416}}, \"EndTime\": 1580323019.338486, \"Dimensions\": {\"model\": 3, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 9}, \"StartTime\": 1580323019.338469}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.1511281211159446, \"sum\": 0.1511281211159446, \"min\": 0.1511281211159446}}, \"EndTime\": 1580323019.338615, \"Dimensions\": {\"model\": 4, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 9}, \"StartTime\": 1580323019.338593}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.032079661282626064, \"sum\": 0.032079661282626064, \"min\": 0.032079661282626064}}, \"EndTime\": 1580323019.338682, \"Dimensions\": {\"model\": 5, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 9}, \"StartTime\": 1580323019.338664}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.08739597389914773, \"sum\": 0.08739597389914773, \"min\": 0.08739597389914773}}, \"EndTime\": 1580323019.338767, \"Dimensions\": {\"model\": 6, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 9}, \"StartTime\": 1580323019.338748}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.24691486705433238, \"sum\": 0.24691486705433238, \"min\": 0.24691486705433238}}, \"EndTime\": 1580323019.338824, \"Dimensions\": {\"model\": 7, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 9}, \"StartTime\": 1580323019.338807}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.03808112959428267, \"sum\": 0.03808112959428267, \"min\": 0.03808112959428267}}, \"EndTime\": 1580323019.338886, \"Dimensions\": {\"model\": 8, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 9}, \"StartTime\": 1580323019.338869}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.04141572484103116, \"sum\": 0.04141572484103116, \"min\": 0.04141572484103116}}, \"EndTime\": 1580323019.33894, \"Dimensions\": {\"model\": 9, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 9}, \"StartTime\": 1580323019.338924}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.3590665865811435, \"sum\": 0.3590665865811435, \"min\": 0.3590665865811435}}, \"EndTime\": 1580323019.339004, \"Dimensions\": {\"model\": 10, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 9}, \"StartTime\": 1580323019.338988}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.06804669883034446, \"sum\": 0.06804669883034446, \"min\": 0.06804669883034446}}, \"EndTime\": 1580323019.339066, \"Dimensions\": {\"model\": 11, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 9}, \"StartTime\": 1580323019.33905}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.03819265591014515, \"sum\": 0.03819265591014515, \"min\": 0.03819265591014515}}, \"EndTime\": 1580323019.339126, \"Dimensions\": {\"model\": 12, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 9}, \"StartTime\": 1580323019.33911}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.06992596470225941, \"sum\": 0.06992596470225941, \"min\": 0.06992596470225941}}, \"EndTime\": 1580323019.339188, \"Dimensions\": {\"model\": 13, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 9}, \"StartTime\": 1580323019.33917}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.037533580780029295, \"sum\": 0.037533580780029295, \"min\": 0.037533580780029295}}, \"EndTime\": 1580323019.339254, \"Dimensions\": {\"model\": 14, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 9}, \"StartTime\": 1580323019.339236}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/29/2020 18:36:59 INFO 139893492320064] #quality_metric: host=algo-1, epoch=9, train multiclass_cross_entropy_objective <loss>=0.033336092342\u001b[0m\n",
      "\u001b[34m[2020-01-29 18:36:59.382] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/validation\", \"epoch\": 29, \"duration\": 32, \"num_examples\": 2, \"num_bytes\": 106704}\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.036848348805457155, \"sum\": 0.036848348805457155, \"min\": 0.036848348805457155}}, \"EndTime\": 1580323019.386653, \"Dimensions\": {\"model\": 0, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 9}, \"StartTime\": 1580323019.386612}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.07316942768380066, \"sum\": 0.07316942768380066, \"min\": 0.07316942768380066}}, \"EndTime\": 1580323019.386729, \"Dimensions\": {\"model\": 1, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 9}, \"StartTime\": 1580323019.386708}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.06425349947251129, \"sum\": 0.06425349947251129, \"min\": 0.06425349947251129}}, \"EndTime\": 1580323019.386802, \"Dimensions\": {\"model\": 2, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 9}, \"StartTime\": 1580323019.386782}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.05260788380858387, \"sum\": 0.05260788380858387, \"min\": 0.05260788380858387}}, \"EndTime\": 1580323019.38687, \"Dimensions\": {\"model\": 3, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 9}, \"StartTime\": 1580323019.386851}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.1445419836623466, \"sum\": 0.1445419836623466, \"min\": 0.1445419836623466}}, \"EndTime\": 1580323019.386935, \"Dimensions\": {\"model\": 4, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 9}, \"StartTime\": 1580323019.386918}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.03939600801660947, \"sum\": 0.03939600801660947, \"min\": 0.03939600801660947}}, \"EndTime\": 1580323019.387004, \"Dimensions\": {\"model\": 5, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 9}, \"StartTime\": 1580323019.386987}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.08611450246792896, \"sum\": 0.08611450246792896, \"min\": 0.08611450246792896}}, \"EndTime\": 1580323019.387068, \"Dimensions\": {\"model\": 6, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 9}, \"StartTime\": 1580323019.387051}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.23081001868614784, \"sum\": 0.23081001868614784, \"min\": 0.23081001868614784}}, \"EndTime\": 1580323019.38713, \"Dimensions\": {\"model\": 7, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 9}, \"StartTime\": 1580323019.387113}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.04151819978165723, \"sum\": 0.04151819978165723, \"min\": 0.04151819978165723}}, \"EndTime\": 1580323019.38719, \"Dimensions\": {\"model\": 8, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 9}, \"StartTime\": 1580323019.387174}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.04442254477023435, \"sum\": 0.04442254477023435, \"min\": 0.04442254477023435}}, \"EndTime\": 1580323019.387249, \"Dimensions\": {\"model\": 9, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 9}, \"StartTime\": 1580323019.387232}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.33857261668010924, \"sum\": 0.33857261668010924, \"min\": 0.33857261668010924}}, \"EndTime\": 1580323019.387299, \"Dimensions\": {\"model\": 10, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 9}, \"StartTime\": 1580323019.387283}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.08122093056538487, \"sum\": 0.08122093056538487, \"min\": 0.08122093056538487}}, \"EndTime\": 1580323019.38735, \"Dimensions\": {\"model\": 11, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 9}, \"StartTime\": 1580323019.387334}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.04228890762637984, \"sum\": 0.04228890762637984, \"min\": 0.04228890762637984}}, \"EndTime\": 1580323019.38741, \"Dimensions\": {\"model\": 12, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 9}, \"StartTime\": 1580323019.387395}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.0695263866470893, \"sum\": 0.0695263866470893, \"min\": 0.0695263866470893}}, \"EndTime\": 1580323019.387472, \"Dimensions\": {\"model\": 13, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 9}, \"StartTime\": 1580323019.387456}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.03971100497020562, \"sum\": 0.03971100497020562, \"min\": 0.03971100497020562}}, \"EndTime\": 1580323019.387534, \"Dimensions\": {\"model\": 14, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 9}, \"StartTime\": 1580323019.387517}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/29/2020 18:36:59 INFO 139893492320064] #quality_metric: host=algo-1, epoch=9, validation multiclass_cross_entropy_objective <loss>=0.0368483488055\u001b[0m\n",
      "\u001b[34m[01/29/2020 18:36:59 INFO 139893492320064] #early_stopping_criteria_metric: host=algo-1, epoch=9, criteria=multiclass_cross_entropy_objective, value=0.0368483488055\u001b[0m\n",
      "\u001b[34m[01/29/2020 18:36:59 INFO 139893492320064] Epoch 9: Loss improved. Updating best model\u001b[0m\n",
      "\u001b[34m[01/29/2020 18:36:59 INFO 139893492320064] #progress_metric: host=algo-1, completed 66 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 12, \"sum\": 12.0, \"min\": 12}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 12, \"sum\": 12.0, \"min\": 12}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 11860, \"sum\": 11860.0, \"min\": 11860}, \"Total Batches Seen\": {\"count\": 1, \"max\": 132, \"sum\": 132.0, \"min\": 132}, \"Total Records Seen\": {\"count\": 1, \"max\": 130600, \"sum\": 130600.0, \"min\": 130600}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 11860, \"sum\": 11860.0, \"min\": 11860}, \"Reset Count\": {\"count\": 1, \"max\": 12, \"sum\": 12.0, \"min\": 12}}, \"EndTime\": 1580323019.388901, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 9}, \"StartTime\": 1580323019.041187}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/29/2020 18:36:59 INFO 139893492320064] #throughput_metric: host=algo-1, train throughput=34095.8254099 records/second\u001b[0m\n",
      "\u001b[34m[2020-01-29 18:36:59.687] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 23, \"duration\": 296, \"num_examples\": 12, \"num_bytes\": 853920}\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.033251750772649594, \"sum\": 0.033251750772649594, \"min\": 0.033251750772649594}}, \"EndTime\": 1580323019.687585, \"Dimensions\": {\"model\": 0, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 10}, \"StartTime\": 1580323019.687506}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.061575835141268645, \"sum\": 0.061575835141268645, \"min\": 0.061575835141268645}}, \"EndTime\": 1580323019.687702, \"Dimensions\": {\"model\": 1, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 10}, \"StartTime\": 1580323019.687677}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.0597798545143821, \"sum\": 0.0597798545143821, \"min\": 0.0597798545143821}}, \"EndTime\": 1580323019.687777, \"Dimensions\": {\"model\": 2, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 10}, \"StartTime\": 1580323019.687756}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.043464602036909626, \"sum\": 0.043464602036909626, \"min\": 0.043464602036909626}}, \"EndTime\": 1580323019.687846, \"Dimensions\": {\"model\": 3, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 10}, \"StartTime\": 1580323019.687826}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.13438328552246093, \"sum\": 0.13438328552246093, \"min\": 0.13438328552246093}}, \"EndTime\": 1580323019.687921, \"Dimensions\": {\"model\": 4, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 10}, \"StartTime\": 1580323019.687901}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.03203508273037997, \"sum\": 0.03203508273037997, \"min\": 0.03203508273037997}}, \"EndTime\": 1580323019.687988, \"Dimensions\": {\"model\": 5, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 10}, \"StartTime\": 1580323019.68797}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.07977160921963779, \"sum\": 0.07977160921963779, \"min\": 0.07977160921963779}}, \"EndTime\": 1580323019.688081, \"Dimensions\": {\"model\": 6, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 10}, \"StartTime\": 1580323019.688062}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.2177990792014382, \"sum\": 0.2177990792014382, \"min\": 0.2177990792014382}}, \"EndTime\": 1580323019.688143, \"Dimensions\": {\"model\": 7, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 10}, \"StartTime\": 1580323019.688125}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.038847081617875534, \"sum\": 0.038847081617875534, \"min\": 0.038847081617875534}}, \"EndTime\": 1580323019.688205, \"Dimensions\": {\"model\": 8, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 10}, \"StartTime\": 1580323019.688187}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.041211945967240766, \"sum\": 0.041211945967240766, \"min\": 0.041211945967240766}}, \"EndTime\": 1580323019.688276, \"Dimensions\": {\"model\": 9, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 10}, \"StartTime\": 1580323019.688257}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.31923868352716617, \"sum\": 0.31923868352716617, \"min\": 0.31923868352716617}}, \"EndTime\": 1580323019.688341, \"Dimensions\": {\"model\": 10, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 10}, \"StartTime\": 1580323019.688324}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.0681555789600719, \"sum\": 0.0681555789600719, \"min\": 0.0681555789600719}}, \"EndTime\": 1580323019.688406, \"Dimensions\": {\"model\": 11, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 10}, \"StartTime\": 1580323019.688389}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.03845463492653586, \"sum\": 0.03845463492653586, \"min\": 0.03845463492653586}}, \"EndTime\": 1580323019.688471, \"Dimensions\": {\"model\": 12, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 10}, \"StartTime\": 1580323019.688454}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.05959622435136275, \"sum\": 0.05959622435136275, \"min\": 0.05959622435136275}}, \"EndTime\": 1580323019.688533, \"Dimensions\": {\"model\": 13, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 10}, \"StartTime\": 1580323019.688516}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.03705254502729936, \"sum\": 0.03705254502729936, \"min\": 0.03705254502729936}}, \"EndTime\": 1580323019.688597, \"Dimensions\": {\"model\": 14, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 10}, \"StartTime\": 1580323019.68858}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/29/2020 18:36:59 INFO 139893492320064] #quality_metric: host=algo-1, epoch=10, train multiclass_cross_entropy_objective <loss>=0.0332517507726\u001b[0m\n",
      "\u001b[34m[2020-01-29 18:36:59.723] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/validation\", \"epoch\": 32, \"duration\": 24, \"num_examples\": 2, \"num_bytes\": 106704}\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.036767601805981674, \"sum\": 0.036767601805981674, \"min\": 0.036767601805981674}}, \"EndTime\": 1580323019.726072, \"Dimensions\": {\"model\": 0, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 10}, \"StartTime\": 1580323019.726033}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.06282826087735442, \"sum\": 0.06282826087735442, \"min\": 0.06282826087735442}}, \"EndTime\": 1580323019.726145, \"Dimensions\": {\"model\": 1, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 10}, \"StartTime\": 1580323019.726125}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.06078864495281266, \"sum\": 0.06078864495281266, \"min\": 0.06078864495281266}}, \"EndTime\": 1580323019.72622, \"Dimensions\": {\"model\": 2, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 10}, \"StartTime\": 1580323019.7262}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.04735952704219844, \"sum\": 0.04735952704219844, \"min\": 0.04735952704219844}}, \"EndTime\": 1580323019.726294, \"Dimensions\": {\"model\": 3, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 10}, \"StartTime\": 1580323019.726274}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.13025739929775798, \"sum\": 0.13025739929775798, \"min\": 0.13025739929775798}}, \"EndTime\": 1580323019.72636, \"Dimensions\": {\"model\": 4, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 10}, \"StartTime\": 1580323019.726342}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.039403816305513165, \"sum\": 0.039403816305513165, \"min\": 0.039403816305513165}}, \"EndTime\": 1580323019.726423, \"Dimensions\": {\"model\": 5, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 10}, \"StartTime\": 1580323019.726407}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.07923753509315563, \"sum\": 0.07923753509315563, \"min\": 0.07923753509315563}}, \"EndTime\": 1580323019.726484, \"Dimensions\": {\"model\": 6, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 10}, \"StartTime\": 1580323019.726468}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.20516480768901293, \"sum\": 0.20516480768901293, \"min\": 0.20516480768901293}}, \"EndTime\": 1580323019.726552, \"Dimensions\": {\"model\": 7, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 10}, \"StartTime\": 1580323019.726535}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.04111730006703159, \"sum\": 0.04111730006703159, \"min\": 0.04111730006703159}}, \"EndTime\": 1580323019.726622, \"Dimensions\": {\"model\": 8, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 10}, \"StartTime\": 1580323019.726603}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.0449342032675801, \"sum\": 0.0449342032675801, \"min\": 0.0449342032675801}}, \"EndTime\": 1580323019.72668, \"Dimensions\": {\"model\": 9, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 10}, \"StartTime\": 1580323019.726663}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.30287106574466516, \"sum\": 0.30287106574466516, \"min\": 0.30287106574466516}}, \"EndTime\": 1580323019.726745, \"Dimensions\": {\"model\": 10, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 10}, \"StartTime\": 1580323019.726728}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.08062080300932149, \"sum\": 0.08062080300932149, \"min\": 0.08062080300932149}}, \"EndTime\": 1580323019.726823, \"Dimensions\": {\"model\": 11, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 10}, \"StartTime\": 1580323019.726804}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.04252291304862451, \"sum\": 0.04252291304862451, \"min\": 0.04252291304862451}}, \"EndTime\": 1580323019.726892, \"Dimensions\": {\"model\": 12, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 10}, \"StartTime\": 1580323019.726874}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.06080179561970205, \"sum\": 0.06080179561970205, \"min\": 0.06080179561970205}}, \"EndTime\": 1580323019.726959, \"Dimensions\": {\"model\": 13, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 10}, \"StartTime\": 1580323019.726941}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.0391139610897996, \"sum\": 0.0391139610897996, \"min\": 0.0391139610897996}}, \"EndTime\": 1580323019.727015, \"Dimensions\": {\"model\": 14, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 10}, \"StartTime\": 1580323019.726999}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/29/2020 18:36:59 INFO 139893492320064] #quality_metric: host=algo-1, epoch=10, validation multiclass_cross_entropy_objective <loss>=0.036767601806\u001b[0m\n",
      "\u001b[34m[01/29/2020 18:36:59 INFO 139893492320064] #early_stopping_criteria_metric: host=algo-1, epoch=10, criteria=multiclass_cross_entropy_objective, value=0.036767601806\u001b[0m\n",
      "\u001b[34m[01/29/2020 18:36:59 INFO 139893492320064] Epoch 10: Loss improved. Updating best model\u001b[0m\n",
      "\u001b[34m[01/29/2020 18:36:59 INFO 139893492320064] #progress_metric: host=algo-1, completed 73 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 12, \"sum\": 12.0, \"min\": 12}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 12, \"sum\": 12.0, \"min\": 12}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 11860, \"sum\": 11860.0, \"min\": 11860}, \"Total Batches Seen\": {\"count\": 1, \"max\": 144, \"sum\": 144.0, \"min\": 144}, \"Total Records Seen\": {\"count\": 1, \"max\": 142460, \"sum\": 142460.0, \"min\": 142460}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 11860, \"sum\": 11860.0, \"min\": 11860}, \"Reset Count\": {\"count\": 1, \"max\": 13, \"sum\": 13.0, \"min\": 13}}, \"EndTime\": 1580323019.728507, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 10}, \"StartTime\": 1580323019.389186}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/29/2020 18:36:59 INFO 139893492320064] #throughput_metric: host=algo-1, train throughput=34934.7370402 records/second\u001b[0m\n",
      "\u001b[34m[2020-01-29 18:36:59.984] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 25, \"duration\": 255, \"num_examples\": 12, \"num_bytes\": 853920}\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.03317310333251953, \"sum\": 0.03317310333251953, \"min\": 0.03317310333251953}}, \"EndTime\": 1580323019.984132, \"Dimensions\": {\"model\": 0, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 11}, \"StartTime\": 1580323019.984063}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.05259469708529386, \"sum\": 0.05259469708529386, \"min\": 0.05259469708529386}}, \"EndTime\": 1580323019.984228, \"Dimensions\": {\"model\": 1, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 11}, \"StartTime\": 1580323019.984211}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.0565837007002397, \"sum\": 0.0565837007002397, \"min\": 0.0565837007002397}}, \"EndTime\": 1580323019.984283, \"Dimensions\": {\"model\": 2, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 11}, \"StartTime\": 1580323019.98427}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.038964818607677115, \"sum\": 0.038964818607677115, \"min\": 0.038964818607677115}}, \"EndTime\": 1580323019.984333, \"Dimensions\": {\"model\": 3, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 11}, \"StartTime\": 1580323019.984321}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.12151031702215022, \"sum\": 0.12151031702215022, \"min\": 0.12151031702215022}}, \"EndTime\": 1580323019.984381, \"Dimensions\": {\"model\": 4, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 11}, \"StartTime\": 1580323019.984369}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.03203919913552024, \"sum\": 0.03203919913552024, \"min\": 0.03203919913552024}}, \"EndTime\": 1580323019.984427, \"Dimensions\": {\"model\": 5, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 11}, \"StartTime\": 1580323019.984416}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.07349766783280806, \"sum\": 0.07349766783280806, \"min\": 0.07349766783280806}}, \"EndTime\": 1580323019.984471, \"Dimensions\": {\"model\": 6, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 11}, \"StartTime\": 1580323019.98446}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.19449609097567472, \"sum\": 0.19449609097567472, \"min\": 0.19449609097567472}}, \"EndTime\": 1580323019.984514, \"Dimensions\": {\"model\": 7, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 11}, \"StartTime\": 1580323019.984503}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.03823141652887518, \"sum\": 0.03823141652887518, \"min\": 0.03823141652887518}}, \"EndTime\": 1580323019.984559, \"Dimensions\": {\"model\": 8, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 11}, \"StartTime\": 1580323019.984548}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.04134099613536488, \"sum\": 0.04134099613536488, \"min\": 0.04134099613536488}}, \"EndTime\": 1580323019.984604, \"Dimensions\": {\"model\": 9, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 11}, \"StartTime\": 1580323019.984593}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.28631712757457384, \"sum\": 0.28631712757457384, \"min\": 0.28631712757457384}}, \"EndTime\": 1580323019.984647, \"Dimensions\": {\"model\": 10, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 11}, \"StartTime\": 1580323019.984636}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.06823825420032847, \"sum\": 0.06823825420032847, \"min\": 0.06823825420032847}}, \"EndTime\": 1580323019.984698, \"Dimensions\": {\"model\": 11, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 11}, \"StartTime\": 1580323019.984685}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.03868142023953525, \"sum\": 0.03868142023953525, \"min\": 0.03868142023953525}}, \"EndTime\": 1580323019.984744, \"Dimensions\": {\"model\": 12, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 11}, \"StartTime\": 1580323019.984733}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.051832222331653945, \"sum\": 0.051832222331653945, \"min\": 0.051832222331653945}}, \"EndTime\": 1580323019.98479, \"Dimensions\": {\"model\": 13, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 11}, \"StartTime\": 1580323019.984778}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.036498722769997334, \"sum\": 0.036498722769997334, \"min\": 0.036498722769997334}}, \"EndTime\": 1580323019.984833, \"Dimensions\": {\"model\": 14, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 11}, \"StartTime\": 1580323019.984822}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/29/2020 18:36:59 INFO 139893492320064] #quality_metric: host=algo-1, epoch=11, train multiclass_cross_entropy_objective <loss>=0.0331731033325\u001b[0m\n",
      "\u001b[34m[2020-01-29 18:37:00.019] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/validation\", \"epoch\": 35, \"duration\": 24, \"num_examples\": 2, \"num_bytes\": 106704}\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.036687516329581275, \"sum\": 0.036687516329581275, \"min\": 0.036687516329581275}}, \"EndTime\": 1580323020.022818, \"Dimensions\": {\"model\": 0, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 11}, \"StartTime\": 1580323020.022764}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.055667458919056674, \"sum\": 0.055667458919056674, \"min\": 0.055667458919056674}}, \"EndTime\": 1580323020.022913, \"Dimensions\": {\"model\": 1, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 11}, \"StartTime\": 1580323020.022889}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.05797110234516674, \"sum\": 0.05797110234516674, \"min\": 0.05797110234516674}}, \"EndTime\": 1580323020.022977, \"Dimensions\": {\"model\": 2, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 11}, \"StartTime\": 1580323020.022964}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.043836878057111776, \"sum\": 0.043836878057111776, \"min\": 0.043836878057111776}}, \"EndTime\": 1580323020.023034, \"Dimensions\": {\"model\": 3, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 11}, \"StartTime\": 1580323020.023016}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.1190553837620456, \"sum\": 0.1190553837620456, \"min\": 0.1190553837620456}}, \"EndTime\": 1580323020.023098, \"Dimensions\": {\"model\": 4, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 11}, \"StartTime\": 1580323020.023081}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.03939658974507238, \"sum\": 0.03939658974507238, \"min\": 0.03939658974507238}}, \"EndTime\": 1580323020.02316, \"Dimensions\": {\"model\": 5, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 11}, \"StartTime\": 1580323020.023143}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.0737571458906619, \"sum\": 0.0737571458906619, \"min\": 0.0737571458906619}}, \"EndTime\": 1580323020.023226, \"Dimensions\": {\"model\": 6, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 11}, \"StartTime\": 1580323020.023207}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.18462668353246775, \"sum\": 0.18462668353246775, \"min\": 0.18462668353246775}}, \"EndTime\": 1580323020.023276, \"Dimensions\": {\"model\": 7, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 11}, \"StartTime\": 1580323020.023265}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.040394422657254896, \"sum\": 0.040394422657254896, \"min\": 0.040394422657254896}}, \"EndTime\": 1580323020.023337, \"Dimensions\": {\"model\": 8, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 11}, \"StartTime\": 1580323020.02332}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.04448854392356718, \"sum\": 0.04448854392356718, \"min\": 0.04448854392356718}}, \"EndTime\": 1580323020.023397, \"Dimensions\": {\"model\": 9, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 11}, \"StartTime\": 1580323020.02338}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.27319559362414075, \"sum\": 0.27319559362414075, \"min\": 0.27319559362414075}}, \"EndTime\": 1580323020.023458, \"Dimensions\": {\"model\": 10, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 11}, \"StartTime\": 1580323020.023443}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.08087782402913742, \"sum\": 0.08087782402913742, \"min\": 0.08087782402913742}}, \"EndTime\": 1580323020.023514, \"Dimensions\": {\"model\": 11, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 11}, \"StartTime\": 1580323020.023496}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.04272240858811598, \"sum\": 0.04272240858811598, \"min\": 0.04272240858811598}}, \"EndTime\": 1580323020.023576, \"Dimensions\": {\"model\": 12, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 11}, \"StartTime\": 1580323020.023559}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.05428405586685407, \"sum\": 0.05428405586685407, \"min\": 0.05428405586685407}}, \"EndTime\": 1580323020.023638, \"Dimensions\": {\"model\": 13, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 11}, \"StartTime\": 1580323020.023621}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.038674385441459624, \"sum\": 0.038674385441459624, \"min\": 0.038674385441459624}}, \"EndTime\": 1580323020.0237, \"Dimensions\": {\"model\": 14, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 11}, \"StartTime\": 1580323020.023683}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/29/2020 18:37:00 INFO 139893492320064] #quality_metric: host=algo-1, epoch=11, validation multiclass_cross_entropy_objective <loss>=0.0366875163296\u001b[0m\n",
      "\u001b[34m[01/29/2020 18:37:00 INFO 139893492320064] #early_stopping_criteria_metric: host=algo-1, epoch=11, criteria=multiclass_cross_entropy_objective, value=0.0366875163296\u001b[0m\n",
      "\u001b[34m[01/29/2020 18:37:00 INFO 139893492320064] Epoch 11: Loss improved. Updating best model\u001b[0m\n",
      "\u001b[34m[01/29/2020 18:37:00 INFO 139893492320064] #progress_metric: host=algo-1, completed 80 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 12, \"sum\": 12.0, \"min\": 12}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 12, \"sum\": 12.0, \"min\": 12}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 11860, \"sum\": 11860.0, \"min\": 11860}, \"Total Batches Seen\": {\"count\": 1, \"max\": 156, \"sum\": 156.0, \"min\": 156}, \"Total Records Seen\": {\"count\": 1, \"max\": 154320, \"sum\": 154320.0, \"min\": 154320}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 11860, \"sum\": 11860.0, \"min\": 11860}, \"Reset Count\": {\"count\": 1, \"max\": 14, \"sum\": 14.0, \"min\": 14}}, \"EndTime\": 1580323020.025203, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 11}, \"StartTime\": 1580323019.728826}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/29/2020 18:37:00 INFO 139893492320064] #throughput_metric: host=algo-1, train throughput=40000.1330324 records/second\u001b[0m\n",
      "\u001b[34m[2020-01-29 18:37:00.265] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 27, \"duration\": 239, \"num_examples\": 12, \"num_bytes\": 853920}\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.03309951920942827, \"sum\": 0.03309951920942827, \"min\": 0.03309951920942827}}, \"EndTime\": 1580323020.265155, \"Dimensions\": {\"model\": 0, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 12}, \"StartTime\": 1580323020.265086}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.04638941088589755, \"sum\": 0.04638941088589755, \"min\": 0.04638941088589755}}, \"EndTime\": 1580323020.265245, \"Dimensions\": {\"model\": 1, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 12}, \"StartTime\": 1580323020.265229}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.05389862442016601, \"sum\": 0.05389862442016601, \"min\": 0.05389862442016601}}, \"EndTime\": 1580323020.265296, \"Dimensions\": {\"model\": 2, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 12}, \"StartTime\": 1580323020.265283}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.03582210852883079, \"sum\": 0.03582210852883079, \"min\": 0.03582210852883079}}, \"EndTime\": 1580323020.265341, \"Dimensions\": {\"model\": 3, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 12}, \"StartTime\": 1580323020.26533}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.11132648398659446, \"sum\": 0.11132648398659446, \"min\": 0.11132648398659446}}, \"EndTime\": 1580323020.265391, \"Dimensions\": {\"model\": 4, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 12}, \"StartTime\": 1580323020.265379}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.032048315395008437, \"sum\": 0.032048315395008437, \"min\": 0.032048315395008437}}, \"EndTime\": 1580323020.265435, \"Dimensions\": {\"model\": 5, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 12}, \"StartTime\": 1580323020.265424}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.06856433209505948, \"sum\": 0.06856433209505948, \"min\": 0.06856433209505948}}, \"EndTime\": 1580323020.265479, \"Dimensions\": {\"model\": 6, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 12}, \"StartTime\": 1580323020.265468}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.1759379189231179, \"sum\": 0.1759379189231179, \"min\": 0.1759379189231179}}, \"EndTime\": 1580323020.265523, \"Dimensions\": {\"model\": 7, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 12}, \"StartTime\": 1580323020.265512}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.03776069068908691, \"sum\": 0.03776069068908691, \"min\": 0.03776069068908691}}, \"EndTime\": 1580323020.265566, \"Dimensions\": {\"model\": 8, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 12}, \"StartTime\": 1580323020.265555}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.041426146767356176, \"sum\": 0.041426146767356176, \"min\": 0.041426146767356176}}, \"EndTime\": 1580323020.265609, \"Dimensions\": {\"model\": 9, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 12}, \"StartTime\": 1580323020.265598}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.25883246820623224, \"sum\": 0.25883246820623224, \"min\": 0.25883246820623224}}, \"EndTime\": 1580323020.265653, \"Dimensions\": {\"model\": 10, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 12}, \"StartTime\": 1580323020.265642}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.06811609649658203, \"sum\": 0.06811609649658203, \"min\": 0.06811609649658203}}, \"EndTime\": 1580323020.265696, \"Dimensions\": {\"model\": 11, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 12}, \"StartTime\": 1580323020.265685}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.038881568041714755, \"sum\": 0.038881568041714755, \"min\": 0.038881568041714755}}, \"EndTime\": 1580323020.265739, \"Dimensions\": {\"model\": 12, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 12}, \"StartTime\": 1580323020.265728}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.04607188762318004, \"sum\": 0.04607188762318004, \"min\": 0.04607188762318004}}, \"EndTime\": 1580323020.265782, \"Dimensions\": {\"model\": 13, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 12}, \"StartTime\": 1580323020.265771}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.03607595114274458, \"sum\": 0.03607595114274458, \"min\": 0.03607595114274458}}, \"EndTime\": 1580323020.265835, \"Dimensions\": {\"model\": 14, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 12}, \"StartTime\": 1580323020.265822}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/29/2020 18:37:00 INFO 139893492320064] #quality_metric: host=algo-1, epoch=12, train multiclass_cross_entropy_objective <loss>=0.0330995192094\u001b[0m\n",
      "\u001b[34m[2020-01-29 18:37:00.300] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/validation\", \"epoch\": 38, \"duration\": 24, \"num_examples\": 2, \"num_bytes\": 106704}\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.036618764262128616, \"sum\": 0.036618764262128616, \"min\": 0.036618764262128616}}, \"EndTime\": 1580323020.303418, \"Dimensions\": {\"model\": 0, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 12}, \"StartTime\": 1580323020.303379}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.05074911722448352, \"sum\": 0.05074911722448352, \"min\": 0.05074911722448352}}, \"EndTime\": 1580323020.303486, \"Dimensions\": {\"model\": 1, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 12}, \"StartTime\": 1580323020.30347}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.05548772541617575, \"sum\": 0.05548772541617575, \"min\": 0.05548772541617575}}, \"EndTime\": 1580323020.303547, \"Dimensions\": {\"model\": 2, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 12}, \"StartTime\": 1580323020.303535}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.04142765735003308, \"sum\": 0.04142765735003308, \"min\": 0.04142765735003308}}, \"EndTime\": 1580323020.303607, \"Dimensions\": {\"model\": 3, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 12}, \"StartTime\": 1580323020.303593}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.11009798551860608, \"sum\": 0.11009798551860608, \"min\": 0.11009798551860608}}, \"EndTime\": 1580323020.303661, \"Dimensions\": {\"model\": 4, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 12}, \"StartTime\": 1580323020.303644}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.039396776361504064, \"sum\": 0.039396776361504064, \"min\": 0.039396776361504064}}, \"EndTime\": 1580323020.303742, \"Dimensions\": {\"model\": 5, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 12}, \"StartTime\": 1580323020.303724}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.06945084431554302, \"sum\": 0.06945084431554302, \"min\": 0.06945084431554302}}, \"EndTime\": 1580323020.303806, \"Dimensions\": {\"model\": 6, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 12}, \"StartTime\": 1580323020.303788}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.168164143839024, \"sum\": 0.168164143839024, \"min\": 0.168164143839024}}, \"EndTime\": 1580323020.303865, \"Dimensions\": {\"model\": 7, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 12}, \"StartTime\": 1580323020.30385}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.040224536066917595, \"sum\": 0.040224536066917595, \"min\": 0.040224536066917595}}, \"EndTime\": 1580323020.303922, \"Dimensions\": {\"model\": 8, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 12}, \"StartTime\": 1580323020.30391}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.04481655898203573, \"sum\": 0.04481655898203573, \"min\": 0.04481655898203573}}, \"EndTime\": 1580323020.303984, \"Dimensions\": {\"model\": 9, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 12}, \"StartTime\": 1580323020.303967}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.24828638238945472, \"sum\": 0.24828638238945472, \"min\": 0.24828638238945472}}, \"EndTime\": 1580323020.304077, \"Dimensions\": {\"model\": 10, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 12}, \"StartTime\": 1580323020.304057}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.08050693867177616, \"sum\": 0.08050693867177616, \"min\": 0.08050693867177616}}, \"EndTime\": 1580323020.304141, \"Dimensions\": {\"model\": 11, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 12}, \"StartTime\": 1580323020.304123}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.042908825533270994, \"sum\": 0.042908825533270994, \"min\": 0.042908825533270994}}, \"EndTime\": 1580323020.304209, \"Dimensions\": {\"model\": 12, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 12}, \"StartTime\": 1580323020.304192}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.049485125522381865, \"sum\": 0.049485125522381865, \"min\": 0.049485125522381865}}, \"EndTime\": 1580323020.304271, \"Dimensions\": {\"model\": 13, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 12}, \"StartTime\": 1580323020.304254}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.038183109319483544, \"sum\": 0.038183109319483544, \"min\": 0.038183109319483544}}, \"EndTime\": 1580323020.304327, \"Dimensions\": {\"model\": 14, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 12}, \"StartTime\": 1580323020.304313}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/29/2020 18:37:00 INFO 139893492320064] #quality_metric: host=algo-1, epoch=12, validation multiclass_cross_entropy_objective <loss>=0.0366187642621\u001b[0m\n",
      "\u001b[34m[01/29/2020 18:37:00 INFO 139893492320064] #early_stopping_criteria_metric: host=algo-1, epoch=12, criteria=multiclass_cross_entropy_objective, value=0.0366187642621\u001b[0m\n",
      "\u001b[34m[01/29/2020 18:37:00 INFO 139893492320064] Epoch 12: Loss improved. Updating best model\u001b[0m\n",
      "\u001b[34m[01/29/2020 18:37:00 INFO 139893492320064] #progress_metric: host=algo-1, completed 86 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 12, \"sum\": 12.0, \"min\": 12}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 12, \"sum\": 12.0, \"min\": 12}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 11860, \"sum\": 11860.0, \"min\": 11860}, \"Total Batches Seen\": {\"count\": 1, \"max\": 168, \"sum\": 168.0, \"min\": 168}, \"Total Records Seen\": {\"count\": 1, \"max\": 166180, \"sum\": 166180.0, \"min\": 166180}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 11860, \"sum\": 11860.0, \"min\": 11860}, \"Reset Count\": {\"count\": 1, \"max\": 15, \"sum\": 15.0, \"min\": 15}}, \"EndTime\": 1580323020.305776, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 12}, \"StartTime\": 1580323020.025439}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/29/2020 18:37:00 INFO 139893492320064] #throughput_metric: host=algo-1, train throughput=42287.0411577 records/second\u001b[0m\n",
      "\u001b[34m[2020-01-29 18:37:00.555] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 29, \"duration\": 249, \"num_examples\": 12, \"num_bytes\": 853920}\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.03303550321405584, \"sum\": 0.03303550321405584, \"min\": 0.03303550321405584}}, \"EndTime\": 1580323020.555815, \"Dimensions\": {\"model\": 0, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 13}, \"StartTime\": 1580323020.555738}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.042118526285344904, \"sum\": 0.042118526285344904, \"min\": 0.042118526285344904}}, \"EndTime\": 1580323020.555917, \"Dimensions\": {\"model\": 1, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 13}, \"StartTime\": 1580323020.555894}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.05146241829612038, \"sum\": 0.05146241829612038, \"min\": 0.05146241829612038}}, \"EndTime\": 1580323020.556172, \"Dimensions\": {\"model\": 2, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 13}, \"StartTime\": 1580323020.556144}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.03373979533802379, \"sum\": 0.03373979533802379, \"min\": 0.03373979533802379}}, \"EndTime\": 1580323020.556253, \"Dimensions\": {\"model\": 3, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 13}, \"StartTime\": 1580323020.556232}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.10312713969837535, \"sum\": 0.10312713969837535, \"min\": 0.10312713969837535}}, \"EndTime\": 1580323020.556323, \"Dimensions\": {\"model\": 4, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 13}, \"StartTime\": 1580323020.556304}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.03205889129638672, \"sum\": 0.03205889129638672, \"min\": 0.03205889129638672}}, \"EndTime\": 1580323020.556388, \"Dimensions\": {\"model\": 5, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 13}, \"StartTime\": 1580323020.55637}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.06462686677412553, \"sum\": 0.06462686677412553, \"min\": 0.06462686677412553}}, \"EndTime\": 1580323020.556452, \"Dimensions\": {\"model\": 6, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 13}, \"StartTime\": 1580323020.556435}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.16074082253196023, \"sum\": 0.16074082253196023, \"min\": 0.16074082253196023}}, \"EndTime\": 1580323020.556516, \"Dimensions\": {\"model\": 7, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 13}, \"StartTime\": 1580323020.556499}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.03774337369745428, \"sum\": 0.03774337369745428, \"min\": 0.03774337369745428}}, \"EndTime\": 1580323020.556579, \"Dimensions\": {\"model\": 8, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 13}, \"StartTime\": 1580323020.556562}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.04123274664445357, \"sum\": 0.04123274664445357, \"min\": 0.04123274664445357}}, \"EndTime\": 1580323020.556641, \"Dimensions\": {\"model\": 9, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 13}, \"StartTime\": 1580323020.556623}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.23567921725186436, \"sum\": 0.23567921725186436, \"min\": 0.23567921725186436}}, \"EndTime\": 1580323020.556699, \"Dimensions\": {\"model\": 10, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 13}, \"StartTime\": 1580323020.556683}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.0681445215398615, \"sum\": 0.0681445215398615, \"min\": 0.0681445215398615}}, \"EndTime\": 1580323020.556761, \"Dimensions\": {\"model\": 11, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 13}, \"StartTime\": 1580323020.556743}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.03905466773293235, \"sum\": 0.03905466773293235, \"min\": 0.03905466773293235}}, \"EndTime\": 1580323020.556822, \"Dimensions\": {\"model\": 12, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 13}, \"StartTime\": 1580323020.556805}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.04175404184514826, \"sum\": 0.04175404184514826, \"min\": 0.04175404184514826}}, \"EndTime\": 1580323020.556885, \"Dimensions\": {\"model\": 13, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 13}, \"StartTime\": 1580323020.556868}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.03585920697992498, \"sum\": 0.03585920697992498, \"min\": 0.03585920697992498}}, \"EndTime\": 1580323020.556945, \"Dimensions\": {\"model\": 14, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 13}, \"StartTime\": 1580323020.556928}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/29/2020 18:37:00 INFO 139893492320064] #quality_metric: host=algo-1, epoch=13, train multiclass_cross_entropy_objective <loss>=0.0330355032141\u001b[0m\n",
      "\u001b[34m[2020-01-29 18:37:00.599] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/validation\", \"epoch\": 41, \"duration\": 29, \"num_examples\": 2, \"num_bytes\": 106704}\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.03656240352573987, \"sum\": 0.03656240352573987, \"min\": 0.03656240352573987}}, \"EndTime\": 1580323020.604787, \"Dimensions\": {\"model\": 0, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 13}, \"StartTime\": 1580323020.60472}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.04739843463769004, \"sum\": 0.04739843463769004, \"min\": 0.04739843463769004}}, \"EndTime\": 1580323020.604896, \"Dimensions\": {\"model\": 1, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 13}, \"StartTime\": 1580323020.604872}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.05317342168728189, \"sum\": 0.05317342168728189, \"min\": 0.05317342168728189}}, \"EndTime\": 1580323020.604982, \"Dimensions\": {\"model\": 2, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 13}, \"StartTime\": 1580323020.604959}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.03987350154984818, \"sum\": 0.03987350154984818, \"min\": 0.03987350154984818}}, \"EndTime\": 1580323020.605062, \"Dimensions\": {\"model\": 3, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 13}, \"StartTime\": 1580323020.605041}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.1028239163953444, \"sum\": 0.1028239163953444, \"min\": 0.1028239163953444}}, \"EndTime\": 1580323020.605135, \"Dimensions\": {\"model\": 4, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 13}, \"StartTime\": 1580323020.605115}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.03940491412493542, \"sum\": 0.03940491412493542, \"min\": 0.03940491412493542}}, \"EndTime\": 1580323020.605211, \"Dimensions\": {\"model\": 5, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 13}, \"StartTime\": 1580323020.605192}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.06594346055456823, \"sum\": 0.06594346055456823, \"min\": 0.06594346055456823}}, \"EndTime\": 1580323020.605277, \"Dimensions\": {\"model\": 6, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 13}, \"StartTime\": 1580323020.60526}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.1544102708659513, \"sum\": 0.1544102708659513, \"min\": 0.1544102708659513}}, \"EndTime\": 1580323020.605345, \"Dimensions\": {\"model\": 7, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 13}, \"StartTime\": 1580323020.605327}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.04037088324666506, \"sum\": 0.04037088324666506, \"min\": 0.04037088324666506}}, \"EndTime\": 1580323020.60541, \"Dimensions\": {\"model\": 8, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 13}, \"StartTime\": 1580323020.605392}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.04452489423043975, \"sum\": 0.04452489423043975, \"min\": 0.04452489423043975}}, \"EndTime\": 1580323020.605473, \"Dimensions\": {\"model\": 9, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 13}, \"StartTime\": 1580323020.605456}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.22728006978105758, \"sum\": 0.22728006978105758, \"min\": 0.22728006978105758}}, \"EndTime\": 1580323020.605535, \"Dimensions\": {\"model\": 10, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 13}, \"StartTime\": 1580323020.605517}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.08113024527566474, \"sum\": 0.08113024527566474, \"min\": 0.08113024527566474}}, \"EndTime\": 1580323020.605601, \"Dimensions\": {\"model\": 11, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 13}, \"StartTime\": 1580323020.605583}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.04305865536173668, \"sum\": 0.04305865536173668, \"min\": 0.04305865536173668}}, \"EndTime\": 1580323020.605664, \"Dimensions\": {\"model\": 12, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 13}, \"StartTime\": 1580323020.605647}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.045971804784859724, \"sum\": 0.045971804784859724, \"min\": 0.045971804784859724}}, \"EndTime\": 1580323020.605727, \"Dimensions\": {\"model\": 13, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 13}, \"StartTime\": 1580323020.605709}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.03787308794605909, \"sum\": 0.03787308794605909, \"min\": 0.03787308794605909}}, \"EndTime\": 1580323020.60579, \"Dimensions\": {\"model\": 14, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 13}, \"StartTime\": 1580323020.605774}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/29/2020 18:37:00 INFO 139893492320064] #quality_metric: host=algo-1, epoch=13, validation multiclass_cross_entropy_objective <loss>=0.0365624035257\u001b[0m\n",
      "\u001b[34m[01/29/2020 18:37:00 INFO 139893492320064] #early_stopping_criteria_metric: host=algo-1, epoch=13, criteria=multiclass_cross_entropy_objective, value=0.0365624035257\u001b[0m\n",
      "\u001b[34m[01/29/2020 18:37:00 INFO 139893492320064] Epoch 13: Loss improved. Updating best model\u001b[0m\n",
      "\u001b[34m[01/29/2020 18:37:00 INFO 139893492320064] #progress_metric: host=algo-1, completed 93 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 12, \"sum\": 12.0, \"min\": 12}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 12, \"sum\": 12.0, \"min\": 12}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 11860, \"sum\": 11860.0, \"min\": 11860}, \"Total Batches Seen\": {\"count\": 1, \"max\": 180, \"sum\": 180.0, \"min\": 180}, \"Total Records Seen\": {\"count\": 1, \"max\": 178040, \"sum\": 178040.0, \"min\": 178040}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 11860, \"sum\": 11860.0, \"min\": 11860}, \"Reset Count\": {\"count\": 1, \"max\": 16, \"sum\": 16.0, \"min\": 16}}, \"EndTime\": 1580323020.607683, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 13}, \"StartTime\": 1580323020.306029}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/29/2020 18:37:00 INFO 139893492320064] #throughput_metric: host=algo-1, train throughput=39296.8944798 records/second\u001b[0m\n",
      "\u001b[34m[2020-01-29 18:37:00.890] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 31, \"duration\": 282, \"num_examples\": 12, \"num_bytes\": 853920}\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.03298163240606135, \"sum\": 0.03298163240606135, \"min\": 0.03298163240606135}}, \"EndTime\": 1580323020.89093, \"Dimensions\": {\"model\": 0, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 14}, \"StartTime\": 1580323020.890862}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.03920168720592152, \"sum\": 0.03920168720592152, \"min\": 0.03920168720592152}}, \"EndTime\": 1580323020.891, \"Dimensions\": {\"model\": 1, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 14}, \"StartTime\": 1580323020.890987}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.04927064652876421, \"sum\": 0.04927064652876421, \"min\": 0.04927064652876421}}, \"EndTime\": 1580323020.891039, \"Dimensions\": {\"model\": 2, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 14}, \"StartTime\": 1580323020.891029}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.03238352654196999, \"sum\": 0.03238352654196999, \"min\": 0.03238352654196999}}, \"EndTime\": 1580323020.891095, \"Dimensions\": {\"model\": 3, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 14}, \"StartTime\": 1580323020.891079}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.0964015717939897, \"sum\": 0.0964015717939897, \"min\": 0.0964015717939897}}, \"EndTime\": 1580323020.89113, \"Dimensions\": {\"model\": 4, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 14}, \"StartTime\": 1580323020.891121}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.03206537472118031, \"sum\": 0.03206537472118031, \"min\": 0.03206537472118031}}, \"EndTime\": 1580323020.891166, \"Dimensions\": {\"model\": 5, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 14}, \"StartTime\": 1580323020.891152}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.06135901468450373, \"sum\": 0.06135901468450373, \"min\": 0.06135901468450373}}, \"EndTime\": 1580323020.891208, \"Dimensions\": {\"model\": 6, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 14}, \"StartTime\": 1580323020.891199}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.14798010670055042, \"sum\": 0.14798010670055042, \"min\": 0.14798010670055042}}, \"EndTime\": 1580323020.891239, \"Dimensions\": {\"model\": 7, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 14}, \"StartTime\": 1580323020.891231}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.03789177218350497, \"sum\": 0.03789177218350497, \"min\": 0.03789177218350497}}, \"EndTime\": 1580323020.891269, \"Dimensions\": {\"model\": 8, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 14}, \"StartTime\": 1580323020.891261}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.041016034733165396, \"sum\": 0.041016034733165396, \"min\": 0.041016034733165396}}, \"EndTime\": 1580323020.891298, \"Dimensions\": {\"model\": 9, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 14}, \"StartTime\": 1580323020.89129}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.2161611591685902, \"sum\": 0.2161611591685902, \"min\": 0.2161611591685902}}, \"EndTime\": 1580323020.89133, \"Dimensions\": {\"model\": 10, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 14}, \"StartTime\": 1580323020.89132}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.06865735522183505, \"sum\": 0.06865735522183505, \"min\": 0.06865735522183505}}, \"EndTime\": 1580323020.89138, \"Dimensions\": {\"model\": 11, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 14}, \"StartTime\": 1580323020.891369}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.039190845489501955, \"sum\": 0.039190845489501955, \"min\": 0.039190845489501955}}, \"EndTime\": 1580323020.89141, \"Dimensions\": {\"model\": 12, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 14}, \"StartTime\": 1580323020.891402}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.03863371918418191, \"sum\": 0.03863371918418191, \"min\": 0.03863371918418191}}, \"EndTime\": 1580323020.891439, \"Dimensions\": {\"model\": 13, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 14}, \"StartTime\": 1580323020.891431}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.035362948330965906, \"sum\": 0.035362948330965906, \"min\": 0.035362948330965906}}, \"EndTime\": 1580323020.891468, \"Dimensions\": {\"model\": 14, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 14}, \"StartTime\": 1580323020.891461}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/29/2020 18:37:00 INFO 139893492320064] #quality_metric: host=algo-1, epoch=14, train multiclass_cross_entropy_objective <loss>=0.0329816324061\u001b[0m\n",
      "\u001b[34m[2020-01-29 18:37:00.923] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/validation\", \"epoch\": 44, \"duration\": 24, \"num_examples\": 2, \"num_bytes\": 106704}\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.036515562801386826, \"sum\": 0.036515562801386826, \"min\": 0.036515562801386826}}, \"EndTime\": 1580323020.926912, \"Dimensions\": {\"model\": 0, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 14}, \"StartTime\": 1580323020.926868}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.04514513517680921, \"sum\": 0.04514513517680921, \"min\": 0.04514513517680921}}, \"EndTime\": 1580323020.926986, \"Dimensions\": {\"model\": 1, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 14}, \"StartTime\": 1580323020.926971}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.05116629761401137, \"sum\": 0.05116629761401137, \"min\": 0.05116629761401137}}, \"EndTime\": 1580323020.927054, \"Dimensions\": {\"model\": 2, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 14}, \"StartTime\": 1580323020.927035}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.038859906627742545, \"sum\": 0.038859906627742545, \"min\": 0.038859906627742545}}, \"EndTime\": 1580323020.927128, \"Dimensions\": {\"model\": 3, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 14}, \"StartTime\": 1580323020.927107}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.09678803313920695, \"sum\": 0.09678803313920695, \"min\": 0.09678803313920695}}, \"EndTime\": 1580323020.927199, \"Dimensions\": {\"model\": 4, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 14}, \"StartTime\": 1580323020.92718}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.0393941624444506, \"sum\": 0.0393941624444506, \"min\": 0.0393941624444506}}, \"EndTime\": 1580323020.927269, \"Dimensions\": {\"model\": 5, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 14}, \"StartTime\": 1580323020.927252}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.06297441114459121, \"sum\": 0.06297441114459121, \"min\": 0.06297441114459121}}, \"EndTime\": 1580323020.927353, \"Dimensions\": {\"model\": 6, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 14}, \"StartTime\": 1580323020.927334}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.1427913722399919, \"sum\": 0.1427913722399919, \"min\": 0.1427913722399919}}, \"EndTime\": 1580323020.927407, \"Dimensions\": {\"model\": 7, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 14}, \"StartTime\": 1580323020.927396}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.040491733473804796, \"sum\": 0.040491733473804796, \"min\": 0.040491733473804796}}, \"EndTime\": 1580323020.927457, \"Dimensions\": {\"model\": 8, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 14}, \"StartTime\": 1580323020.927442}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.04475362548622203, \"sum\": 0.04475362548622203, \"min\": 0.04475362548622203}}, \"EndTime\": 1580323020.927525, \"Dimensions\": {\"model\": 9, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 14}, \"StartTime\": 1580323020.927508}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.20946676689281798, \"sum\": 0.20946676689281798, \"min\": 0.20946676689281798}}, \"EndTime\": 1580323020.927591, \"Dimensions\": {\"model\": 10, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 14}, \"StartTime\": 1580323020.927575}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.08048969788750818, \"sum\": 0.08048969788750818, \"min\": 0.08048969788750818}}, \"EndTime\": 1580323020.927646, \"Dimensions\": {\"model\": 11, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 14}, \"StartTime\": 1580323020.927629}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.04317255830957822, \"sum\": 0.04317255830957822, \"min\": 0.04317255830957822}}, \"EndTime\": 1580323020.927729, \"Dimensions\": {\"model\": 12, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 14}, \"StartTime\": 1580323020.927712}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.04335625580287012, \"sum\": 0.04335625580287012, \"min\": 0.04335625580287012}}, \"EndTime\": 1580323020.927793, \"Dimensions\": {\"model\": 13, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 14}, \"StartTime\": 1580323020.927776}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_multiclass_cross_entropy_objective\": {\"count\": 1, \"max\": 0.03759926372533224, \"sum\": 0.03759926372533224, \"min\": 0.03759926372533224}}, \"EndTime\": 1580323020.927857, \"Dimensions\": {\"model\": 14, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 14}, \"StartTime\": 1580323020.927839}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/29/2020 18:37:00 INFO 139893492320064] #quality_metric: host=algo-1, epoch=14, validation multiclass_cross_entropy_objective <loss>=0.0365155628014\u001b[0m\n",
      "\u001b[34m[01/29/2020 18:37:00 INFO 139893492320064] #early_stopping_criteria_metric: host=algo-1, epoch=14, criteria=multiclass_cross_entropy_objective, value=0.0365155628014\u001b[0m\n",
      "\u001b[34m[01/29/2020 18:37:00 INFO 139893492320064] Epoch 14: Loss improved. Updating best model\u001b[0m\n",
      "\u001b[34m[01/29/2020 18:37:00 INFO 139893492320064] #progress_metric: host=algo-1, completed 100 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 12, \"sum\": 12.0, \"min\": 12}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 12, \"sum\": 12.0, \"min\": 12}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 11860, \"sum\": 11860.0, \"min\": 11860}, \"Total Batches Seen\": {\"count\": 1, \"max\": 192, \"sum\": 192.0, \"min\": 192}, \"Total Records Seen\": {\"count\": 1, \"max\": 189900, \"sum\": 189900.0, \"min\": 189900}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 11860, \"sum\": 11860.0, \"min\": 11860}, \"Reset Count\": {\"count\": 1, \"max\": 17, \"sum\": 17.0, \"min\": 17}}, \"EndTime\": 1580323020.92945, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 14}, \"StartTime\": 1580323020.60799}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/29/2020 18:37:00 INFO 139893492320064] #throughput_metric: host=algo-1, train throughput=36878.7975058 records/second\u001b[0m\n",
      "\u001b[34m[01/29/2020 18:37:00 WARNING 139893492320064] wait_for_all_workers will not sync workers since the kv store is not running distributed\u001b[0m\n",
      "\u001b[34m[01/29/2020 18:37:00 WARNING 139893492320064] wait_for_all_workers will not sync workers since the kv store is not running distributed\u001b[0m\n",
      "\u001b[34m[2020-01-29 18:37:00.965] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/validation\", \"epoch\": 47, \"duration\": 25, \"num_examples\": 2, \"num_bytes\": 106704}\u001b[0m\n",
      "\u001b[34m[01/29/2020 18:37:00 INFO 139893492320064] #early_stopping_criteria_metric: host=algo-1, epoch=14, criteria=multiclass_cross_entropy_objective, value=0.0365155628014\u001b[0m\n",
      "\u001b[34m[2020-01-29 18:37:00.998] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/validation\", \"epoch\": 49, \"duration\": 25, \"num_examples\": 2, \"num_bytes\": 106704}\u001b[0m\n",
      "\u001b[34m[01/29/2020 18:37:01 INFO 139893492320064] #validation_score (algo-1) : ('multiclass_cross_entropy_objective', 0.036515562801386826)\u001b[0m\n",
      "\u001b[34m[01/29/2020 18:37:01 INFO 139893492320064] #validation_score (algo-1) : ('multiclass_accuracy', 0.9865047233468286)\u001b[0m\n",
      "\u001b[34m[01/29/2020 18:37:01 INFO 139893492320064] #validation_score (algo-1) : ('multiclass_top_k_accuracy_3', 0.9966261808367072)\u001b[0m\n",
      "\u001b[34m[01/29/2020 18:37:01 INFO 139893492320064] #validation_score (algo-1) : ('dcg', 0.9932240268640351)\u001b[0m\n",
      "\u001b[34m[01/29/2020 18:37:01 INFO 139893492320064] #validation_score (algo-1) : ('macro_recall', 0.4)\u001b[0m\n",
      "\u001b[34m[01/29/2020 18:37:01 INFO 139893492320064] #validation_score (algo-1) : ('macro_precision', nan)\u001b[0m\n",
      "\u001b[34m[01/29/2020 18:37:01 INFO 139893492320064] #validation_score (algo-1) : ('macro_f_1.000', 0.31666666)\u001b[0m\n",
      "\u001b[34m[01/29/2020 18:37:01 INFO 139893492320064] #quality_metric: host=algo-1, validation multiclass_cross_entropy_objective <loss>=0.0365155628014\u001b[0m\n",
      "\u001b[34m[01/29/2020 18:37:01 INFO 139893492320064] #quality_metric: host=algo-1, validation multiclass_accuracy <score>=0.986504723347\u001b[0m\n",
      "\u001b[34m[01/29/2020 18:37:01 INFO 139893492320064] #quality_metric: host=algo-1, validation multiclass_top_k_accuracy_3 <score>=0.996626180837\u001b[0m\n",
      "\u001b[34m[01/29/2020 18:37:01 INFO 139893492320064] #quality_metric: host=algo-1, validation dcg <score>=0.993224026864\u001b[0m\n",
      "\u001b[34m[01/29/2020 18:37:01 INFO 139893492320064] #quality_metric: host=algo-1, validation macro_recall <score>=0.40000000596\u001b[0m\n",
      "\u001b[34m[01/29/2020 18:37:01 INFO 139893492320064] #quality_metric: host=algo-1, validation macro_precision <score>=nan\u001b[0m\n",
      "\u001b[34m[01/29/2020 18:37:01 INFO 139893492320064] #quality_metric: host=algo-1, validation macro_f_1.000 <score>=0.316666662693\u001b[0m\n",
      "\u001b[34m[01/29/2020 18:37:01 INFO 139893492320064] Best model found for hyperparameters: {\"lr_scheduler_step\": 10, \"wd\": 0.02, \"optimizer\": \"adam\", \"lr_scheduler_factor\": 0.98, \"l1\": 0.02, \"learning_rate\": 0.02, \"lr_scheduler_minimum_lr\": 1e-05}\u001b[0m\n",
      "\u001b[34m[01/29/2020 18:37:01 INFO 139893492320064] Saved checkpoint to \"/tmp/tmpVtcjht/mx-mod-0000.params\"\u001b[0m\n",
      "\u001b[34m[2020-01-29 18:37:01.030] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/test\", \"epoch\": 0, \"duration\": 5285, \"num_examples\": 1, \"num_bytes\": 72000}\u001b[0m\n",
      "\u001b[34m[2020-01-29 18:37:01.047] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/test\", \"epoch\": 1, \"duration\": 16, \"num_examples\": 2, \"num_bytes\": 106776}\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 2, \"sum\": 2.0, \"min\": 2}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 2, \"sum\": 2.0, \"min\": 2}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 1483, \"sum\": 1483.0, \"min\": 1483}, \"Total Batches Seen\": {\"count\": 1, \"max\": 2, \"sum\": 2.0, \"min\": 2}, \"Total Records Seen\": {\"count\": 1, \"max\": 1483, \"sum\": 1483.0, \"min\": 1483}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 1483, \"sum\": 1483.0, \"min\": 1483}, \"Reset Count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1580323021.073115, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"test_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\"}, \"StartTime\": 1580323021.030215}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/29/2020 18:37:01 INFO 139893492320064] #test_score (algo-1) : ('multiclass_cross_entropy_objective', 0.037045372714083175)\u001b[0m\n",
      "\u001b[34m[01/29/2020 18:37:01 INFO 139893492320064] #test_score (algo-1) : ('multiclass_accuracy', 0.9851652056641942)\u001b[0m\n",
      "\u001b[34m[01/29/2020 18:37:01 INFO 139893492320064] #test_score (algo-1) : ('multiclass_top_k_accuracy_3', 0.9932569116655429)\u001b[0m\n",
      "\u001b[34m[01/29/2020 18:37:01 INFO 139893492320064] #test_score (algo-1) : ('dcg', 0.9924376494805714)\u001b[0m\n",
      "\u001b[34m[01/29/2020 18:37:01 INFO 139893492320064] #test_score (algo-1) : ('macro_recall', 0.4)\u001b[0m\n",
      "\u001b[34m[01/29/2020 18:37:01 INFO 139893492320064] #test_score (algo-1) : ('macro_precision', nan)\u001b[0m\n",
      "\u001b[34m[01/29/2020 18:37:01 INFO 139893492320064] #test_score (algo-1) : ('macro_f_1.000', 0.29000002)\u001b[0m\n",
      "\u001b[34m[01/29/2020 18:37:01 INFO 139893492320064] #quality_metric: host=algo-1, test multiclass_cross_entropy_objective <loss>=0.0370453727141\u001b[0m\n",
      "\u001b[34m[01/29/2020 18:37:01 INFO 139893492320064] #quality_metric: host=algo-1, test multiclass_accuracy <score>=0.985165205664\u001b[0m\n",
      "\u001b[34m[01/29/2020 18:37:01 INFO 139893492320064] #quality_metric: host=algo-1, test multiclass_top_k_accuracy_3 <score>=0.993256911666\u001b[0m\n",
      "\u001b[34m[01/29/2020 18:37:01 INFO 139893492320064] #quality_metric: host=algo-1, test dcg <score>=0.992437649481\u001b[0m\n",
      "\u001b[34m[01/29/2020 18:37:01 INFO 139893492320064] #quality_metric: host=algo-1, test macro_recall <score>=0.40000000596\u001b[0m\n",
      "\u001b[34m[01/29/2020 18:37:01 INFO 139893492320064] #quality_metric: host=algo-1, test macro_precision <score>=nan\u001b[0m\n",
      "\u001b[34m[01/29/2020 18:37:01 INFO 139893492320064] #quality_metric: host=algo-1, test macro_f_1.000 <score>=0.290000021458\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"totaltime\": {\"count\": 1, \"max\": 5438.944101333618, \"sum\": 5438.944101333618, \"min\": 5438.944101333618}, \"finalize.time\": {\"count\": 1, \"max\": 95.92008590698242, \"sum\": 95.92008590698242, \"min\": 95.92008590698242}, \"initialize.time\": {\"count\": 1, \"max\": 158.3700180053711, \"sum\": 158.3700180053711, \"min\": 158.3700180053711}, \"check_early_stopping.time\": {\"count\": 16, \"max\": 1.399993896484375, \"sum\": 14.927148818969727, \"min\": 0.2770423889160156}, \"setuptime\": {\"count\": 1, \"max\": 30.198097229003906, \"sum\": 30.198097229003906, \"min\": 30.198097229003906}, \"update.time\": {\"count\": 15, \"max\": 393.42808723449707, \"sum\": 5013.566732406616, \"min\": 280.1499366760254}, \"epochs\": {\"count\": 1, \"max\": 15, \"sum\": 15.0, \"min\": 15}}, \"EndTime\": 1580323021.07947, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\"}, \"StartTime\": 1580323015.735848}\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2020-01-29 18:37:10 Completed - Training job completed\n",
      "Training seconds: 76\n",
      "Billable seconds: 76\n"
     ]
    }
   ],
   "source": [
    "multiclass_estimator.fit([train_records, val_records, test_records])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using already existing model: linear-learner-2020-01-29-18-33-06-589\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------------------------!"
     ]
    }
   ],
   "source": [
    "multiclass_predictor = multiclass_estimator.deploy(initial_instance_count=1, instance_type='ml.m4.xlarge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_metrics(predictor, test_features, test_labels):\n",
    "    \"\"\"\n",
    "    Evaluate a model on a test set using the given prediction endpoint. Display classification metrics.\n",
    "    \"\"\"\n",
    "    # split the test dataset into 100 batches and evaluate using prediction endpoint\n",
    "    prediction_batches = [predictor.predict(batch) for batch in np.array_split(test_features, 100)]\n",
    "\n",
    "    # parse protobuf responses to extract predicted labels\n",
    "    extract_label = lambda x: x.label['predicted_label'].float32_tensor.values\n",
    "    test_preds = np.concatenate([np.array([extract_label(x) for x in batch]) for batch in prediction_batches])\n",
    "    test_preds = test_preds.reshape((-1,))\n",
    "    \n",
    "    # calculate accuracy\n",
    "    accuracy = (test_preds == test_labels).sum() / test_labels.shape[0]\n",
    "    \n",
    "    # calculate recall for each class\n",
    "    recall_per_class, classes = [], []\n",
    "    for target_label in np.unique(test_labels):\n",
    "        recall_numerator = np.logical_and(test_preds == target_label, test_labels == target_label).sum()\n",
    "        recall_denominator = (test_labels == target_label).sum()\n",
    "        recall_per_class.append(recall_numerator / recall_denominator)\n",
    "        classes.append(label_map[target_label])\n",
    "    recall = pd.DataFrame({'recall': recall_per_class, 'class_label': classes})\n",
    "    recall.sort_values('class_label', ascending=False, inplace=True)\n",
    "\n",
    "    # calculate confusion matrix\n",
    "    label_mapper = np.vectorize(lambda x: label_map[x])\n",
    "    confusion_matrix = pd.crosstab(label_mapper(test_labels), label_mapper(test_preds), \n",
    "                                   rownames=['Actuals'], colnames=['Predictions'], normalize='index')\n",
    "\n",
    "    # display results\n",
    "    sns.heatmap(confusion_matrix, annot=True, fmt='.2f', cmap=\"YlGnBu\").set_title('Confusion Matrix')  \n",
    "    ax = recall.plot(kind='barh', x='class_label', y='recall', color='steelblue', title='Recall', legend=False)\n",
    "    ax.set_ylabel('')\n",
    "    print('Accuracy: {:.3f}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.985\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#evaluate metrics of the model trained with default hyperparameters\n",
    "evaluate_metrics(multiclass_predictor, test_features, test_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "#next try witha class balance hyperparamete\n",
    "balanced_multiclass_estimator = sagemaker.LinearLearner(role=sagemaker.get_execution_role(),\n",
    "                                                        train_instance_count=1,\n",
    "                                                        train_instance_type='ml.m4.xlarge',\n",
    "                                                        predictor_type='multiclass_classifier',\n",
    "                                                        num_classes=5,\n",
    "                                                        balance_multiclass_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-01-29 21:58:49 Starting - Starting the training job...\n",
      "2020-01-29 21:58:50 Starting - Launching requested ML instances.........\n",
      "2020-01-29 22:00:24 Starting - Preparing the instances for training...\n",
      "2020-01-29 22:01:18 Downloading - Downloading input data...\n",
      "2020-01-29 22:01:37 Training - Downloading the training image..\u001b[34mDocker entrypoint called with argument(s): train\u001b[0m\n",
      "\u001b[34m[01/29/2020 22:02:02 INFO 139697286510400] Reading default configuration from /opt/amazon/lib/python2.7/site-packages/algorithm/resources/default-input.json: {u'loss_insensitivity': u'0.01', u'epochs': u'15', u'feature_dim': u'auto', u'init_bias': u'0.0', u'lr_scheduler_factor': u'auto', u'num_calibration_samples': u'10000000', u'accuracy_top_k': u'3', u'_num_kv_servers': u'auto', u'use_bias': u'true', u'num_point_for_scaler': u'10000', u'_log_level': u'info', u'quantile': u'0.5', u'bias_lr_mult': u'auto', u'lr_scheduler_step': u'auto', u'init_method': u'uniform', u'init_sigma': u'0.01', u'lr_scheduler_minimum_lr': u'auto', u'target_recall': u'0.8', u'num_models': u'auto', u'early_stopping_patience': u'3', u'momentum': u'auto', u'unbias_label': u'auto', u'wd': u'auto', u'optimizer': u'auto', u'_tuning_objective_metric': u'', u'early_stopping_tolerance': u'0.001', u'learning_rate': u'auto', u'_kvstore': u'auto', u'normalize_data': u'true', u'binary_classifier_model_selection_criteria': u'accuracy', u'use_lr_scheduler': u'true', u'target_precision': u'0.8', u'unbias_data': u'auto', u'init_scale': u'0.07', u'bias_wd_mult': u'auto', u'f_beta': u'1.0', u'mini_batch_size': u'1000', u'huber_delta': u'1.0', u'num_classes': u'1', u'beta_1': u'auto', u'loss': u'auto', u'beta_2': u'auto', u'_enable_profiler': u'false', u'normalize_label': u'auto', u'_num_gpus': u'auto', u'balance_multiclass_weights': u'false', u'positive_example_weight_mult': u'1.0', u'l1': u'auto', u'margin': u'1.0'}\u001b[0m\n",
      "\u001b[34m[01/29/2020 22:02:02 INFO 139697286510400] Reading provided configuration from /opt/ml/input/config/hyperparameters.json: {u'balance_multiclass_weights': u'True', u'feature_dim': u'7', u'mini_batch_size': u'1000', u'predictor_type': u'multiclass_classifier', u'num_classes': u'5'}\u001b[0m\n",
      "\u001b[34m[01/29/2020 22:02:02 INFO 139697286510400] Final configuration: {u'loss_insensitivity': u'0.01', u'epochs': u'15', u'feature_dim': u'7', u'init_bias': u'0.0', u'lr_scheduler_factor': u'auto', u'num_calibration_samples': u'10000000', u'accuracy_top_k': u'3', u'_num_kv_servers': u'auto', u'use_bias': u'true', u'num_point_for_scaler': u'10000', u'_log_level': u'info', u'quantile': u'0.5', u'bias_lr_mult': u'auto', u'lr_scheduler_step': u'auto', u'init_method': u'uniform', u'init_sigma': u'0.01', u'lr_scheduler_minimum_lr': u'auto', u'target_recall': u'0.8', u'num_models': u'auto', u'early_stopping_patience': u'3', u'momentum': u'auto', u'unbias_label': u'auto', u'wd': u'auto', u'optimizer': u'auto', u'_tuning_objective_metric': u'', u'early_stopping_tolerance': u'0.001', u'learning_rate': u'auto', u'_kvstore': u'auto', u'normalize_data': u'true', u'binary_classifier_model_selection_criteria': u'accuracy', u'use_lr_scheduler': u'true', u'target_precision': u'0.8', u'unbias_data': u'auto', u'init_scale': u'0.07', u'bias_wd_mult': u'auto', u'f_beta': u'1.0', u'mini_batch_size': u'1000', u'huber_delta': u'1.0', u'num_classes': u'5', u'predictor_type': u'multiclass_classifier', u'beta_1': u'auto', u'loss': u'auto', u'beta_2': u'auto', u'_enable_profiler': u'false', u'normalize_label': u'auto', u'_num_gpus': u'auto', u'balance_multiclass_weights': u'True', u'positive_example_weight_mult': u'1.0', u'l1': u'auto', u'margin': u'1.0'}\u001b[0m\n",
      "\u001b[34m[01/29/2020 22:02:02 WARNING 139697286510400] Loggers have already been setup.\u001b[0m\n",
      "\u001b[34mProcess 1 is a worker.\u001b[0m\n",
      "\u001b[34m[01/29/2020 22:02:02 INFO 139697286510400] Using default worker.\u001b[0m\n",
      "\u001b[34m[2020-01-29 22:02:02.710] [tensorio] [warning] TensorIO is already initialized; ignoring the initialization routine.\u001b[0m\n",
      "\u001b[34m[2020-01-29 22:02:02.716] [tensorio] [warning] TensorIO is already initialized; ignoring the initialization routine.\u001b[0m\n",
      "\u001b[34m[2020-01-29 22:02:02.752] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 0, \"duration\": 45, \"num_examples\": 1, \"num_bytes\": 72000}\u001b[0m\n",
      "\u001b[34m[01/29/2020 22:02:02 INFO 139697286510400] Create Store: local\u001b[0m\n",
      "\u001b[34m[2020-01-29 22:02:02.808] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 1, \"duration\": 54, \"num_examples\": 11, \"num_bytes\": 792000}\u001b[0m\n",
      "\u001b[34m[01/29/2020 22:02:02 INFO 139697286510400] Scaler algorithm parameters\n",
      " <algorithm.scaler.ScalerAlgorithmStable object at 0x7f0d7d899350>\u001b[0m\n",
      "\u001b[34m[01/29/2020 22:02:02 INFO 139697286510400] Scaling model computed with parameters:\n",
      " {'stdev_weight': \u001b[0m\n",
      "\u001b[34m[0.14185676 0.43555418 0.375233   0.24539958 0.0165122  0.00953419\n",
      " 1.        ]\u001b[0m\n",
      "\u001b[34m<NDArray 7 @cpu(0)>, 'stdev_label': None, 'mean_label': None, 'mean_weight': \u001b[0m\n",
      "\u001b[34m[2.0545455e-02 7.4554539e-01 1.6954546e-01 6.4363636e-02 2.7272728e-04\n",
      " 9.0909089e-05 0.0000000e+00]\u001b[0m\n",
      "\u001b[34m<NDArray 7 @cpu(0)>}\u001b[0m\n",
      "\u001b[34m[01/29/2020 22:02:02 INFO 139697286510400] nvidia-smi took: 0.0252289772034 secs to identify 0 gpus\u001b[0m\n",
      "\u001b[34m[01/29/2020 22:02:02 INFO 139697286510400] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 11, \"sum\": 11.0, \"min\": 11}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Batches Seen\": {\"count\": 1, \"max\": 12, \"sum\": 12.0, \"min\": 12}, \"Total Records Seen\": {\"count\": 1, \"max\": 12000, \"sum\": 12000.0, \"min\": 12000}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 11000, \"sum\": 11000.0, \"min\": 11000}, \"Reset Count\": {\"count\": 1, \"max\": 2, \"sum\": 2.0, \"min\": 2}}, \"EndTime\": 1580335322.921581, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"init_train_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\"}, \"StartTime\": 1580335322.921542}\n",
      "\u001b[0m\n",
      "\u001b[34m[2020-01-29 22:02:03.256] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 3, \"duration\": 334, \"num_examples\": 12, \"num_bytes\": 853920}\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 7.084355779474432, \"sum\": 7.084355779474432, \"min\": 7.084355779474432}}, \"EndTime\": 1580335323.256248, \"Dimensions\": {\"model\": 0, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 0}, \"StartTime\": 1580335323.256163}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 7.328068536931818, \"sum\": 7.328068536931818, \"min\": 7.328068536931818}}, \"EndTime\": 1580335323.256346, \"Dimensions\": {\"model\": 1, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 0}, \"StartTime\": 1580335323.256324}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 7.0526068892045455, \"sum\": 7.0526068892045455, \"min\": 7.0526068892045455}}, \"EndTime\": 1580335323.256418, \"Dimensions\": {\"model\": 2, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 0}, \"StartTime\": 1580335323.256399}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 7.542092595880682, \"sum\": 7.542092595880682, \"min\": 7.542092595880682}}, \"EndTime\": 1580335323.256483, \"Dimensions\": {\"model\": 3, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 0}, \"StartTime\": 1580335323.256464}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 7.379017755681819, \"sum\": 7.379017755681819, \"min\": 7.379017755681819}}, \"EndTime\": 1580335323.256537, \"Dimensions\": {\"model\": 4, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 0}, \"StartTime\": 1580335323.25652}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 6.8730224609375, \"sum\": 6.8730224609375, \"min\": 6.8730224609375}}, \"EndTime\": 1580335323.256592, \"Dimensions\": {\"model\": 5, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 0}, \"StartTime\": 1580335323.256575}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 7.121735440340909, \"sum\": 7.121735440340909, \"min\": 7.121735440340909}}, \"EndTime\": 1580335323.256653, \"Dimensions\": {\"model\": 6, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 0}, \"StartTime\": 1580335323.256635}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 7.699161665482954, \"sum\": 7.699161665482954, \"min\": 7.699161665482954}}, \"EndTime\": 1580335323.256706, \"Dimensions\": {\"model\": 7, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 0}, \"StartTime\": 1580335323.256689}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 8.0044775390625, \"sum\": 8.0044775390625, \"min\": 8.0044775390625}}, \"EndTime\": 1580335323.256759, \"Dimensions\": {\"model\": 8, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 0}, \"StartTime\": 1580335323.256742}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 9.571153009588068, \"sum\": 9.571153009588068, \"min\": 9.571153009588068}}, \"EndTime\": 1580335323.256825, \"Dimensions\": {\"model\": 9, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 0}, \"StartTime\": 1580335323.256807}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 7.733662775213068, \"sum\": 7.733662775213068, \"min\": 7.733662775213068}}, \"EndTime\": 1580335323.256876, \"Dimensions\": {\"model\": 10, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 0}, \"StartTime\": 1580335323.256859}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 7.92006396484375, \"sum\": 7.92006396484375, \"min\": 7.92006396484375}}, \"EndTime\": 1580335323.256925, \"Dimensions\": {\"model\": 11, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 0}, \"StartTime\": 1580335323.256909}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 7.73592529296875, \"sum\": 7.73592529296875, \"min\": 7.73592529296875}}, \"EndTime\": 1580335323.256985, \"Dimensions\": {\"model\": 12, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 0}, \"StartTime\": 1580335323.256967}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 7.433864834872159, \"sum\": 7.433864834872159, \"min\": 7.433864834872159}}, \"EndTime\": 1580335323.257044, \"Dimensions\": {\"model\": 13, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 0}, \"StartTime\": 1580335323.257026}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 7.620017977627841, \"sum\": 7.620017977627841, \"min\": 7.620017977627841}}, \"EndTime\": 1580335323.257101, \"Dimensions\": {\"model\": 14, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 0}, \"StartTime\": 1580335323.257085}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/29/2020 22:02:03 INFO 139697286510400] #quality_metric: host=algo-1, epoch=0, train weighted_softmax_loss_objective <loss>=7.08435577947\u001b[0m\n",
      "\u001b[34m[2020-01-29 22:02:03.270] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/validation\", \"epoch\": 0, \"duration\": 559, \"num_examples\": 1, \"num_bytes\": 72000}\u001b[0m\n",
      "\u001b[34m[2020-01-29 22:02:03.305] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/validation\", \"epoch\": 2, \"duration\": 34, \"num_examples\": 2, \"num_bytes\": 106704}\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 7.3046337956519904, \"sum\": 7.3046337956519904, \"min\": 7.3046337956519904}}, \"EndTime\": 1580335323.310908, \"Dimensions\": {\"model\": 0, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 0}, \"StartTime\": 1580335323.310853}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 8.288630888368758, \"sum\": 8.288630888368758, \"min\": 8.288630888368758}}, \"EndTime\": 1580335323.310991, \"Dimensions\": {\"model\": 1, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 0}, \"StartTime\": 1580335323.310977}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 7.936499221122217, \"sum\": 7.936499221122217, \"min\": 7.936499221122217}}, \"EndTime\": 1580335323.311062, \"Dimensions\": {\"model\": 2, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 0}, \"StartTime\": 1580335323.311043}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 8.400578096006242, \"sum\": 8.400578096006242, \"min\": 8.400578096006242}}, \"EndTime\": 1580335323.311131, \"Dimensions\": {\"model\": 3, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 0}, \"StartTime\": 1580335323.311112}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 7.49228420077387, \"sum\": 7.49228420077387, \"min\": 7.49228420077387}}, \"EndTime\": 1580335323.311207, \"Dimensions\": {\"model\": 4, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 0}, \"StartTime\": 1580335323.311188}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 7.787568333017038, \"sum\": 7.787568333017038, \"min\": 7.787568333017038}}, \"EndTime\": 1580335323.311282, \"Dimensions\": {\"model\": 5, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 0}, \"StartTime\": 1580335323.311263}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 7.710575736968623, \"sum\": 7.710575736968623, \"min\": 7.710575736968623}}, \"EndTime\": 1580335323.311357, \"Dimensions\": {\"model\": 6, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 0}, \"StartTime\": 1580335323.311338}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 7.803164339258603, \"sum\": 7.803164339258603, \"min\": 7.803164339258603}}, \"EndTime\": 1580335323.311421, \"Dimensions\": {\"model\": 7, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 0}, \"StartTime\": 1580335323.311403}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 7.387430744454285, \"sum\": 7.387430744454285, \"min\": 7.387430744454285}}, \"EndTime\": 1580335323.311484, \"Dimensions\": {\"model\": 8, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 0}, \"StartTime\": 1580335323.311467}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 9.637531563659751, \"sum\": 9.637531563659751, \"min\": 9.637531563659751}}, \"EndTime\": 1580335323.311551, \"Dimensions\": {\"model\": 9, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 0}, \"StartTime\": 1580335323.311535}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 7.907659656766616, \"sum\": 7.907659656766616, \"min\": 7.907659656766616}}, \"EndTime\": 1580335323.311623, \"Dimensions\": {\"model\": 10, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 0}, \"StartTime\": 1580335323.311606}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 8.491552767322453, \"sum\": 8.491552767322453, \"min\": 8.491552767322453}}, \"EndTime\": 1580335323.311683, \"Dimensions\": {\"model\": 11, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 0}, \"StartTime\": 1580335323.311667}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 7.97122320054192, \"sum\": 7.97122320054192, \"min\": 7.97122320054192}}, \"EndTime\": 1580335323.311742, \"Dimensions\": {\"model\": 12, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 0}, \"StartTime\": 1580335323.311724}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 8.35154487311277, \"sum\": 8.35154487311277, \"min\": 8.35154487311277}}, \"EndTime\": 1580335323.3118, \"Dimensions\": {\"model\": 13, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 0}, \"StartTime\": 1580335323.311783}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 8.499719781914221, \"sum\": 8.499719781914221, \"min\": 8.499719781914221}}, \"EndTime\": 1580335323.311863, \"Dimensions\": {\"model\": 14, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 0}, \"StartTime\": 1580335323.311845}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/29/2020 22:02:03 INFO 139697286510400] #quality_metric: host=algo-1, epoch=0, validation weighted_softmax_loss_objective <loss>=7.30463379565\u001b[0m\n",
      "\u001b[34m[01/29/2020 22:02:03 INFO 139697286510400] #early_stopping_criteria_metric: host=algo-1, epoch=0, criteria=weighted_softmax_loss_objective, value=7.30463379565\u001b[0m\n",
      "\u001b[34m[01/29/2020 22:02:03 INFO 139697286510400] Epoch 0: Loss improved. Updating best model\u001b[0m\n",
      "\u001b[34m[01/29/2020 22:02:03 INFO 139697286510400] #progress_metric: host=algo-1, completed 6 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 12, \"sum\": 12.0, \"min\": 12}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 12, \"sum\": 12.0, \"min\": 12}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 11860, \"sum\": 11860.0, \"min\": 11860}, \"Total Batches Seen\": {\"count\": 1, \"max\": 24, \"sum\": 24.0, \"min\": 24}, \"Total Records Seen\": {\"count\": 1, \"max\": 23860, \"sum\": 23860.0, \"min\": 23860}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 11860, \"sum\": 11860.0, \"min\": 11860}, \"Reset Count\": {\"count\": 1, \"max\": 3, \"sum\": 3.0, \"min\": 3}}, \"EndTime\": 1580335323.313443, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 0}, \"StartTime\": 1580335322.921793}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/29/2020 22:02:03 INFO 139697286510400] #throughput_metric: host=algo-1, train throughput=30274.5680082 records/second\u001b[0m\n",
      "\u001b[34m[2020-01-29 22:02:03.605] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 5, \"duration\": 289, \"num_examples\": 12, \"num_bytes\": 853920}\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 6.229687233664773, \"sum\": 6.229687233664773, \"min\": 6.229687233664773}}, \"EndTime\": 1580335323.605985, \"Dimensions\": {\"model\": 0, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 1}, \"StartTime\": 1580335323.605908}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 6.722523837002841, \"sum\": 6.722523837002841, \"min\": 6.722523837002841}}, \"EndTime\": 1580335323.606081, \"Dimensions\": {\"model\": 1, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 1}, \"StartTime\": 1580335323.606064}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 6.666570090553977, \"sum\": 6.666570090553977, \"min\": 6.666570090553977}}, \"EndTime\": 1580335323.606134, \"Dimensions\": {\"model\": 2, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 1}, \"StartTime\": 1580335323.606121}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 6.728041326349432, \"sum\": 6.728041326349432, \"min\": 6.728041326349432}}, \"EndTime\": 1580335323.606182, \"Dimensions\": {\"model\": 3, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 1}, \"StartTime\": 1580335323.606169}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 6.751425248579546, \"sum\": 6.751425248579546, \"min\": 6.751425248579546}}, \"EndTime\": 1580335323.60623, \"Dimensions\": {\"model\": 4, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 1}, \"StartTime\": 1580335323.606218}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 6.110911199396307, \"sum\": 6.110911199396307, \"min\": 6.110911199396307}}, \"EndTime\": 1580335323.606277, \"Dimensions\": {\"model\": 5, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 1}, \"StartTime\": 1580335323.606265}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 6.707628950639204, \"sum\": 6.707628950639204, \"min\": 6.707628950639204}}, \"EndTime\": 1580335323.606323, \"Dimensions\": {\"model\": 6, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 1}, \"StartTime\": 1580335323.606311}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 6.998426047585228, \"sum\": 6.998426047585228, \"min\": 6.998426047585228}}, \"EndTime\": 1580335323.606377, \"Dimensions\": {\"model\": 7, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 1}, \"StartTime\": 1580335323.606364}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 6.37891943359375, \"sum\": 6.37891943359375, \"min\": 6.37891943359375}}, \"EndTime\": 1580335323.606431, \"Dimensions\": {\"model\": 8, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 1}, \"StartTime\": 1580335323.606418}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 7.165949529474432, \"sum\": 7.165949529474432, \"min\": 7.165949529474432}}, \"EndTime\": 1580335323.606477, \"Dimensions\": {\"model\": 9, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 1}, \"StartTime\": 1580335323.606465}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 7.073538130326704, \"sum\": 7.073538130326704, \"min\": 7.073538130326704}}, \"EndTime\": 1580335323.606528, \"Dimensions\": {\"model\": 10, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 1}, \"StartTime\": 1580335323.606515}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 6.562612615411932, \"sum\": 6.562612615411932, \"min\": 6.562612615411932}}, \"EndTime\": 1580335323.606581, \"Dimensions\": {\"model\": 11, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 1}, \"StartTime\": 1580335323.606568}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 6.553041015625, \"sum\": 6.553041015625, \"min\": 6.553041015625}}, \"EndTime\": 1580335323.606627, \"Dimensions\": {\"model\": 12, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 1}, \"StartTime\": 1580335323.606615}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 6.722741477272727, \"sum\": 6.722741477272727, \"min\": 6.722741477272727}}, \"EndTime\": 1580335323.606679, \"Dimensions\": {\"model\": 13, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 1}, \"StartTime\": 1580335323.606667}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 6.492766068892045, \"sum\": 6.492766068892045, \"min\": 6.492766068892045}}, \"EndTime\": 1580335323.606732, \"Dimensions\": {\"model\": 14, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 1}, \"StartTime\": 1580335323.606719}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/29/2020 22:02:03 INFO 139697286510400] #quality_metric: host=algo-1, epoch=1, train weighted_softmax_loss_objective <loss>=6.22968723366\u001b[0m\n",
      "\u001b[34m[2020-01-29 22:02:03.650] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/validation\", \"epoch\": 5, \"duration\": 31, \"num_examples\": 2, \"num_bytes\": 106704}\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 6.43539729356444, \"sum\": 6.43539729356444, \"min\": 6.43539729356444}}, \"EndTime\": 1580335323.656581, \"Dimensions\": {\"model\": 0, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 1}, \"StartTime\": 1580335323.656525}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 7.901439671896086, \"sum\": 7.901439671896086, \"min\": 7.901439671896086}}, \"EndTime\": 1580335323.656704, \"Dimensions\": {\"model\": 1, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 1}, \"StartTime\": 1580335323.656679}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 6.605910904816127, \"sum\": 6.605910904816127, \"min\": 6.605910904816127}}, \"EndTime\": 1580335323.656779, \"Dimensions\": {\"model\": 2, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 1}, \"StartTime\": 1580335323.656758}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 7.964711136502615, \"sum\": 7.964711136502615, \"min\": 7.964711136502615}}, \"EndTime\": 1580335323.656848, \"Dimensions\": {\"model\": 3, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 1}, \"StartTime\": 1580335323.656829}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 7.277502556722335, \"sum\": 7.277502556722335, \"min\": 7.277502556722335}}, \"EndTime\": 1580335323.656916, \"Dimensions\": {\"model\": 4, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 1}, \"StartTime\": 1580335323.656897}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 7.387746381051788, \"sum\": 7.387746381051788, \"min\": 7.387746381051788}}, \"EndTime\": 1580335323.656982, \"Dimensions\": {\"model\": 5, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 1}, \"StartTime\": 1580335323.656963}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 6.876869438469973, \"sum\": 6.876869438469973, \"min\": 6.876869438469973}}, \"EndTime\": 1580335323.657044, \"Dimensions\": {\"model\": 6, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 1}, \"StartTime\": 1580335323.657028}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 7.6579914376159754, \"sum\": 7.6579914376159754, \"min\": 7.6579914376159754}}, \"EndTime\": 1580335323.657105, \"Dimensions\": {\"model\": 7, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 1}, \"StartTime\": 1580335323.657088}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 6.792459711854757, \"sum\": 6.792459711854757, \"min\": 6.792459711854757}}, \"EndTime\": 1580335323.657169, \"Dimensions\": {\"model\": 8, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 1}, \"StartTime\": 1580335323.657151}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 8.42015613138917, \"sum\": 8.42015613138917, \"min\": 8.42015613138917}}, \"EndTime\": 1580335323.657229, \"Dimensions\": {\"model\": 9, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 1}, \"StartTime\": 1580335323.657213}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 7.695362744865469, \"sum\": 7.695362744865469, \"min\": 7.695362744865469}}, \"EndTime\": 1580335323.65729, \"Dimensions\": {\"model\": 10, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 1}, \"StartTime\": 1580335323.657273}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 7.961291849854504, \"sum\": 7.961291849854504, \"min\": 7.961291849854504}}, \"EndTime\": 1580335323.657354, \"Dimensions\": {\"model\": 11, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 1}, \"StartTime\": 1580335323.657336}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 6.510663113613361, \"sum\": 6.510663113613361, \"min\": 6.510663113613361}}, \"EndTime\": 1580335323.657424, \"Dimensions\": {\"model\": 12, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 1}, \"StartTime\": 1580335323.657407}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 7.925904967685138, \"sum\": 7.925904967685138, \"min\": 7.925904967685138}}, \"EndTime\": 1580335323.657485, \"Dimensions\": {\"model\": 13, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 1}, \"StartTime\": 1580335323.657467}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 6.908331949540317, \"sum\": 6.908331949540317, \"min\": 6.908331949540317}}, \"EndTime\": 1580335323.657547, \"Dimensions\": {\"model\": 14, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 1}, \"StartTime\": 1580335323.657529}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/29/2020 22:02:03 INFO 139697286510400] #quality_metric: host=algo-1, epoch=1, validation weighted_softmax_loss_objective <loss>=6.43539729356\u001b[0m\n",
      "\u001b[34m[01/29/2020 22:02:03 INFO 139697286510400] #early_stopping_criteria_metric: host=algo-1, epoch=1, criteria=weighted_softmax_loss_objective, value=6.43539729356\u001b[0m\n",
      "\u001b[34m[01/29/2020 22:02:03 INFO 139697286510400] Epoch 1: Loss improved. Updating best model\u001b[0m\n",
      "\u001b[34m[01/29/2020 22:02:03 INFO 139697286510400] #progress_metric: host=algo-1, completed 13 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 12, \"sum\": 12.0, \"min\": 12}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 12, \"sum\": 12.0, \"min\": 12}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 11860, \"sum\": 11860.0, \"min\": 11860}, \"Total Batches Seen\": {\"count\": 1, \"max\": 36, \"sum\": 36.0, \"min\": 36}, \"Total Records Seen\": {\"count\": 1, \"max\": 35720, \"sum\": 35720.0, \"min\": 35720}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 11860, \"sum\": 11860.0, \"min\": 11860}, \"Reset Count\": {\"count\": 1, \"max\": 4, \"sum\": 4.0, \"min\": 4}}, \"EndTime\": 1580335323.659283, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 1}, \"StartTime\": 1580335323.313643}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/29/2020 22:02:03 INFO 139697286510400] #throughput_metric: host=algo-1, train throughput=34302.5397333 records/second\u001b[0m\n",
      "\u001b[34m[2020-01-29 22:02:03.985] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 7, \"duration\": 325, \"num_examples\": 12, \"num_bytes\": 853920}\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 5.688625954367898, \"sum\": 5.688625954367898, \"min\": 5.688625954367898}}, \"EndTime\": 1580335323.985215, \"Dimensions\": {\"model\": 0, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 2}, \"StartTime\": 1580335323.985129}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 6.443131170099432, \"sum\": 6.443131170099432, \"min\": 6.443131170099432}}, \"EndTime\": 1580335323.985321, \"Dimensions\": {\"model\": 1, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 2}, \"StartTime\": 1580335323.985297}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 6.007916481711648, \"sum\": 6.007916481711648, \"min\": 6.007916481711648}}, \"EndTime\": 1580335323.985534, \"Dimensions\": {\"model\": 2, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 2}, \"StartTime\": 1580335323.985507}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 6.406326393821023, \"sum\": 6.406326393821023, \"min\": 6.406326393821023}}, \"EndTime\": 1580335323.985607, \"Dimensions\": {\"model\": 3, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 2}, \"StartTime\": 1580335323.985587}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 6.423716574928977, \"sum\": 6.423716574928977, \"min\": 6.423716574928977}}, \"EndTime\": 1580335323.985732, \"Dimensions\": {\"model\": 4, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 2}, \"StartTime\": 1580335323.985709}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 5.880668124112216, \"sum\": 5.880668124112216, \"min\": 5.880668124112216}}, \"EndTime\": 1580335323.985864, \"Dimensions\": {\"model\": 5, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 2}, \"StartTime\": 1580335323.985843}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 6.130092063210228, \"sum\": 6.130092063210228, \"min\": 6.130092063210228}}, \"EndTime\": 1580335323.985993, \"Dimensions\": {\"model\": 6, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 2}, \"StartTime\": 1580335323.985971}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 6.786597212357955, \"sum\": 6.786597212357955, \"min\": 6.786597212357955}}, \"EndTime\": 1580335323.986113, \"Dimensions\": {\"model\": 7, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 2}, \"StartTime\": 1580335323.986092}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 6.196953702059659, \"sum\": 6.196953702059659, \"min\": 6.196953702059659}}, \"EndTime\": 1580335323.986184, \"Dimensions\": {\"model\": 8, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 2}, \"StartTime\": 1580335323.986166}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 6.868216530539772, \"sum\": 6.868216530539772, \"min\": 6.868216530539772}}, \"EndTime\": 1580335323.986249, \"Dimensions\": {\"model\": 9, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 2}, \"StartTime\": 1580335323.98623}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 6.83802783203125, \"sum\": 6.83802783203125, \"min\": 6.83802783203125}}, \"EndTime\": 1580335323.986313, \"Dimensions\": {\"model\": 10, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 2}, \"StartTime\": 1580335323.986295}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 6.260645330255682, \"sum\": 6.260645330255682, \"min\": 6.260645330255682}}, \"EndTime\": 1580335323.986379, \"Dimensions\": {\"model\": 11, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 2}, \"StartTime\": 1580335323.98636}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 5.788878440163352, \"sum\": 5.788878440163352, \"min\": 5.788878440163352}}, \"EndTime\": 1580335323.986444, \"Dimensions\": {\"model\": 12, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 2}, \"StartTime\": 1580335323.986425}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 6.420756702769887, \"sum\": 6.420756702769887, \"min\": 6.420756702769887}}, \"EndTime\": 1580335323.986506, \"Dimensions\": {\"model\": 13, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 2}, \"StartTime\": 1580335323.986489}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 6.199195268110795, \"sum\": 6.199195268110795, \"min\": 6.199195268110795}}, \"EndTime\": 1580335323.986567, \"Dimensions\": {\"model\": 14, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 2}, \"StartTime\": 1580335323.986549}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/29/2020 22:02:03 INFO 139697286510400] #quality_metric: host=algo-1, epoch=2, train weighted_softmax_loss_objective <loss>=5.68862595437\u001b[0m\n",
      "\u001b[34m[2020-01-29 22:02:04.043] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/validation\", \"epoch\": 8, \"duration\": 38, \"num_examples\": 2, \"num_bytes\": 106704}\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 6.417062200837129, \"sum\": 6.417062200837129, \"min\": 6.417062200837129}}, \"EndTime\": 1580335324.049582, \"Dimensions\": {\"model\": 0, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 2}, \"StartTime\": 1580335324.049525}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 7.663499757506748, \"sum\": 7.663499757506748, \"min\": 7.663499757506748}}, \"EndTime\": 1580335324.049674, \"Dimensions\": {\"model\": 1, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 2}, \"StartTime\": 1580335324.049653}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 6.556723652580971, \"sum\": 6.556723652580971, \"min\": 6.556723652580971}}, \"EndTime\": 1580335324.049746, \"Dimensions\": {\"model\": 2, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 2}, \"StartTime\": 1580335324.049726}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 7.700353130798752, \"sum\": 7.700353130798752, \"min\": 7.700353130798752}}, \"EndTime\": 1580335324.049815, \"Dimensions\": {\"model\": 3, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 2}, \"StartTime\": 1580335324.049796}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 6.944003168227058, \"sum\": 6.944003168227058, \"min\": 6.944003168227058}}, \"EndTime\": 1580335324.049882, \"Dimensions\": {\"model\": 4, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 2}, \"StartTime\": 1580335324.049863}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 7.21233957885248, \"sum\": 7.21233957885248, \"min\": 7.21233957885248}}, \"EndTime\": 1580335324.049946, \"Dimensions\": {\"model\": 5, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 2}, \"StartTime\": 1580335324.049929}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 6.809652351657388, \"sum\": 6.809652351657388, \"min\": 6.809652351657388}}, \"EndTime\": 1580335324.05001, \"Dimensions\": {\"model\": 6, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 2}, \"StartTime\": 1580335324.049991}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 7.329924919344635, \"sum\": 7.329924919344635, \"min\": 7.329924919344635}}, \"EndTime\": 1580335324.050073, \"Dimensions\": {\"model\": 7, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 2}, \"StartTime\": 1580335324.050055}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 7.655268001170294, \"sum\": 7.655268001170294, \"min\": 7.655268001170294}}, \"EndTime\": 1580335324.050137, \"Dimensions\": {\"model\": 8, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 2}, \"StartTime\": 1580335324.05012}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 7.692213297855516, \"sum\": 7.692213297855516, \"min\": 7.692213297855516}}, \"EndTime\": 1580335324.050201, \"Dimensions\": {\"model\": 9, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 2}, \"StartTime\": 1580335324.050182}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 7.4495195602437585, \"sum\": 7.4495195602437585, \"min\": 7.4495195602437585}}, \"EndTime\": 1580335324.050267, \"Dimensions\": {\"model\": 10, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 2}, \"StartTime\": 1580335324.050247}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 7.734756531503036, \"sum\": 7.734756531503036, \"min\": 7.734756531503036}}, \"EndTime\": 1580335324.050342, \"Dimensions\": {\"model\": 11, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 2}, \"StartTime\": 1580335324.050322}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 6.479287748555584, \"sum\": 6.479287748555584, \"min\": 6.479287748555584}}, \"EndTime\": 1580335324.050413, \"Dimensions\": {\"model\": 12, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 2}, \"StartTime\": 1580335324.050392}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 7.64050721285636, \"sum\": 7.64050721285636, \"min\": 7.64050721285636}}, \"EndTime\": 1580335324.050483, \"Dimensions\": {\"model\": 13, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 2}, \"StartTime\": 1580335324.050463}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 6.359446825447031, \"sum\": 6.359446825447031, \"min\": 6.359446825447031}}, \"EndTime\": 1580335324.050555, \"Dimensions\": {\"model\": 14, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 2}, \"StartTime\": 1580335324.050535}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/29/2020 22:02:04 INFO 139697286510400] #quality_metric: host=algo-1, epoch=2, validation weighted_softmax_loss_objective <loss>=6.41706220084\u001b[0m\n",
      "\u001b[34m[01/29/2020 22:02:04 INFO 139697286510400] #early_stopping_criteria_metric: host=algo-1, epoch=2, criteria=weighted_softmax_loss_objective, value=6.35944682545\u001b[0m\n",
      "\u001b[34m[01/29/2020 22:02:04 INFO 139697286510400] Epoch 2: Loss improved. Updating best model\u001b[0m\n",
      "\u001b[34m[01/29/2020 22:02:04 INFO 139697286510400] #progress_metric: host=algo-1, completed 20 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 12, \"sum\": 12.0, \"min\": 12}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 12, \"sum\": 12.0, \"min\": 12}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 11860, \"sum\": 11860.0, \"min\": 11860}, \"Total Batches Seen\": {\"count\": 1, \"max\": 48, \"sum\": 48.0, \"min\": 48}, \"Total Records Seen\": {\"count\": 1, \"max\": 47580, \"sum\": 47580.0, \"min\": 47580}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 11860, \"sum\": 11860.0, \"min\": 11860}, \"Reset Count\": {\"count\": 1, \"max\": 5, \"sum\": 5.0, \"min\": 5}}, \"EndTime\": 1580335324.052592, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 2}, \"StartTime\": 1580335323.659562}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/29/2020 22:02:04 INFO 139697286510400] #throughput_metric: host=algo-1, train throughput=30164.9862984 records/second\u001b[0m\n",
      "\u001b[34m[2020-01-29 22:02:04.424] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 9, \"duration\": 371, \"num_examples\": 12, \"num_bytes\": 853920}\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 5.67360595703125, \"sum\": 5.67360595703125, \"min\": 5.67360595703125}}, \"EndTime\": 1580335324.424266, \"Dimensions\": {\"model\": 0, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 3}, \"StartTime\": 1580335324.424161}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 6.243927445845171, \"sum\": 6.243927445845171, \"min\": 6.243927445845171}}, \"EndTime\": 1580335324.424371, \"Dimensions\": {\"model\": 1, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 3}, \"StartTime\": 1580335324.424348}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 5.825544855291193, \"sum\": 5.825544855291193, \"min\": 5.825544855291193}}, \"EndTime\": 1580335324.424476, \"Dimensions\": {\"model\": 2, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 3}, \"StartTime\": 1580335324.424452}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 6.187937122691761, \"sum\": 6.187937122691761, \"min\": 6.187937122691761}}, \"EndTime\": 1580335324.424575, \"Dimensions\": {\"model\": 3, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 3}, \"StartTime\": 1580335324.424551}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 6.2034893243963065, \"sum\": 6.2034893243963065, \"min\": 6.2034893243963065}}, \"EndTime\": 1580335324.424642, \"Dimensions\": {\"model\": 4, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 3}, \"StartTime\": 1580335324.424625}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 5.7647312899502845, \"sum\": 5.7647312899502845, \"min\": 5.7647312899502845}}, \"EndTime\": 1580335324.424761, \"Dimensions\": {\"model\": 5, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 3}, \"StartTime\": 1580335324.42474}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 6.0122314453125, \"sum\": 6.0122314453125, \"min\": 6.0122314453125}}, \"EndTime\": 1580335324.424831, \"Dimensions\": {\"model\": 6, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 3}, \"StartTime\": 1580335324.424813}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 6.556513538707386, \"sum\": 6.556513538707386, \"min\": 6.556513538707386}}, \"EndTime\": 1580335324.424945, \"Dimensions\": {\"model\": 7, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 3}, \"StartTime\": 1580335324.424903}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 6.316074995561079, \"sum\": 6.316074995561079, \"min\": 6.316074995561079}}, \"EndTime\": 1580335324.425017, \"Dimensions\": {\"model\": 8, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 3}, \"StartTime\": 1580335324.424998}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 6.763638805042613, \"sum\": 6.763638805042613, \"min\": 6.763638805042613}}, \"EndTime\": 1580335324.425092, \"Dimensions\": {\"model\": 9, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 3}, \"StartTime\": 1580335324.425062}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 6.652399636008523, \"sum\": 6.652399636008523, \"min\": 6.652399636008523}}, \"EndTime\": 1580335324.425181, \"Dimensions\": {\"model\": 10, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 3}, \"StartTime\": 1580335324.42516}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 6.112248401988636, \"sum\": 6.112248401988636, \"min\": 6.112248401988636}}, \"EndTime\": 1580335324.425243, \"Dimensions\": {\"model\": 11, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 3}, \"StartTime\": 1580335324.425225}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 5.699920454545454, \"sum\": 5.699920454545454, \"min\": 5.699920454545454}}, \"EndTime\": 1580335324.425343, \"Dimensions\": {\"model\": 12, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 3}, \"StartTime\": 1580335324.425324}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 6.216743696732954, \"sum\": 6.216743696732954, \"min\": 6.216743696732954}}, \"EndTime\": 1580335324.42541, \"Dimensions\": {\"model\": 13, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 3}, \"StartTime\": 1580335324.425391}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 5.897283025568182, \"sum\": 5.897283025568182, \"min\": 5.897283025568182}}, \"EndTime\": 1580335324.425512, \"Dimensions\": {\"model\": 14, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 3}, \"StartTime\": 1580335324.42549}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/29/2020 22:02:04 INFO 139697286510400] #quality_metric: host=algo-1, epoch=3, train weighted_softmax_loss_objective <loss>=5.67360595703\u001b[0m\n",
      "\u001b[34m[2020-01-29 22:02:04.510] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/validation\", \"epoch\": 11, \"duration\": 37, \"num_examples\": 2, \"num_bytes\": 106704}\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 6.241497745076333, \"sum\": 6.241497745076333, \"min\": 6.241497745076333}}, \"EndTime\": 1580335324.518731, \"Dimensions\": {\"model\": 0, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 3}, \"StartTime\": 1580335324.51865}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 7.490706841472672, \"sum\": 7.490706841472672, \"min\": 7.490706841472672}}, \"EndTime\": 1580335324.518856, \"Dimensions\": {\"model\": 1, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 3}, \"StartTime\": 1580335324.518831}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 6.438948370023617, \"sum\": 6.438948370023617, \"min\": 6.438948370023617}}, \"EndTime\": 1580335324.518926, \"Dimensions\": {\"model\": 2, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 3}, \"StartTime\": 1580335324.518907}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 7.517536775946778, \"sum\": 7.517536775946778, \"min\": 7.517536775946778}}, \"EndTime\": 1580335324.518995, \"Dimensions\": {\"model\": 3, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 3}, \"StartTime\": 1580335324.518977}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 6.842569986979167, \"sum\": 6.842569986979167, \"min\": 6.842569986979167}}, \"EndTime\": 1580335324.519061, \"Dimensions\": {\"model\": 4, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 3}, \"StartTime\": 1580335324.519042}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 7.119837298888748, \"sum\": 7.119837298888748, \"min\": 7.119837298888748}}, \"EndTime\": 1580335324.519122, \"Dimensions\": {\"model\": 5, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 3}, \"StartTime\": 1580335324.519105}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 6.507273150198212, \"sum\": 6.507273150198212, \"min\": 6.507273150198212}}, \"EndTime\": 1580335324.519185, \"Dimensions\": {\"model\": 6, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 3}, \"StartTime\": 1580335324.519167}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 7.187082720510712, \"sum\": 7.187082720510712, \"min\": 7.187082720510712}}, \"EndTime\": 1580335324.519243, \"Dimensions\": {\"model\": 7, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 3}, \"StartTime\": 1580335324.519227}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 7.427896970679403, \"sum\": 7.427896970679403, \"min\": 7.427896970679403}}, \"EndTime\": 1580335324.519304, \"Dimensions\": {\"model\": 8, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 3}, \"StartTime\": 1580335324.519287}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 7.48419230637441, \"sum\": 7.48419230637441, \"min\": 7.48419230637441}}, \"EndTime\": 1580335324.519361, \"Dimensions\": {\"model\": 9, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 3}, \"StartTime\": 1580335324.519346}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 7.280574083006495, \"sum\": 7.280574083006495, \"min\": 7.280574083006495}}, \"EndTime\": 1580335324.519415, \"Dimensions\": {\"model\": 10, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 3}, \"StartTime\": 1580335324.519401}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 7.623091024586707, \"sum\": 7.623091024586707, \"min\": 7.623091024586707}}, \"EndTime\": 1580335324.519471, \"Dimensions\": {\"model\": 11, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 3}, \"StartTime\": 1580335324.519456}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 6.257097869749494, \"sum\": 6.257097869749494, \"min\": 6.257097869749494}}, \"EndTime\": 1580335324.519526, \"Dimensions\": {\"model\": 12, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 3}, \"StartTime\": 1580335324.519511}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 7.4746630793480096, \"sum\": 7.4746630793480096, \"min\": 7.4746630793480096}}, \"EndTime\": 1580335324.519585, \"Dimensions\": {\"model\": 13, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 3}, \"StartTime\": 1580335324.519569}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 6.2133202597840755, \"sum\": 6.2133202597840755, \"min\": 6.2133202597840755}}, \"EndTime\": 1580335324.519642, \"Dimensions\": {\"model\": 14, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 3}, \"StartTime\": 1580335324.519626}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/29/2020 22:02:04 INFO 139697286510400] #quality_metric: host=algo-1, epoch=3, validation weighted_softmax_loss_objective <loss>=6.24149774508\u001b[0m\n",
      "\u001b[34m[01/29/2020 22:02:04 INFO 139697286510400] #early_stopping_criteria_metric: host=algo-1, epoch=3, criteria=weighted_softmax_loss_objective, value=6.21332025978\u001b[0m\n",
      "\u001b[34m[01/29/2020 22:02:04 INFO 139697286510400] Epoch 3: Loss improved. Updating best model\u001b[0m\n",
      "\u001b[34m[01/29/2020 22:02:04 INFO 139697286510400] #progress_metric: host=algo-1, completed 26 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 12, \"sum\": 12.0, \"min\": 12}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 12, \"sum\": 12.0, \"min\": 12}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 11860, \"sum\": 11860.0, \"min\": 11860}, \"Total Batches Seen\": {\"count\": 1, \"max\": 60, \"sum\": 60.0, \"min\": 60}, \"Total Records Seen\": {\"count\": 1, \"max\": 59440, \"sum\": 59440.0, \"min\": 59440}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 11860, \"sum\": 11860.0, \"min\": 11860}, \"Reset Count\": {\"count\": 1, \"max\": 6, \"sum\": 6.0, \"min\": 6}}, \"EndTime\": 1580335324.521489, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 3}, \"StartTime\": 1580335324.052914}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/29/2020 22:02:04 INFO 139697286510400] #throughput_metric: host=algo-1, train throughput=25303.2766901 records/second\u001b[0m\n",
      "\u001b[34m[2020-01-29 22:02:04.871] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 11, \"duration\": 349, \"num_examples\": 12, \"num_bytes\": 853920}\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 5.569263649680398, \"sum\": 5.569263649680398, \"min\": 5.569263649680398}}, \"EndTime\": 1580335324.871787, \"Dimensions\": {\"model\": 0, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 4}, \"StartTime\": 1580335324.871702}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 6.092679709694602, \"sum\": 6.092679709694602, \"min\": 6.092679709694602}}, \"EndTime\": 1580335324.871888, \"Dimensions\": {\"model\": 1, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 4}, \"StartTime\": 1580335324.871868}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 5.7602296697443185, \"sum\": 5.7602296697443185, \"min\": 5.7602296697443185}}, \"EndTime\": 1580335324.871953, \"Dimensions\": {\"model\": 2, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 4}, \"StartTime\": 1580335324.871936}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 6.032053977272727, \"sum\": 6.032053977272727, \"min\": 6.032053977272727}}, \"EndTime\": 1580335324.872014, \"Dimensions\": {\"model\": 3, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 4}, \"StartTime\": 1580335324.871997}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 6.060037974964489, \"sum\": 6.060037974964489, \"min\": 6.060037974964489}}, \"EndTime\": 1580335324.872078, \"Dimensions\": {\"model\": 4, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 4}, \"StartTime\": 1580335324.87206}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 5.697473876953125, \"sum\": 5.697473876953125, \"min\": 5.697473876953125}}, \"EndTime\": 1580335324.872167, \"Dimensions\": {\"model\": 5, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 4}, \"StartTime\": 1580335324.872148}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 5.811456787109375, \"sum\": 5.811456787109375, \"min\": 5.811456787109375}}, \"EndTime\": 1580335324.872232, \"Dimensions\": {\"model\": 6, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 4}, \"StartTime\": 1580335324.872215}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 6.40083984375, \"sum\": 6.40083984375, \"min\": 6.40083984375}}, \"EndTime\": 1580335324.872295, \"Dimensions\": {\"model\": 7, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 4}, \"StartTime\": 1580335324.872278}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 6.260397594105114, \"sum\": 6.260397594105114, \"min\": 6.260397594105114}}, \"EndTime\": 1580335324.872354, \"Dimensions\": {\"model\": 8, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 4}, \"StartTime\": 1580335324.872337}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 6.7032744584517046, \"sum\": 6.7032744584517046, \"min\": 6.7032744584517046}}, \"EndTime\": 1580335324.872417, \"Dimensions\": {\"model\": 9, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 4}, \"StartTime\": 1580335324.872399}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 6.501731667258523, \"sum\": 6.501731667258523, \"min\": 6.501731667258523}}, \"EndTime\": 1580335324.87248, \"Dimensions\": {\"model\": 10, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 4}, \"StartTime\": 1580335324.872463}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 6.032874422940341, \"sum\": 6.032874422940341, \"min\": 6.032874422940341}}, \"EndTime\": 1580335324.872542, \"Dimensions\": {\"model\": 11, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 4}, \"StartTime\": 1580335324.872525}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 5.611610751065341, \"sum\": 5.611610751065341, \"min\": 5.611610751065341}}, \"EndTime\": 1580335324.872603, \"Dimensions\": {\"model\": 12, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 4}, \"StartTime\": 1580335324.872586}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 6.067199529474432, \"sum\": 6.067199529474432, \"min\": 6.067199529474432}}, \"EndTime\": 1580335324.872707, \"Dimensions\": {\"model\": 13, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 4}, \"StartTime\": 1580335324.872648}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 5.689406405362216, \"sum\": 5.689406405362216, \"min\": 5.689406405362216}}, \"EndTime\": 1580335324.872778, \"Dimensions\": {\"model\": 14, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 4}, \"StartTime\": 1580335324.872758}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/29/2020 22:02:04 INFO 139697286510400] #quality_metric: host=algo-1, epoch=4, train weighted_softmax_loss_objective <loss>=5.56926364968\u001b[0m\n",
      "\u001b[34m[2020-01-29 22:02:04.931] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/validation\", \"epoch\": 14, \"duration\": 40, \"num_examples\": 2, \"num_bytes\": 106704}\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 6.2597283943783735, \"sum\": 6.2597283943783735, \"min\": 6.2597283943783735}}, \"EndTime\": 1580335324.939061, \"Dimensions\": {\"model\": 0, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 4}, \"StartTime\": 1580335324.938979}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 7.360073156524122, \"sum\": 7.360073156524122, \"min\": 7.360073156524122}}, \"EndTime\": 1580335324.939188, \"Dimensions\": {\"model\": 1, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 4}, \"StartTime\": 1580335324.939162}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 6.273879160604335, \"sum\": 6.273879160604335, \"min\": 6.273879160604335}}, \"EndTime\": 1580335324.939266, \"Dimensions\": {\"model\": 2, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 4}, \"StartTime\": 1580335324.939247}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 7.387212797054234, \"sum\": 7.387212797054234, \"min\": 7.387212797054234}}, \"EndTime\": 1580335324.939332, \"Dimensions\": {\"model\": 3, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 4}, \"StartTime\": 1580335324.939313}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 6.654419768998819, \"sum\": 6.654419768998819, \"min\": 6.654419768998819}}, \"EndTime\": 1580335324.9394, \"Dimensions\": {\"model\": 4, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 4}, \"StartTime\": 1580335324.939381}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 7.0594100231422905, \"sum\": 7.0594100231422905, \"min\": 7.0594100231422905}}, \"EndTime\": 1580335324.939466, \"Dimensions\": {\"model\": 5, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 4}, \"StartTime\": 1580335324.939448}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 6.449548554002193, \"sum\": 6.449548554002193, \"min\": 6.449548554002193}}, \"EndTime\": 1580335324.939534, \"Dimensions\": {\"model\": 6, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 4}, \"StartTime\": 1580335324.939514}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 7.046186727711707, \"sum\": 7.046186727711707, \"min\": 7.046186727711707}}, \"EndTime\": 1580335324.939604, \"Dimensions\": {\"model\": 7, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 4}, \"StartTime\": 1580335324.939585}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 7.071326787333418, \"sum\": 7.071326787333418, \"min\": 7.071326787333418}}, \"EndTime\": 1580335324.939668, \"Dimensions\": {\"model\": 8, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 4}, \"StartTime\": 1580335324.93965}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 7.427789726720648, \"sum\": 7.427789726720648, \"min\": 7.427789726720648}}, \"EndTime\": 1580335324.93973, \"Dimensions\": {\"model\": 9, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 4}, \"StartTime\": 1580335324.939713}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 7.159010996541835, \"sum\": 7.159010996541835, \"min\": 7.159010996541835}}, \"EndTime\": 1580335324.939787, \"Dimensions\": {\"model\": 10, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 4}, \"StartTime\": 1580335324.939772}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 7.567193858858384, \"sum\": 7.567193858858384, \"min\": 7.567193858858384}}, \"EndTime\": 1580335324.939846, \"Dimensions\": {\"model\": 11, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 4}, \"StartTime\": 1580335324.939829}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 6.242120781408148, \"sum\": 6.242120781408148, \"min\": 6.242120781408148}}, \"EndTime\": 1580335324.939906, \"Dimensions\": {\"model\": 12, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 4}, \"StartTime\": 1580335324.939889}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 7.312108913735662, \"sum\": 7.312108913735662, \"min\": 7.312108913735662}}, \"EndTime\": 1580335324.939966, \"Dimensions\": {\"model\": 13, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 4}, \"StartTime\": 1580335324.939949}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 6.302045279025388, \"sum\": 6.302045279025388, \"min\": 6.302045279025388}}, \"EndTime\": 1580335324.940027, \"Dimensions\": {\"model\": 14, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 4}, \"StartTime\": 1580335324.94001}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/29/2020 22:02:04 INFO 139697286510400] #quality_metric: host=algo-1, epoch=4, validation weighted_softmax_loss_objective <loss>=6.25972839438\u001b[0m\n",
      "\u001b[34m[01/29/2020 22:02:04 INFO 139697286510400] #early_stopping_criteria_metric: host=algo-1, epoch=4, criteria=weighted_softmax_loss_objective, value=6.24212078141\u001b[0m\n",
      "\u001b[34m[01/29/2020 22:02:04 INFO 139697286510400] #progress_metric: host=algo-1, completed 33 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 12, \"sum\": 12.0, \"min\": 12}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 12, \"sum\": 12.0, \"min\": 12}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 11860, \"sum\": 11860.0, \"min\": 11860}, \"Total Batches Seen\": {\"count\": 1, \"max\": 72, \"sum\": 72.0, \"min\": 72}, \"Total Records Seen\": {\"count\": 1, \"max\": 71300, \"sum\": 71300.0, \"min\": 71300}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 11860, \"sum\": 11860.0, \"min\": 11860}, \"Reset Count\": {\"count\": 1, \"max\": 7, \"sum\": 7.0, \"min\": 7}}, \"EndTime\": 1580335324.941227, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 4}, \"StartTime\": 1580335324.521766}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/29/2020 22:02:04 INFO 139697286510400] #throughput_metric: host=algo-1, train throughput=28264.2748765 records/second\u001b[0m\n",
      "\u001b[34m[2020-01-29 22:02:05.269] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 13, \"duration\": 327, \"num_examples\": 12, \"num_bytes\": 853920}\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 5.576160245028409, \"sum\": 5.576160245028409, \"min\": 5.576160245028409}}, \"EndTime\": 1580335325.269304, \"Dimensions\": {\"model\": 0, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 5}, \"StartTime\": 1580335325.269226}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 5.975527854225852, \"sum\": 5.975527854225852, \"min\": 5.975527854225852}}, \"EndTime\": 1580335325.269426, \"Dimensions\": {\"model\": 1, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 5}, \"StartTime\": 1580335325.269408}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 5.650417835582386, \"sum\": 5.650417835582386, \"min\": 5.650417835582386}}, \"EndTime\": 1580335325.269481, \"Dimensions\": {\"model\": 2, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 5}, \"StartTime\": 1580335325.269468}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 5.91943037553267, \"sum\": 5.91943037553267, \"min\": 5.91943037553267}}, \"EndTime\": 1580335325.269529, \"Dimensions\": {\"model\": 3, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 5}, \"StartTime\": 1580335325.269517}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 5.929160134055397, \"sum\": 5.929160134055397, \"min\": 5.929160134055397}}, \"EndTime\": 1580335325.269576, \"Dimensions\": {\"model\": 4, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 5}, \"StartTime\": 1580335325.269564}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 5.655063520951704, \"sum\": 5.655063520951704, \"min\": 5.655063520951704}}, \"EndTime\": 1580335325.269863, \"Dimensions\": {\"model\": 5, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 5}, \"StartTime\": 1580335325.269844}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 5.755840931285511, \"sum\": 5.755840931285511, \"min\": 5.755840931285511}}, \"EndTime\": 1580335325.269935, \"Dimensions\": {\"model\": 6, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 5}, \"StartTime\": 1580335325.269919}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 6.270394797585228, \"sum\": 6.270394797585228, \"min\": 6.270394797585228}}, \"EndTime\": 1580335325.269985, \"Dimensions\": {\"model\": 7, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 5}, \"StartTime\": 1580335325.269973}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 6.160576571377841, \"sum\": 6.160576571377841, \"min\": 6.160576571377841}}, \"EndTime\": 1580335325.270033, \"Dimensions\": {\"model\": 8, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 5}, \"StartTime\": 1580335325.270021}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 6.69027510209517, \"sum\": 6.69027510209517, \"min\": 6.69027510209517}}, \"EndTime\": 1580335325.270079, \"Dimensions\": {\"model\": 9, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 5}, \"StartTime\": 1580335325.270067}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 6.376843394886364, \"sum\": 6.376843394886364, \"min\": 6.376843394886364}}, \"EndTime\": 1580335325.270124, \"Dimensions\": {\"model\": 10, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 5}, \"StartTime\": 1580335325.270112}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 5.988453879616477, \"sum\": 5.988453879616477, \"min\": 5.988453879616477}}, \"EndTime\": 1580335325.270169, \"Dimensions\": {\"model\": 11, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 5}, \"StartTime\": 1580335325.270157}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 5.585749755859375, \"sum\": 5.585749755859375, \"min\": 5.585749755859375}}, \"EndTime\": 1580335325.270216, \"Dimensions\": {\"model\": 12, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 5}, \"StartTime\": 1580335325.270204}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 5.95007450727983, \"sum\": 5.95007450727983, \"min\": 5.95007450727983}}, \"EndTime\": 1580335325.270261, \"Dimensions\": {\"model\": 13, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 5}, \"StartTime\": 1580335325.270249}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 5.692884543678978, \"sum\": 5.692884543678978, \"min\": 5.692884543678978}}, \"EndTime\": 1580335325.270306, \"Dimensions\": {\"model\": 14, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 5}, \"StartTime\": 1580335325.270294}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/29/2020 22:02:05 INFO 139697286510400] #quality_metric: host=algo-1, epoch=5, train weighted_softmax_loss_objective <loss>=5.57616024503\u001b[0m\n",
      "\u001b[34m[2020-01-29 22:02:05.323] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/validation\", \"epoch\": 17, \"duration\": 35, \"num_examples\": 2, \"num_bytes\": 106704}\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 6.216538237495783, \"sum\": 6.216538237495783, \"min\": 6.216538237495783}}, \"EndTime\": 1580335325.328429, \"Dimensions\": {\"model\": 0, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 5}, \"StartTime\": 1580335325.328375}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 7.259712909075573, \"sum\": 7.259712909075573, \"min\": 7.259712909075573}}, \"EndTime\": 1580335325.328511, \"Dimensions\": {\"model\": 1, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 5}, \"StartTime\": 1580335325.328496}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 6.309882654352227, \"sum\": 6.309882654352227, \"min\": 6.309882654352227}}, \"EndTime\": 1580335325.328554, \"Dimensions\": {\"model\": 2, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 5}, \"StartTime\": 1580335325.328543}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 7.29279379902581, \"sum\": 7.29279379902581, \"min\": 7.29279379902581}}, \"EndTime\": 1580335325.328589, \"Dimensions\": {\"model\": 3, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 5}, \"StartTime\": 1580335325.32858}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 6.589013309453019, \"sum\": 6.589013309453019, \"min\": 6.589013309453019}}, \"EndTime\": 1580335325.32863, \"Dimensions\": {\"model\": 4, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 5}, \"StartTime\": 1580335325.328614}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 7.0244677668480096, \"sum\": 7.0244677668480096, \"min\": 7.0244677668480096}}, \"EndTime\": 1580335325.328689, \"Dimensions\": {\"model\": 5, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 5}, \"StartTime\": 1580335325.328671}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 6.365677353502446, \"sum\": 6.365677353502446, \"min\": 6.365677353502446}}, \"EndTime\": 1580335325.328737, \"Dimensions\": {\"model\": 6, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 5}, \"StartTime\": 1580335325.328726}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 6.909261891394652, \"sum\": 6.909261891394652, \"min\": 6.909261891394652}}, \"EndTime\": 1580335325.328796, \"Dimensions\": {\"model\": 7, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 5}, \"StartTime\": 1580335325.328777}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 7.023303898079032, \"sum\": 7.023303898079032, \"min\": 7.023303898079032}}, \"EndTime\": 1580335325.328856, \"Dimensions\": {\"model\": 8, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 5}, \"StartTime\": 1580335325.328839}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 7.398204396771677, \"sum\": 7.398204396771677, \"min\": 7.398204396771677}}, \"EndTime\": 1580335325.328911, \"Dimensions\": {\"model\": 9, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 5}, \"StartTime\": 1580335325.3289}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 7.033539518492747, \"sum\": 7.033539518492747, \"min\": 7.033539518492747}}, \"EndTime\": 1580335325.328946, \"Dimensions\": {\"model\": 10, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 5}, \"StartTime\": 1580335325.328937}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 7.539352931796137, \"sum\": 7.539352931796137, \"min\": 7.539352931796137}}, \"EndTime\": 1580335325.328978, \"Dimensions\": {\"model\": 11, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 5}, \"StartTime\": 1580335325.328968}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 6.242056863349781, \"sum\": 6.242056863349781, \"min\": 6.242056863349781}}, \"EndTime\": 1580335325.329037, \"Dimensions\": {\"model\": 12, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 5}, \"StartTime\": 1580335325.32902}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 7.220483365490047, \"sum\": 7.220483365490047, \"min\": 7.220483365490047}}, \"EndTime\": 1580335325.329097, \"Dimensions\": {\"model\": 13, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 5}, \"StartTime\": 1580335325.32908}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 6.325093504870951, \"sum\": 6.325093504870951, \"min\": 6.325093504870951}}, \"EndTime\": 1580335325.329157, \"Dimensions\": {\"model\": 14, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 5}, \"StartTime\": 1580335325.32914}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/29/2020 22:02:05 INFO 139697286510400] #quality_metric: host=algo-1, epoch=5, validation weighted_softmax_loss_objective <loss>=6.2165382375\u001b[0m\n",
      "\u001b[34m[01/29/2020 22:02:05 INFO 139697286510400] #early_stopping_criteria_metric: host=algo-1, epoch=5, criteria=weighted_softmax_loss_objective, value=6.2165382375\u001b[0m\n",
      "\u001b[34m[01/29/2020 22:02:05 INFO 139697286510400] #progress_metric: host=algo-1, completed 40 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 12, \"sum\": 12.0, \"min\": 12}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 12, \"sum\": 12.0, \"min\": 12}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 11860, \"sum\": 11860.0, \"min\": 11860}, \"Total Batches Seen\": {\"count\": 1, \"max\": 84, \"sum\": 84.0, \"min\": 84}, \"Total Records Seen\": {\"count\": 1, \"max\": 83160, \"sum\": 83160.0, \"min\": 83160}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 11860, \"sum\": 11860.0, \"min\": 11860}, \"Reset Count\": {\"count\": 1, \"max\": 8, \"sum\": 8.0, \"min\": 8}}, \"EndTime\": 1580335325.330015, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 5}, \"StartTime\": 1580335324.941582}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/29/2020 22:02:05 INFO 139697286510400] #throughput_metric: host=algo-1, train throughput=30523.4203302 records/second\u001b[0m\n",
      "\u001b[34m[2020-01-29 22:02:05.661] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 15, \"duration\": 331, \"num_examples\": 12, \"num_bytes\": 853920}\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 5.544584073153409, \"sum\": 5.544584073153409, \"min\": 5.544584073153409}}, \"EndTime\": 1580335325.661735, \"Dimensions\": {\"model\": 0, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 6}, \"StartTime\": 1580335325.661629}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 5.885296075994318, \"sum\": 5.885296075994318, \"min\": 5.885296075994318}}, \"EndTime\": 1580335325.661832, \"Dimensions\": {\"model\": 1, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 6}, \"StartTime\": 1580335325.661815}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 5.644503196022727, \"sum\": 5.644503196022727, \"min\": 5.644503196022727}}, \"EndTime\": 1580335325.661918, \"Dimensions\": {\"model\": 2, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 6}, \"StartTime\": 1580335325.661902}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 5.837214777166193, \"sum\": 5.837214777166193, \"min\": 5.837214777166193}}, \"EndTime\": 1580335325.661967, \"Dimensions\": {\"model\": 3, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 6}, \"StartTime\": 1580335325.661955}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 5.854121781782671, \"sum\": 5.854121781782671, \"min\": 5.854121781782671}}, \"EndTime\": 1580335325.662013, \"Dimensions\": {\"model\": 4, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 6}, \"StartTime\": 1580335325.662001}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 5.628715864701705, \"sum\": 5.628715864701705, \"min\": 5.628715864701705}}, \"EndTime\": 1580335325.662059, \"Dimensions\": {\"model\": 5, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 6}, \"StartTime\": 1580335325.662047}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 5.685546186967329, \"sum\": 5.685546186967329, \"min\": 5.685546186967329}}, \"EndTime\": 1580335325.662104, \"Dimensions\": {\"model\": 6, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 6}, \"StartTime\": 1580335325.662093}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 6.152529052734375, \"sum\": 6.152529052734375, \"min\": 6.152529052734375}}, \"EndTime\": 1580335325.662149, \"Dimensions\": {\"model\": 7, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 6}, \"StartTime\": 1580335325.662137}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 6.157866987748579, \"sum\": 6.157866987748579, \"min\": 6.157866987748579}}, \"EndTime\": 1580335325.662194, \"Dimensions\": {\"model\": 8, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 6}, \"StartTime\": 1580335325.662182}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 6.674628462357955, \"sum\": 6.674628462357955, \"min\": 6.674628462357955}}, \"EndTime\": 1580335325.662238, \"Dimensions\": {\"model\": 9, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 6}, \"StartTime\": 1580335325.662227}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 6.265786576704546, \"sum\": 6.265786576704546, \"min\": 6.265786576704546}}, \"EndTime\": 1580335325.662283, \"Dimensions\": {\"model\": 10, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 6}, \"StartTime\": 1580335325.662271}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 5.962764137961647, \"sum\": 5.962764137961647, \"min\": 5.962764137961647}}, \"EndTime\": 1580335325.662336, \"Dimensions\": {\"model\": 11, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 6}, \"StartTime\": 1580335325.662323}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 5.581042502663352, \"sum\": 5.581042502663352, \"min\": 5.581042502663352}}, \"EndTime\": 1580335325.662388, \"Dimensions\": {\"model\": 12, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 6}, \"StartTime\": 1580335325.662376}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 5.866893310546875, \"sum\": 5.866893310546875, \"min\": 5.866893310546875}}, \"EndTime\": 1580335325.66244, \"Dimensions\": {\"model\": 13, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 6}, \"StartTime\": 1580335325.662427}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 5.748451526988636, \"sum\": 5.748451526988636, \"min\": 5.748451526988636}}, \"EndTime\": 1580335325.662489, \"Dimensions\": {\"model\": 14, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 6}, \"StartTime\": 1580335325.662476}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/29/2020 22:02:05 INFO 139697286510400] #quality_metric: host=algo-1, epoch=6, train weighted_softmax_loss_objective <loss>=5.54458407315\u001b[0m\n",
      "\u001b[34m[2020-01-29 22:02:05.714] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/validation\", \"epoch\": 20, \"duration\": 39, \"num_examples\": 2, \"num_bytes\": 106704}\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 6.21637004074941, \"sum\": 6.21637004074941, \"min\": 6.21637004074941}}, \"EndTime\": 1580335325.719863, \"Dimensions\": {\"model\": 0, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 6}, \"StartTime\": 1580335325.719788}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 7.182567601583586, \"sum\": 7.182567601583586, \"min\": 7.182567601583586}}, \"EndTime\": 1580335325.71999, \"Dimensions\": {\"model\": 1, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 6}, \"StartTime\": 1580335325.719964}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 6.240477197726889, \"sum\": 6.240477197726889, \"min\": 6.240477197726889}}, \"EndTime\": 1580335325.720068, \"Dimensions\": {\"model\": 2, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 6}, \"StartTime\": 1580335325.720046}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 7.224039054592612, \"sum\": 7.224039054592612, \"min\": 7.224039054592612}}, \"EndTime\": 1580335325.720161, \"Dimensions\": {\"model\": 3, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 6}, \"StartTime\": 1580335325.72014}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 6.4971511984965415, \"sum\": 6.4971511984965415, \"min\": 6.4971511984965415}}, \"EndTime\": 1580335325.720231, \"Dimensions\": {\"model\": 4, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 6}, \"StartTime\": 1580335325.720211}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 7.001721998618843, \"sum\": 7.001721998618843, \"min\": 7.001721998618843}}, \"EndTime\": 1580335325.720296, \"Dimensions\": {\"model\": 5, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 6}, \"StartTime\": 1580335325.720279}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 6.321431230758687, \"sum\": 6.321431230758687, \"min\": 6.321431230758687}}, \"EndTime\": 1580335325.720361, \"Dimensions\": {\"model\": 6, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 6}, \"StartTime\": 1580335325.720342}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 6.816607064724612, \"sum\": 6.816607064724612, \"min\": 6.816607064724612}}, \"EndTime\": 1580335325.720425, \"Dimensions\": {\"model\": 7, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 6}, \"StartTime\": 1580335325.720406}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 7.1626273089574894, \"sum\": 7.1626273089574894, \"min\": 7.1626273089574894}}, \"EndTime\": 1580335325.720489, \"Dimensions\": {\"model\": 8, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 6}, \"StartTime\": 1580335325.72047}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 7.39453553316886, \"sum\": 7.39453553316886, \"min\": 7.39453553316886}}, \"EndTime\": 1580335325.720554, \"Dimensions\": {\"model\": 9, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 6}, \"StartTime\": 1580335325.720536}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 6.932025945460104, \"sum\": 6.932025945460104, \"min\": 6.932025945460104}}, \"EndTime\": 1580335325.720617, \"Dimensions\": {\"model\": 10, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 6}, \"StartTime\": 1580335325.720599}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 7.523724966525388, \"sum\": 7.523724966525388, \"min\": 7.523724966525388}}, \"EndTime\": 1580335325.720678, \"Dimensions\": {\"model\": 11, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 6}, \"StartTime\": 1580335325.72066}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 6.204280961380314, \"sum\": 6.204280961380314, \"min\": 6.204280961380314}}, \"EndTime\": 1580335325.720738, \"Dimensions\": {\"model\": 12, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 6}, \"StartTime\": 1580335325.720721}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 7.148678510616987, \"sum\": 7.148678510616987, \"min\": 7.148678510616987}}, \"EndTime\": 1580335325.720795, \"Dimensions\": {\"model\": 13, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 6}, \"StartTime\": 1580335325.720779}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 6.328511967832743, \"sum\": 6.328511967832743, \"min\": 6.328511967832743}}, \"EndTime\": 1580335325.720854, \"Dimensions\": {\"model\": 14, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 6}, \"StartTime\": 1580335325.720837}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/29/2020 22:02:05 INFO 139697286510400] #quality_metric: host=algo-1, epoch=6, validation weighted_softmax_loss_objective <loss>=6.21637004075\u001b[0m\n",
      "\u001b[34m[01/29/2020 22:02:05 INFO 139697286510400] #early_stopping_criteria_metric: host=algo-1, epoch=6, criteria=weighted_softmax_loss_objective, value=6.20428096138\u001b[0m\n",
      "\u001b[34m[01/29/2020 22:02:05 INFO 139697286510400] Epoch 6: Loss improved. Updating best model\u001b[0m\n",
      "\u001b[34m[01/29/2020 22:02:05 INFO 139697286510400] #progress_metric: host=algo-1, completed 46 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 12, \"sum\": 12.0, \"min\": 12}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 12, \"sum\": 12.0, \"min\": 12}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 11860, \"sum\": 11860.0, \"min\": 11860}, \"Total Batches Seen\": {\"count\": 1, \"max\": 96, \"sum\": 96.0, \"min\": 96}, \"Total Records Seen\": {\"count\": 1, \"max\": 95020, \"sum\": 95020.0, \"min\": 95020}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 11860, \"sum\": 11860.0, \"min\": 11860}, \"Reset Count\": {\"count\": 1, \"max\": 9, \"sum\": 9.0, \"min\": 9}}, \"EndTime\": 1580335325.722634, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 6}, \"StartTime\": 1580335325.330274}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/29/2020 22:02:05 INFO 139697286510400] #throughput_metric: host=algo-1, train throughput=30217.0252557 records/second\u001b[0m\n",
      "\u001b[34m[2020-01-29 22:02:06.077] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 17, \"duration\": 351, \"num_examples\": 12, \"num_bytes\": 853920}\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 5.543812522194602, \"sum\": 5.543812522194602, \"min\": 5.543812522194602}}, \"EndTime\": 1580335326.077561, \"Dimensions\": {\"model\": 0, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 7}, \"StartTime\": 1580335326.077488}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 5.815663529829545, \"sum\": 5.815663529829545, \"min\": 5.815663529829545}}, \"EndTime\": 1580335326.077652, \"Dimensions\": {\"model\": 1, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 7}, \"StartTime\": 1580335326.077636}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 5.610113059303977, \"sum\": 5.610113059303977, \"min\": 5.610113059303977}}, \"EndTime\": 1580335326.077705, \"Dimensions\": {\"model\": 2, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 7}, \"StartTime\": 1580335326.077692}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 5.776964288884943, \"sum\": 5.776964288884943, \"min\": 5.776964288884943}}, \"EndTime\": 1580335326.077757, \"Dimensions\": {\"model\": 3, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 7}, \"StartTime\": 1580335326.077744}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 5.784542724609375, \"sum\": 5.784542724609375, \"min\": 5.784542724609375}}, \"EndTime\": 1580335326.077811, \"Dimensions\": {\"model\": 4, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 7}, \"StartTime\": 1580335326.077798}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 5.610878573330966, \"sum\": 5.610878573330966, \"min\": 5.610878573330966}}, \"EndTime\": 1580335326.077865, \"Dimensions\": {\"model\": 5, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 7}, \"StartTime\": 1580335326.077853}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 5.656182017933238, \"sum\": 5.656182017933238, \"min\": 5.656182017933238}}, \"EndTime\": 1580335326.077912, \"Dimensions\": {\"model\": 6, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 7}, \"StartTime\": 1580335326.0779}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 6.060023304332386, \"sum\": 6.060023304332386, \"min\": 6.060023304332386}}, \"EndTime\": 1580335326.077965, \"Dimensions\": {\"model\": 7, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 7}, \"StartTime\": 1580335326.077952}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 6.219546697443182, \"sum\": 6.219546697443182, \"min\": 6.219546697443182}}, \"EndTime\": 1580335326.078011, \"Dimensions\": {\"model\": 8, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 7}, \"StartTime\": 1580335326.077999}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 6.672764337713068, \"sum\": 6.672764337713068, \"min\": 6.672764337713068}}, \"EndTime\": 1580335326.078063, \"Dimensions\": {\"model\": 9, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 7}, \"StartTime\": 1580335326.078051}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 6.171300315163352, \"sum\": 6.171300315163352, \"min\": 6.171300315163352}}, \"EndTime\": 1580335326.078116, \"Dimensions\": {\"model\": 10, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 7}, \"StartTime\": 1580335326.078103}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 5.9478943314985795, \"sum\": 5.9478943314985795, \"min\": 5.9478943314985795}}, \"EndTime\": 1580335326.078163, \"Dimensions\": {\"model\": 11, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 7}, \"StartTime\": 1580335326.078151}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 5.563724143288352, \"sum\": 5.563724143288352, \"min\": 5.563724143288352}}, \"EndTime\": 1580335326.07821, \"Dimensions\": {\"model\": 12, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 7}, \"StartTime\": 1580335326.078198}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 5.797577459161932, \"sum\": 5.797577459161932, \"min\": 5.797577459161932}}, \"EndTime\": 1580335326.078262, \"Dimensions\": {\"model\": 13, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 7}, \"StartTime\": 1580335326.078249}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 5.770619118430398, \"sum\": 5.770619118430398, \"min\": 5.770619118430398}}, \"EndTime\": 1580335326.078315, \"Dimensions\": {\"model\": 14, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 7}, \"StartTime\": 1580335326.078302}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/29/2020 22:02:06 INFO 139697286510400] #quality_metric: host=algo-1, epoch=7, train weighted_softmax_loss_objective <loss>=5.54381252219\u001b[0m\n",
      "\u001b[34m[2020-01-29 22:02:06.128] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/validation\", \"epoch\": 23, \"duration\": 37, \"num_examples\": 2, \"num_bytes\": 106704}\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 6.204272230305331, \"sum\": 6.204272230305331, \"min\": 6.204272230305331}}, \"EndTime\": 1580335326.135123, \"Dimensions\": {\"model\": 0, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 7}, \"StartTime\": 1580335326.135063}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 7.123008985429318, \"sum\": 7.123008985429318, \"min\": 7.123008985429318}}, \"EndTime\": 1580335326.135215, \"Dimensions\": {\"model\": 1, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 7}, \"StartTime\": 1580335326.135194}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 6.230235152559885, \"sum\": 6.230235152559885, \"min\": 6.230235152559885}}, \"EndTime\": 1580335326.135288, \"Dimensions\": {\"model\": 2, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 7}, \"StartTime\": 1580335326.135268}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 7.173499803633182, \"sum\": 7.173499803633182, \"min\": 7.173499803633182}}, \"EndTime\": 1580335326.135356, \"Dimensions\": {\"model\": 3, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 7}, \"StartTime\": 1580335326.135336}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 6.453612292826417, \"sum\": 6.453612292826417, \"min\": 6.453612292826417}}, \"EndTime\": 1580335326.135424, \"Dimensions\": {\"model\": 4, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 7}, \"StartTime\": 1580335326.135404}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 6.983050018186994, \"sum\": 6.983050018186994, \"min\": 6.983050018186994}}, \"EndTime\": 1580335326.13549, \"Dimensions\": {\"model\": 5, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 7}, \"StartTime\": 1580335326.135471}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 6.297417644547065, \"sum\": 6.297417644547065, \"min\": 6.297417644547065}}, \"EndTime\": 1580335326.135554, \"Dimensions\": {\"model\": 6, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 7}, \"StartTime\": 1580335326.135536}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 6.7263595436909585, \"sum\": 6.7263595436909585, \"min\": 6.7263595436909585}}, \"EndTime\": 1580335326.135617, \"Dimensions\": {\"model\": 7, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 7}, \"StartTime\": 1580335326.1356}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 7.204432190188512, \"sum\": 7.204432190188512, \"min\": 7.204432190188512}}, \"EndTime\": 1580335326.13568, \"Dimensions\": {\"model\": 8, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 7}, \"StartTime\": 1580335326.135664}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 7.389026389591768, \"sum\": 7.389026389591768, \"min\": 7.389026389591768}}, \"EndTime\": 1580335326.135741, \"Dimensions\": {\"model\": 9, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 7}, \"StartTime\": 1580335326.135723}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 6.847987701374831, \"sum\": 6.847987701374831, \"min\": 6.847987701374831}}, \"EndTime\": 1580335326.135848, \"Dimensions\": {\"model\": 10, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 7}, \"StartTime\": 1580335326.13583}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 7.514258504396508, \"sum\": 7.514258504396508, \"min\": 7.514258504396508}}, \"EndTime\": 1580335326.135907, \"Dimensions\": {\"model\": 11, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 7}, \"StartTime\": 1580335326.13589}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 6.216054074677379, \"sum\": 6.216054074677379, \"min\": 6.216054074677379}}, \"EndTime\": 1580335326.135964, \"Dimensions\": {\"model\": 12, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 7}, \"StartTime\": 1580335326.135949}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 7.057938754639001, \"sum\": 7.057938754639001, \"min\": 7.057938754639001}}, \"EndTime\": 1580335326.136021, \"Dimensions\": {\"model\": 13, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 7}, \"StartTime\": 1580335326.136006}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 6.313718396803306, \"sum\": 6.313718396803306, \"min\": 6.313718396803306}}, \"EndTime\": 1580335326.136077, \"Dimensions\": {\"model\": 14, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 7}, \"StartTime\": 1580335326.136061}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/29/2020 22:02:06 INFO 139697286510400] #quality_metric: host=algo-1, epoch=7, validation weighted_softmax_loss_objective <loss>=6.20427223031\u001b[0m\n",
      "\u001b[34m[01/29/2020 22:02:06 INFO 139697286510400] #early_stopping_criteria_metric: host=algo-1, epoch=7, criteria=weighted_softmax_loss_objective, value=6.20427223031\u001b[0m\n",
      "\u001b[34m[01/29/2020 22:02:06 INFO 139697286510400] #progress_metric: host=algo-1, completed 53 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 12, \"sum\": 12.0, \"min\": 12}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 12, \"sum\": 12.0, \"min\": 12}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 11860, \"sum\": 11860.0, \"min\": 11860}, \"Total Batches Seen\": {\"count\": 1, \"max\": 108, \"sum\": 108.0, \"min\": 108}, \"Total Records Seen\": {\"count\": 1, \"max\": 106880, \"sum\": 106880.0, \"min\": 106880}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 11860, \"sum\": 11860.0, \"min\": 11860}, \"Reset Count\": {\"count\": 1, \"max\": 10, \"sum\": 10.0, \"min\": 10}}, \"EndTime\": 1580335326.137097, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 7}, \"StartTime\": 1580335325.722942}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/29/2020 22:02:06 INFO 139697286510400] #throughput_metric: host=algo-1, train throughput=28627.1616295 records/second\u001b[0m\n",
      "\u001b[34m[2020-01-29 22:02:06.446] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 19, \"duration\": 307, \"num_examples\": 12, \"num_bytes\": 853920}\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 5.530768132990056, \"sum\": 5.530768132990056, \"min\": 5.530768132990056}}, \"EndTime\": 1580335326.446515, \"Dimensions\": {\"model\": 0, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 8}, \"StartTime\": 1580335326.446437}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 5.762046186967329, \"sum\": 5.762046186967329, \"min\": 5.762046186967329}}, \"EndTime\": 1580335326.446607, \"Dimensions\": {\"model\": 1, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 8}, \"StartTime\": 1580335326.44659}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 5.595081898082387, \"sum\": 5.595081898082387, \"min\": 5.595081898082387}}, \"EndTime\": 1580335326.44666, \"Dimensions\": {\"model\": 2, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 8}, \"StartTime\": 1580335326.446647}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 5.732482155539773, \"sum\": 5.732482155539773, \"min\": 5.732482155539773}}, \"EndTime\": 1580335326.446708, \"Dimensions\": {\"model\": 3, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 8}, \"StartTime\": 1580335326.446695}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 5.740461070667614, \"sum\": 5.740461070667614, \"min\": 5.740461070667614}}, \"EndTime\": 1580335326.446756, \"Dimensions\": {\"model\": 4, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 8}, \"StartTime\": 1580335326.446743}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 5.5996006747159095, \"sum\": 5.5996006747159095, \"min\": 5.5996006747159095}}, \"EndTime\": 1580335326.446801, \"Dimensions\": {\"model\": 5, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 8}, \"StartTime\": 1580335326.446789}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 5.626584716796875, \"sum\": 5.626584716796875, \"min\": 5.626584716796875}}, \"EndTime\": 1580335326.446848, \"Dimensions\": {\"model\": 6, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 8}, \"StartTime\": 1580335326.446836}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 5.98135302734375, \"sum\": 5.98135302734375, \"min\": 5.98135302734375}}, \"EndTime\": 1580335326.446894, \"Dimensions\": {\"model\": 7, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 8}, \"StartTime\": 1580335326.446882}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 6.251556729403409, \"sum\": 6.251556729403409, \"min\": 6.251556729403409}}, \"EndTime\": 1580335326.446939, \"Dimensions\": {\"model\": 8, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 8}, \"StartTime\": 1580335326.446927}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 6.669011363636364, \"sum\": 6.669011363636364, \"min\": 6.669011363636364}}, \"EndTime\": 1580335326.446984, \"Dimensions\": {\"model\": 9, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 8}, \"StartTime\": 1580335326.446972}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 6.090914217862216, \"sum\": 6.090914217862216, \"min\": 6.090914217862216}}, \"EndTime\": 1580335326.447029, \"Dimensions\": {\"model\": 10, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 8}, \"StartTime\": 1580335326.447017}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 5.939818914240057, \"sum\": 5.939818914240057, \"min\": 5.939818914240057}}, \"EndTime\": 1580335326.447077, \"Dimensions\": {\"model\": 11, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 8}, \"StartTime\": 1580335326.447064}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 5.562941339666193, \"sum\": 5.562941339666193, \"min\": 5.562941339666193}}, \"EndTime\": 1580335326.447122, \"Dimensions\": {\"model\": 12, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 8}, \"StartTime\": 1580335326.44711}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 5.74604414506392, \"sum\": 5.74604414506392, \"min\": 5.74604414506392}}, \"EndTime\": 1580335326.447167, \"Dimensions\": {\"model\": 13, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 8}, \"StartTime\": 1580335326.447155}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 5.764212801846591, \"sum\": 5.764212801846591, \"min\": 5.764212801846591}}, \"EndTime\": 1580335326.447211, \"Dimensions\": {\"model\": 14, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 8}, \"StartTime\": 1580335326.447199}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/29/2020 22:02:06 INFO 139697286510400] #quality_metric: host=algo-1, epoch=8, train weighted_softmax_loss_objective <loss>=5.53076813299\u001b[0m\n",
      "\u001b[34m[2020-01-29 22:02:06.488] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/validation\", \"epoch\": 26, \"duration\": 29, \"num_examples\": 2, \"num_bytes\": 106704}\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 6.200610779879386, \"sum\": 6.200610779879386, \"min\": 6.200610779879386}}, \"EndTime\": 1580335326.493606, \"Dimensions\": {\"model\": 0, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 8}, \"StartTime\": 1580335326.493554}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 7.0768970484353915, \"sum\": 7.0768970484353915, \"min\": 7.0768970484353915}}, \"EndTime\": 1580335326.493687, \"Dimensions\": {\"model\": 1, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 8}, \"StartTime\": 1580335326.493673}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 6.2220483694964575, \"sum\": 6.2220483694964575, \"min\": 6.2220483694964575}}, \"EndTime\": 1580335326.493756, \"Dimensions\": {\"model\": 2, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 8}, \"StartTime\": 1580335326.493737}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 7.136004613961285, \"sum\": 7.136004613961285, \"min\": 7.136004613961285}}, \"EndTime\": 1580335326.493819, \"Dimensions\": {\"model\": 3, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 8}, \"StartTime\": 1580335326.493803}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 6.406076037449393, \"sum\": 6.406076037449393, \"min\": 6.406076037449393}}, \"EndTime\": 1580335326.493887, \"Dimensions\": {\"model\": 4, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 8}, \"StartTime\": 1580335326.493869}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 6.973803150830803, \"sum\": 6.973803150830803, \"min\": 6.973803150830803}}, \"EndTime\": 1580335326.493955, \"Dimensions\": {\"model\": 5, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 8}, \"StartTime\": 1580335326.493937}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 6.268263432017544, \"sum\": 6.268263432017544, \"min\": 6.268263432017544}}, \"EndTime\": 1580335326.49402, \"Dimensions\": {\"model\": 6, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 8}, \"StartTime\": 1580335326.494002}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 6.659062394568151, \"sum\": 6.659062394568151, \"min\": 6.659062394568151}}, \"EndTime\": 1580335326.494085, \"Dimensions\": {\"model\": 7, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 8}, \"StartTime\": 1580335326.494067}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 7.1067441458965925, \"sum\": 7.1067441458965925, \"min\": 7.1067441458965925}}, \"EndTime\": 1580335326.494148, \"Dimensions\": {\"model\": 8, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 8}, \"StartTime\": 1580335326.494132}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 7.388858028108131, \"sum\": 7.388858028108131, \"min\": 7.388858028108131}}, \"EndTime\": 1580335326.494213, \"Dimensions\": {\"model\": 9, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 8}, \"StartTime\": 1580335326.494195}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 6.771685519199139, \"sum\": 6.771685519199139, \"min\": 6.771685519199139}}, \"EndTime\": 1580335326.494276, \"Dimensions\": {\"model\": 10, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 8}, \"StartTime\": 1580335326.494258}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 7.509193327745446, \"sum\": 7.509193327745446, \"min\": 7.509193327745446}}, \"EndTime\": 1580335326.494342, \"Dimensions\": {\"model\": 11, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 8}, \"StartTime\": 1580335326.494325}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 6.198177939967105, \"sum\": 6.198177939967105, \"min\": 6.198177939967105}}, \"EndTime\": 1580335326.494406, \"Dimensions\": {\"model\": 12, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 8}, \"StartTime\": 1580335326.494393}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 7.017411410889001, \"sum\": 7.017411410889001, \"min\": 7.017411410889001}}, \"EndTime\": 1580335326.494461, \"Dimensions\": {\"model\": 13, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 8}, \"StartTime\": 1580335326.494444}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 6.304203996130651, \"sum\": 6.304203996130651, \"min\": 6.304203996130651}}, \"EndTime\": 1580335326.494524, \"Dimensions\": {\"model\": 14, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 8}, \"StartTime\": 1580335326.494508}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/29/2020 22:02:06 INFO 139697286510400] #quality_metric: host=algo-1, epoch=8, validation weighted_softmax_loss_objective <loss>=6.20061077988\u001b[0m\n",
      "\u001b[34m[01/29/2020 22:02:06 INFO 139697286510400] #early_stopping_criteria_metric: host=algo-1, epoch=8, criteria=weighted_softmax_loss_objective, value=6.19817793997\u001b[0m\n",
      "\u001b[34m[01/29/2020 22:02:06 INFO 139697286510400] #progress_metric: host=algo-1, completed 60 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 12, \"sum\": 12.0, \"min\": 12}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 12, \"sum\": 12.0, \"min\": 12}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 11860, \"sum\": 11860.0, \"min\": 11860}, \"Total Batches Seen\": {\"count\": 1, \"max\": 120, \"sum\": 120.0, \"min\": 120}, \"Total Records Seen\": {\"count\": 1, \"max\": 118740, \"sum\": 118740.0, \"min\": 118740}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 11860, \"sum\": 11860.0, \"min\": 11860}, \"Reset Count\": {\"count\": 1, \"max\": 11, \"sum\": 11.0, \"min\": 11}}, \"EndTime\": 1580335326.495405, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 8}, \"StartTime\": 1580335326.137356}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/29/2020 22:02:06 INFO 139697286510400] #throughput_metric: host=algo-1, train throughput=33111.5524229 records/second\u001b[0m\n",
      "\u001b[34m[2020-01-29 22:02:06.775] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 21, \"duration\": 279, \"num_examples\": 12, \"num_bytes\": 853920}\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 5.527494695490057, \"sum\": 5.527494695490057, \"min\": 5.527494695490057}}, \"EndTime\": 1580335326.775766, \"Dimensions\": {\"model\": 0, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 9}, \"StartTime\": 1580335326.775682}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 5.720488192471591, \"sum\": 5.720488192471591, \"min\": 5.720488192471591}}, \"EndTime\": 1580335326.77587, \"Dimensions\": {\"model\": 1, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 9}, \"StartTime\": 1580335326.775845}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 5.585362437855114, \"sum\": 5.585362437855114, \"min\": 5.585362437855114}}, \"EndTime\": 1580335326.775997, \"Dimensions\": {\"model\": 2, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 9}, \"StartTime\": 1580335326.775974}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 5.699481622869318, \"sum\": 5.699481622869318, \"min\": 5.699481622869318}}, \"EndTime\": 1580335326.776066, \"Dimensions\": {\"model\": 3, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 9}, \"StartTime\": 1580335326.776047}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 5.701760786576704, \"sum\": 5.701760786576704, \"min\": 5.701760786576704}}, \"EndTime\": 1580335326.776155, \"Dimensions\": {\"model\": 4, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 9}, \"StartTime\": 1580335326.776135}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 5.5919584073153406, \"sum\": 5.5919584073153406, \"min\": 5.5919584073153406}}, \"EndTime\": 1580335326.77622, \"Dimensions\": {\"model\": 5, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 9}, \"StartTime\": 1580335326.776202}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 5.609061212713068, \"sum\": 5.609061212713068, \"min\": 5.609061212713068}}, \"EndTime\": 1580335326.776284, \"Dimensions\": {\"model\": 6, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 9}, \"StartTime\": 1580335326.776266}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 5.917368541370738, \"sum\": 5.917368541370738, \"min\": 5.917368541370738}}, \"EndTime\": 1580335326.776347, \"Dimensions\": {\"model\": 7, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 9}, \"StartTime\": 1580335326.776331}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 6.221881192294034, \"sum\": 6.221881192294034, \"min\": 6.221881192294034}}, \"EndTime\": 1580335326.776407, \"Dimensions\": {\"model\": 8, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 9}, \"StartTime\": 1580335326.776391}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 6.668434992009943, \"sum\": 6.668434992009943, \"min\": 6.668434992009943}}, \"EndTime\": 1580335326.77647, \"Dimensions\": {\"model\": 9, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 9}, \"StartTime\": 1580335326.776453}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 6.020999578302557, \"sum\": 6.020999578302557, \"min\": 6.020999578302557}}, \"EndTime\": 1580335326.776532, \"Dimensions\": {\"model\": 10, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 9}, \"StartTime\": 1580335326.776514}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 5.935975941051137, \"sum\": 5.935975941051137, \"min\": 5.935975941051137}}, \"EndTime\": 1580335326.776614, \"Dimensions\": {\"model\": 11, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 9}, \"StartTime\": 1580335326.776596}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 5.554937721946023, \"sum\": 5.554937721946023, \"min\": 5.554937721946023}}, \"EndTime\": 1580335326.776673, \"Dimensions\": {\"model\": 12, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 9}, \"StartTime\": 1580335326.776657}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 5.704685613458807, \"sum\": 5.704685613458807, \"min\": 5.704685613458807}}, \"EndTime\": 1580335326.776733, \"Dimensions\": {\"model\": 13, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 9}, \"StartTime\": 1580335326.776715}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 5.755552978515625, \"sum\": 5.755552978515625, \"min\": 5.755552978515625}}, \"EndTime\": 1580335326.776793, \"Dimensions\": {\"model\": 14, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 9}, \"StartTime\": 1580335326.776776}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/29/2020 22:02:06 INFO 139697286510400] #quality_metric: host=algo-1, epoch=9, train weighted_softmax_loss_objective <loss>=5.52749469549\u001b[0m\n",
      "\u001b[34m[2020-01-29 22:02:06.817] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/validation\", \"epoch\": 29, \"duration\": 28, \"num_examples\": 2, \"num_bytes\": 106704}\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 6.195845589785763, \"sum\": 6.195845589785763, \"min\": 6.195845589785763}}, \"EndTime\": 1580335326.822363, \"Dimensions\": {\"model\": 0, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 9}, \"StartTime\": 1580335326.82231}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 7.041427138685054, \"sum\": 7.041427138685054, \"min\": 7.041427138685054}}, \"EndTime\": 1580335326.822445, \"Dimensions\": {\"model\": 1, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 9}, \"StartTime\": 1580335326.82243}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 6.204813392217021, \"sum\": 6.204813392217021, \"min\": 6.204813392217021}}, \"EndTime\": 1580335326.822516, \"Dimensions\": {\"model\": 2, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 9}, \"StartTime\": 1580335326.822496}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 7.108422159665992, \"sum\": 7.108422159665992, \"min\": 7.108422159665992}}, \"EndTime\": 1580335326.822585, \"Dimensions\": {\"model\": 3, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 9}, \"StartTime\": 1580335326.822569}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 6.376676201659497, \"sum\": 6.376676201659497, \"min\": 6.376676201659497}}, \"EndTime\": 1580335326.822651, \"Dimensions\": {\"model\": 4, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 9}, \"StartTime\": 1580335326.822632}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 6.963254035404015, \"sum\": 6.963254035404015, \"min\": 6.963254035404015}}, \"EndTime\": 1580335326.822716, \"Dimensions\": {\"model\": 5, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 9}, \"StartTime\": 1580335326.822698}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 6.257149432513073, \"sum\": 6.257149432513073, \"min\": 6.257149432513073}}, \"EndTime\": 1580335326.822788, \"Dimensions\": {\"model\": 6, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 9}, \"StartTime\": 1580335326.822769}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 6.6012055143492745, \"sum\": 6.6012055143492745, \"min\": 6.6012055143492745}}, \"EndTime\": 1580335326.822847, \"Dimensions\": {\"model\": 7, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 9}, \"StartTime\": 1580335326.822833}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 7.005303880946356, \"sum\": 7.005303880946356, \"min\": 7.005303880946356}}, \"EndTime\": 1580335326.822908, \"Dimensions\": {\"model\": 8, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 9}, \"StartTime\": 1580335326.822891}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 7.38758658590587, \"sum\": 7.38758658590587, \"min\": 7.38758658590587}}, \"EndTime\": 1580335326.822965, \"Dimensions\": {\"model\": 9, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 9}, \"StartTime\": 1580335326.822954}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 6.707469451121795, \"sum\": 6.707469451121795, \"min\": 6.707469451121795}}, \"EndTime\": 1580335326.823018, \"Dimensions\": {\"model\": 10, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 9}, \"StartTime\": 1580335326.823002}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 7.50690644504892, \"sum\": 7.50690644504892, \"min\": 7.50690644504892}}, \"EndTime\": 1580335326.82308, \"Dimensions\": {\"model\": 11, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 9}, \"StartTime\": 1580335326.823063}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 6.198690437594888, \"sum\": 6.198690437594888, \"min\": 6.198690437594888}}, \"EndTime\": 1580335326.823142, \"Dimensions\": {\"model\": 12, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 9}, \"StartTime\": 1580335326.823125}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 6.944726364815283, \"sum\": 6.944726364815283, \"min\": 6.944726364815283}}, \"EndTime\": 1580335326.823203, \"Dimensions\": {\"model\": 13, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 9}, \"StartTime\": 1580335326.823187}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 6.3064813240658735, \"sum\": 6.3064813240658735, \"min\": 6.3064813240658735}}, \"EndTime\": 1580335326.823275, \"Dimensions\": {\"model\": 14, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 9}, \"StartTime\": 1580335326.823257}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/29/2020 22:02:06 INFO 139697286510400] #quality_metric: host=algo-1, epoch=9, validation weighted_softmax_loss_objective <loss>=6.19584558979\u001b[0m\n",
      "\u001b[34m[01/29/2020 22:02:06 INFO 139697286510400] #early_stopping_criteria_metric: host=algo-1, epoch=9, criteria=weighted_softmax_loss_objective, value=6.19584558979\u001b[0m\n",
      "\u001b[34m[01/29/2020 22:02:06 INFO 139697286510400] #progress_metric: host=algo-1, completed 66 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 12, \"sum\": 12.0, \"min\": 12}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 12, \"sum\": 12.0, \"min\": 12}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 11860, \"sum\": 11860.0, \"min\": 11860}, \"Total Batches Seen\": {\"count\": 1, \"max\": 132, \"sum\": 132.0, \"min\": 132}, \"Total Records Seen\": {\"count\": 1, \"max\": 130600, \"sum\": 130600.0, \"min\": 130600}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 11860, \"sum\": 11860.0, \"min\": 11860}, \"Reset Count\": {\"count\": 1, \"max\": 12, \"sum\": 12.0, \"min\": 12}}, \"EndTime\": 1580335326.824279, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 9}, \"StartTime\": 1580335326.4957}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/29/2020 22:02:06 INFO 139697286510400] #throughput_metric: host=algo-1, train throughput=36080.4531195 records/second\u001b[0m\n",
      "\u001b[34m[2020-01-29 22:02:07.109] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 23, \"duration\": 284, \"num_examples\": 12, \"num_bytes\": 853920}\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 5.5204557217684656, \"sum\": 5.5204557217684656, \"min\": 5.5204557217684656}}, \"EndTime\": 1580335327.109465, \"Dimensions\": {\"model\": 0, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 10}, \"StartTime\": 1580335327.109386}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 5.6885404163707385, \"sum\": 5.6885404163707385, \"min\": 5.6885404163707385}}, \"EndTime\": 1580335327.109591, \"Dimensions\": {\"model\": 1, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 10}, \"StartTime\": 1580335327.109572}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 5.574026300603693, \"sum\": 5.574026300603693, \"min\": 5.574026300603693}}, \"EndTime\": 1580335327.109648, \"Dimensions\": {\"model\": 2, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 10}, \"StartTime\": 1580335327.109635}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 5.674822287819603, \"sum\": 5.674822287819603, \"min\": 5.674822287819603}}, \"EndTime\": 1580335327.109706, \"Dimensions\": {\"model\": 3, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 10}, \"StartTime\": 1580335327.109692}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 5.6738318093039775, \"sum\": 5.6738318093039775, \"min\": 5.6738318093039775}}, \"EndTime\": 1580335327.109761, \"Dimensions\": {\"model\": 4, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 10}, \"StartTime\": 1580335327.109747}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 5.586798783735795, \"sum\": 5.586798783735795, \"min\": 5.586798783735795}}, \"EndTime\": 1580335327.10981, \"Dimensions\": {\"model\": 5, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 10}, \"StartTime\": 1580335327.109798}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 5.593207608309659, \"sum\": 5.593207608309659, \"min\": 5.593207608309659}}, \"EndTime\": 1580335327.109863, \"Dimensions\": {\"model\": 6, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 10}, \"StartTime\": 1580335327.10985}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 5.863773237748579, \"sum\": 5.863773237748579, \"min\": 5.863773237748579}}, \"EndTime\": 1580335327.109916, \"Dimensions\": {\"model\": 7, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 10}, \"StartTime\": 1580335327.109903}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 6.172877707741478, \"sum\": 6.172877707741478, \"min\": 6.172877707741478}}, \"EndTime\": 1580335327.109964, \"Dimensions\": {\"model\": 8, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 10}, \"StartTime\": 1580335327.109951}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 6.66820674272017, \"sum\": 6.66820674272017, \"min\": 6.66820674272017}}, \"EndTime\": 1580335327.110011, \"Dimensions\": {\"model\": 9, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 10}, \"StartTime\": 1580335327.109999}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 5.961062966086648, \"sum\": 5.961062966086648, \"min\": 5.961062966086648}}, \"EndTime\": 1580335327.110063, \"Dimensions\": {\"model\": 10, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 10}, \"StartTime\": 1580335327.11005}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 5.934402521306819, \"sum\": 5.934402521306819, \"min\": 5.934402521306819}}, \"EndTime\": 1580335327.110115, \"Dimensions\": {\"model\": 11, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 10}, \"StartTime\": 1580335327.110102}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 5.55204052734375, \"sum\": 5.55204052734375, \"min\": 5.55204052734375}}, \"EndTime\": 1580335327.110164, \"Dimensions\": {\"model\": 12, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 10}, \"StartTime\": 1580335327.110152}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 5.669652521306818, \"sum\": 5.669652521306818, \"min\": 5.669652521306818}}, \"EndTime\": 1580335327.110212, \"Dimensions\": {\"model\": 13, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 10}, \"StartTime\": 1580335327.110199}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 5.755849165482955, \"sum\": 5.755849165482955, \"min\": 5.755849165482955}}, \"EndTime\": 1580335327.110258, \"Dimensions\": {\"model\": 14, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 10}, \"StartTime\": 1580335327.110246}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/29/2020 22:02:07 INFO 139697286510400] #quality_metric: host=algo-1, epoch=10, train weighted_softmax_loss_objective <loss>=5.52045572177\u001b[0m\n",
      "\u001b[34m[2020-01-29 22:02:07.165] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/validation\", \"epoch\": 32, \"duration\": 41, \"num_examples\": 2, \"num_bytes\": 106704}\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 6.191988102015857, \"sum\": 6.191988102015857, \"min\": 6.191988102015857}}, \"EndTime\": 1580335327.172862, \"Dimensions\": {\"model\": 0, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 10}, \"StartTime\": 1580335327.172782}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 7.014265588098853, \"sum\": 7.014265588098853, \"min\": 7.014265588098853}}, \"EndTime\": 1580335327.172988, \"Dimensions\": {\"model\": 1, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 10}, \"StartTime\": 1580335327.172963}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 6.201801830296896, \"sum\": 6.201801830296896, \"min\": 6.201801830296896}}, \"EndTime\": 1580335327.173067, \"Dimensions\": {\"model\": 2, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 10}, \"StartTime\": 1580335327.173046}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 7.087680914463141, \"sum\": 7.087680914463141, \"min\": 7.087680914463141}}, \"EndTime\": 1580335327.173143, \"Dimensions\": {\"model\": 3, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 10}, \"StartTime\": 1580335327.173122}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 6.349375612822621, \"sum\": 6.349375612822621, \"min\": 6.349375612822621}}, \"EndTime\": 1580335327.173216, \"Dimensions\": {\"model\": 4, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 10}, \"StartTime\": 1580335327.173196}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 6.959865719361504, \"sum\": 6.959865719361504, \"min\": 6.959865719361504}}, \"EndTime\": 1580335327.173281, \"Dimensions\": {\"model\": 5, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 10}, \"StartTime\": 1580335327.173264}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 6.240882451395918, \"sum\": 6.240882451395918, \"min\": 6.240882451395918}}, \"EndTime\": 1580335327.17335, \"Dimensions\": {\"model\": 6, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 10}, \"StartTime\": 1580335327.17333}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 6.551023578515098, \"sum\": 6.551023578515098, \"min\": 6.551023578515098}}, \"EndTime\": 1580335327.173423, \"Dimensions\": {\"model\": 7, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 10}, \"StartTime\": 1580335327.173403}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 6.968445400799173, \"sum\": 6.968445400799173, \"min\": 6.968445400799173}}, \"EndTime\": 1580335327.173494, \"Dimensions\": {\"model\": 8, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 10}, \"StartTime\": 1580335327.173474}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 7.386966185370277, \"sum\": 7.386966185370277, \"min\": 7.386966185370277}}, \"EndTime\": 1580335327.173566, \"Dimensions\": {\"model\": 9, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 10}, \"StartTime\": 1580335327.173545}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 6.652392841704622, \"sum\": 6.652392841704622, \"min\": 6.652392841704622}}, \"EndTime\": 1580335327.173635, \"Dimensions\": {\"model\": 10, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 10}, \"StartTime\": 1580335327.173616}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 7.505915385669703, \"sum\": 7.505915385669703, \"min\": 7.505915385669703}}, \"EndTime\": 1580335327.173703, \"Dimensions\": {\"model\": 11, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 10}, \"StartTime\": 1580335327.173685}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 6.193435154141363, \"sum\": 6.193435154141363, \"min\": 6.193435154141363}}, \"EndTime\": 1580335327.173767, \"Dimensions\": {\"model\": 12, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 10}, \"StartTime\": 1580335327.173748}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 6.923547083227901, \"sum\": 6.923547083227901, \"min\": 6.923547083227901}}, \"EndTime\": 1580335327.173831, \"Dimensions\": {\"model\": 13, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 10}, \"StartTime\": 1580335327.173813}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"validation_weighted_softmax_loss_objective\": {\"count\": 1, \"max\": 6.308564426767038, \"sum\": 6.308564426767038, \"min\": 6.308564426767038}}, \"EndTime\": 1580335327.173895, \"Dimensions\": {\"model\": 14, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 10}, \"StartTime\": 1580335327.173878}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/29/2020 22:02:07 INFO 139697286510400] #quality_metric: host=algo-1, epoch=10, validation weighted_softmax_loss_objective <loss>=6.19198810202\u001b[0m\n",
      "\u001b[34m[01/29/2020 22:02:07 INFO 139697286510400] #early_stopping_criteria_metric: host=algo-1, epoch=10, criteria=weighted_softmax_loss_objective, value=6.19198810202\u001b[0m\n",
      "\u001b[34m[01/29/2020 22:02:07 INFO 139697286510400] Early stop condition met. Stopping training.\u001b[0m\n",
      "\u001b[34m[01/29/2020 22:02:07 INFO 139697286510400] #progress_metric: host=algo-1, completed 100 % epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 12, \"sum\": 12.0, \"min\": 12}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 12, \"sum\": 12.0, \"min\": 12}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 11860, \"sum\": 11860.0, \"min\": 11860}, \"Total Batches Seen\": {\"count\": 1, \"max\": 144, \"sum\": 144.0, \"min\": 144}, \"Total Records Seen\": {\"count\": 1, \"max\": 142460, \"sum\": 142460.0, \"min\": 142460}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 11860, \"sum\": 11860.0, \"min\": 11860}, \"Reset Count\": {\"count\": 1, \"max\": 13, \"sum\": 13.0, \"min\": 13}}, \"EndTime\": 1580335327.175144, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 10}, \"StartTime\": 1580335326.824575}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/29/2020 22:02:07 INFO 139697286510400] #throughput_metric: host=algo-1, train throughput=33816.6392636 records/second\u001b[0m\n",
      "\u001b[34m[01/29/2020 22:02:07 WARNING 139697286510400] wait_for_all_workers will not sync workers since the kv store is not running distributed\u001b[0m\n",
      "\u001b[34m[01/29/2020 22:02:07 WARNING 139697286510400] wait_for_all_workers will not sync workers since the kv store is not running distributed\u001b[0m\n",
      "\u001b[34m[2020-01-29 22:02:07.227] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/validation\", \"epoch\": 35, \"duration\": 34, \"num_examples\": 2, \"num_bytes\": 106704}\u001b[0m\n",
      "\u001b[34m[01/29/2020 22:02:07 INFO 139697286510400] #early_stopping_criteria_metric: host=algo-1, epoch=10, criteria=weighted_softmax_loss_objective, value=6.19198810202\u001b[0m\n",
      "\u001b[34m[2020-01-29 22:02:07.261] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/validation\", \"epoch\": 37, \"duration\": 23, \"num_examples\": 2, \"num_bytes\": 106704}\u001b[0m\n",
      "\u001b[34m[01/29/2020 22:02:07 INFO 139697286510400] #validation_score (algo-1) : ('weighted_softmax_loss_objective', 6.204280961380314)\u001b[0m\n",
      "\u001b[34m[01/29/2020 22:02:07 INFO 139697286510400] #validation_score (algo-1) : ('multiclass_accuracy', 0.9844804318488529)\u001b[0m\n",
      "\u001b[34m[01/29/2020 22:02:07 INFO 139697286510400] #validation_score (algo-1) : ('multiclass_top_k_accuracy_3', 0.9973009446693657)\u001b[0m\n",
      "\u001b[34m[01/29/2020 22:02:07 INFO 139697286510400] #validation_score (algo-1) : ('dcg', 0.9924948585499958)\u001b[0m\n",
      "\u001b[34m[01/29/2020 22:02:07 INFO 139697286510400] #validation_score (algo-1) : ('macro_recall', 0.4)\u001b[0m\n",
      "\u001b[34m[01/29/2020 22:02:07 INFO 139697286510400] #validation_score (algo-1) : ('macro_precision', nan)\u001b[0m\n",
      "\u001b[34m[01/29/2020 22:02:07 INFO 139697286510400] #validation_score (algo-1) : ('macro_f_1.000', 0.29777777)\u001b[0m\n",
      "\u001b[34m[01/29/2020 22:02:07 INFO 139697286510400] #quality_metric: host=algo-1, validation weighted_softmax_loss_objective <loss>=6.20428096138\u001b[0m\n",
      "\u001b[34m[01/29/2020 22:02:07 INFO 139697286510400] #quality_metric: host=algo-1, validation multiclass_accuracy <score>=0.984480431849\u001b[0m\n",
      "\u001b[34m[01/29/2020 22:02:07 INFO 139697286510400] #quality_metric: host=algo-1, validation multiclass_top_k_accuracy_3 <score>=0.997300944669\u001b[0m\n",
      "\u001b[34m[01/29/2020 22:02:07 INFO 139697286510400] #quality_metric: host=algo-1, validation dcg <score>=0.99249485855\u001b[0m\n",
      "\u001b[34m[01/29/2020 22:02:07 INFO 139697286510400] #quality_metric: host=algo-1, validation macro_recall <score>=0.40000000596\u001b[0m\n",
      "\u001b[34m[01/29/2020 22:02:07 INFO 139697286510400] #quality_metric: host=algo-1, validation macro_precision <score>=nan\u001b[0m\n",
      "\u001b[34m[01/29/2020 22:02:07 INFO 139697286510400] #quality_metric: host=algo-1, validation macro_f_1.000 <score>=0.29777777195\u001b[0m\n",
      "\u001b[34m[01/29/2020 22:02:07 INFO 139697286510400] Best model found for hyperparameters: {\"lr_scheduler_step\": 16, \"wd\": 0.05944801003018111, \"optimizer\": \"adam\", \"lr_scheduler_factor\": 0.9945323368650523, \"l1\": 0.04625012248286039, \"learning_rate\": 0.022553784220131885, \"lr_scheduler_minimum_lr\": 1.5575517641504765e-06}\u001b[0m\n",
      "\u001b[34m[01/29/2020 22:02:07 INFO 139697286510400] Saved checkpoint to \"/tmp/tmpcOFLNf/mx-mod-0000.params\"\u001b[0m\n",
      "\u001b[34m[2020-01-29 22:02:07.323] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/test\", \"epoch\": 0, \"duration\": 4606, \"num_examples\": 1, \"num_bytes\": 72000}\u001b[0m\n",
      "\u001b[34m[2020-01-29 22:02:07.352] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/test\", \"epoch\": 1, \"duration\": 29, \"num_examples\": 2, \"num_bytes\": 106776}\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 2, \"sum\": 2.0, \"min\": 2}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 2, \"sum\": 2.0, \"min\": 2}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 1483, \"sum\": 1483.0, \"min\": 1483}, \"Total Batches Seen\": {\"count\": 1, \"max\": 2, \"sum\": 2.0, \"min\": 2}, \"Total Records Seen\": {\"count\": 1, \"max\": 1483, \"sum\": 1483.0, \"min\": 1483}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 1483, \"sum\": 1483.0, \"min\": 1483}, \"Reset Count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1580335327.382277, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"test_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\"}, \"StartTime\": 1580335327.322953}\n",
      "\u001b[0m\n",
      "\u001b[34m[01/29/2020 22:02:07 INFO 139697286510400] #test_score (algo-1) : ('weighted_softmax_loss_objective', 6.863527036886801)\u001b[0m\n",
      "\u001b[34m[01/29/2020 22:02:07 INFO 139697286510400] #test_score (algo-1) : ('multiclass_accuracy', 0.9824679703304113)\u001b[0m\n",
      "\u001b[34m[01/29/2020 22:02:07 INFO 139697286510400] #test_score (algo-1) : ('multiclass_top_k_accuracy_3', 0.99527983816588)\u001b[0m\n",
      "\u001b[34m[01/29/2020 22:02:07 INFO 139697286510400] #test_score (algo-1) : ('dcg', 0.9917896396793873)\u001b[0m\n",
      "\u001b[34m[01/29/2020 22:02:07 INFO 139697286510400] #test_score (algo-1) : ('macro_recall', 0.4)\u001b[0m\n",
      "\u001b[34m[01/29/2020 22:02:07 INFO 139697286510400] #test_score (algo-1) : ('macro_precision', nan)\u001b[0m\n",
      "\u001b[34m[01/29/2020 22:02:07 INFO 139697286510400] #test_score (algo-1) : ('macro_f_1.000', 0.25555557)\u001b[0m\n",
      "\u001b[34m[01/29/2020 22:02:07 INFO 139697286510400] #quality_metric: host=algo-1, test weighted_softmax_loss_objective <loss>=6.86352703689\u001b[0m\n",
      "\u001b[34m[01/29/2020 22:02:07 INFO 139697286510400] #quality_metric: host=algo-1, test multiclass_accuracy <score>=0.98246797033\u001b[0m\n",
      "\u001b[34m[01/29/2020 22:02:07 INFO 139697286510400] #quality_metric: host=algo-1, test multiclass_top_k_accuracy_3 <score>=0.995279838166\u001b[0m\n",
      "\u001b[34m[01/29/2020 22:02:07 INFO 139697286510400] #quality_metric: host=algo-1, test dcg <score>=0.991789639679\u001b[0m\n",
      "\u001b[34m[01/29/2020 22:02:07 INFO 139697286510400] #quality_metric: host=algo-1, test macro_recall <score>=0.40000000596\u001b[0m\n",
      "\u001b[34m[01/29/2020 22:02:07 INFO 139697286510400] #quality_metric: host=algo-1, test macro_precision <score>=nan\u001b[0m\n",
      "\u001b[34m[01/29/2020 22:02:07 INFO 139697286510400] #quality_metric: host=algo-1, test macro_f_1.000 <score>=0.255555570126\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"totaltime\": {\"count\": 1, \"max\": 4773.262023925781, \"sum\": 4773.262023925781, \"min\": 4773.262023925781}, \"finalize.time\": {\"count\": 1, \"max\": 142.67492294311523, \"sum\": 142.67492294311523, \"min\": 142.67492294311523}, \"initialize.time\": {\"count\": 1, \"max\": 199.61309432983398, \"sum\": 199.61309432983398, \"min\": 199.61309432983398}, \"check_early_stopping.time\": {\"count\": 12, \"max\": 1.1680126190185547, \"sum\": 6.798982620239258, \"min\": 0.20503997802734375}, \"setuptime\": {\"count\": 1, \"max\": 29.497861862182617, \"sum\": 29.497861862182617, \"min\": 29.497861862182617}, \"update.time\": {\"count\": 11, \"max\": 468.37401390075684, \"sum\": 4248.0151653289795, \"min\": 328.28712463378906}, \"epochs\": {\"count\": 1, \"max\": 15, \"sum\": 15.0, \"min\": 15}}, \"EndTime\": 1580335327.390468, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\"}, \"StartTime\": 1580335322.706095}\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2020-01-29 22:02:18 Uploading - Uploading generated training model\n",
      "2020-01-29 22:02:18 Completed - Training job completed\n",
      "Training seconds: 60\n",
      "Billable seconds: 60\n"
     ]
    }
   ],
   "source": [
    "balanced_multiclass_estimator.fit([train_records, val_records, test_records])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using already existing model: linear-learner-2020-01-29-21-58-49-477\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------------------------------------!"
     ]
    }
   ],
   "source": [
    "balanced_multiclass_predictor = balanced_multiclass_estimator.deploy(initial_instance_count=1, \n",
    "                                                                     instance_type='ml.m4.xlarge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.982\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "evaluate_metrics(balanced_multiclass_predictor, test_features, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ensure endpoints are deleted\n",
    "#multiclass_predictor.delete_endpoint()\n",
    "#balanced_multiclass_predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "#even when balancing the classes, that did not work that well\n",
    "#next will try and xgboost with a softmax function for multiclass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is our local data directory. We need to make sure that it exists.\n",
    "data_dir = '../data/SBMC'\n",
    "if not os.path.exists(data_dir):\n",
    "    os.makedirs(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use pandas to save our test, train and validation data to csv files. Note that we make sure not to include header\n",
    "# information or an index as this is required by the built in algorithms provided by Amazon. Also, for the train and\n",
    "# validation data, it is assumed that the first entry in each row is the target variable.\n",
    "\n",
    "X_test.to_csv(os.path.join(data_dir, 'test.csv'), header=False, index=False)\n",
    "\n",
    "pd.concat([Y_val, X_val], axis=1).to_csv(os.path.join(data_dir, 'validation.csv'), header=False, index=False)\n",
    "pd.concat([Y_train, X_train], axis=1).to_csv(os.path.join(data_dir, 'train.csv'), header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = 'SB_MC'\n",
    "\n",
    "test_location = session.upload_data(os.path.join(data_dir, 'test.csv'), key_prefix=prefix)\n",
    "val_location = session.upload_data(os.path.join(data_dir, 'validation.csv'), key_prefix=prefix)\n",
    "train_location = session.upload_data(os.path.join(data_dir, 'train.csv'), key_prefix=prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As stated above, we use this utility method to construct the image name for the training container.\n",
    "container = get_image_uri(session.boto_region_name, 'xgboost', '0.90-1')\n",
    "\n",
    "# Now that we know which container to use, we can construct the estimator object.\n",
    "xgb = sagemaker.estimator.Estimator(container, # The image name of the training container\n",
    "                                    role,      # The IAM role to use (our current role in this case)\n",
    "                                    train_instance_count=1, # The number of instances to use for training\n",
    "                                    train_instance_type='ml.p2.xlarge', # The type of instance to use for training\n",
    "                                    output_path='s3://{}/{}/output'.format(session.default_bucket(), prefix),\n",
    "                                                                        # Where to save the output (the model artifacts)\n",
    "                                    sagemaker_session=session) # The current SageMaker session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb.set_hyperparameters(max_depth=5,\n",
    "                        eta=0.2,\n",
    "                        gamma=4,\n",
    "                        min_child_weight=6,\n",
    "                        subsample=0.8,\n",
    "                        objective='multi:softmax',\n",
    "                        num_class = 4,\n",
    "                        early_stopping_rounds=10,\n",
    "                        num_round=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-01-30 03:59:37 Starting - Starting the training job...\n",
      "2020-01-30 03:59:38 Starting - Launching requested ML instances......\n",
      "2020-01-30 04:00:47 Starting - Preparing the instances for training......\n",
      "2020-01-30 04:02:00 Downloading - Downloading input data...\n",
      "2020-01-30 04:02:26 Training - Downloading the training image...\n",
      "2020-01-30 04:03:03 Uploading - Uploading generated training model\n",
      "2020-01-30 04:03:03 Failed - Training job failed\n",
      "\u001b[34mINFO:sagemaker-containers:Imported framework sagemaker_xgboost_container.training\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-containers:Failed to parse hyperparameter objective value multi:softmax to Json.\u001b[0m\n",
      "\u001b[34mReturning the value itself\u001b[0m\n",
      "\u001b[34mINFO:sagemaker_xgboost_container.training:Running XGBoost Sagemaker in algorithm mode\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[04:02:52] 6654x7 matrix with 46578 entries loaded from /opt/ml/input/data/train?format=csv&label_column=0&delimiter=,\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[04:02:52] 3278x7 matrix with 22946 entries loaded from /opt/ml/input/data/validation?format=csv&label_column=0&delimiter=,\u001b[0m\n",
      "\u001b[34mINFO:root:Single node training.\u001b[0m\n",
      "\u001b[34mINFO:root:Train matrix has 6654 rows\u001b[0m\n",
      "\u001b[34mINFO:root:Validation matrix has 3278 rows\u001b[0m\n",
      "\u001b[34mERROR:sagemaker-containers:Reporting training FAILURE\u001b[0m\n",
      "\u001b[34mERROR:sagemaker-containers:framework error: \u001b[0m\n",
      "\u001b[34mTraceback (most recent call last):\n",
      "  File \"/miniconda3/lib/python3.7/site-packages/sagemaker_xgboost_container/algorithm_mode/train.py\", line 192, in train_job\n",
      "    verbose_eval=False)\n",
      "  File \"/miniconda3/lib/python3.7/site-packages/xgboost/training.py\", line 216, in train\n",
      "    xgb_model=xgb_model, callbacks=callbacks)\n",
      "  File \"/miniconda3/lib/python3.7/site-packages/xgboost/training.py\", line 74, in _train_internal\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"/miniconda3/lib/python3.7/site-packages/xgboost/core.py\", line 1109, in update\n",
      "    dtrain.handle))\n",
      "  File \"/miniconda3/lib/python3.7/site-packages/xgboost/core.py\", line 176, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\u001b[0m\n",
      "\u001b[34mxgboost.core.XGBoostError: [04:02:53] /workspace/src/objective/multiclass_obj.cu:110: SoftmaxMultiClassObj: label must be in [0, num_class).\u001b[0m\n",
      "\u001b[34mStack trace:\n",
      "  [bt] (0) /miniconda3/xgboost/libxgboost.so(dmlc::LogMessageFatal::~LogMessageFatal()+0x24) [0x7f55885a4cb4]\n",
      "  [bt] (1) /miniconda3/xgboost/libxgboost.so(xgboost::obj::SoftmaxMultiClassObj::GetGradient(xgboost::HostDeviceVector<float> const&, xgboost::MetaInfo const&, int, xgboost::HostDeviceVector<xgboost::detail::GradientPairInternal<float> >*)+0xa26) [0x7f558879e846]\n",
      "  [bt] (2) /miniconda3/xgboost/libxgboost.so(xgboost::LearnerImpl::UpdateOneIter(int, xgboost::DMatrix*)+0x345) [0x7f558863e505]\n",
      "  [bt] (3) /miniconda3/xgboost/libxgboost.so(XGBoosterUpdateOneIter+0x35) [0x7f55885a1aa5]\n",
      "  [bt] (4) /miniconda3/lib/python3.7/lib-dynload/../../libffi.so.6(ffi_call_unix64+0x4c) [0x7f55b6f1eec0]\n",
      "  [bt] (5) /miniconda3/lib/python3.7/lib-dynload/../../libffi.so.6(ffi_call+0x22d) [0x7f55b6f1e87d]\n",
      "  [bt] (6) /miniconda3/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f55b739dede]\n",
      "  [bt] (7) /miniconda3/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12914) [0x7f55b739e914]\n",
      "  [bt] (8) /miniconda3/bin/python(_PyObject_FastCallKeywords+0x49b) [0x55b9177798fb]\n",
      "\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34mDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0m\n",
      "\u001b[34mTraceback (most recent call last):\n",
      "  File \"/miniconda3/lib/python3.7/site-packages/sagemaker_containers/_trainer.py\", line 81, in train\n",
      "    entrypoint()\n",
      "  File \"/miniconda3/lib/python3.7/site-packages/sagemaker_xgboost_container/training.py\", line 94, in main\n",
      "    train(framework.training_env())\n",
      "  File \"/miniconda3/lib/python3.7/site-packages/sagemaker_xgboost_container/training.py\", line 90, in train\n",
      "    run_algorithm_mode()\n",
      "  File \"/miniconda3/lib/python3.7/site-packages/sagemaker_xgboost_container/training.py\", line 68, in run_algorithm_mode\n",
      "    checkpoint_config=checkpoint_config\n",
      "  File \"/miniconda3/lib/python3.7/site-packages/sagemaker_xgboost_container/algorithm_mode/train.py\", line 135, in sagemaker_train\n",
      "    train_job(**train_args)\n",
      "  File \"/miniconda3/lib/python3.7/site-packages/sagemaker_xgboost_container/algorithm_mode/train.py\", line 196, in train_job\n",
      "    raise exc.UserError(str(e))\u001b[0m\n",
      "\u001b[34msagemaker_algorithm_toolkit.exceptions.UserError: [04:02:53] /workspace/src/objective/multiclass_obj.cu:110: SoftmaxMultiClassObj: label must be in [0, num_class).\u001b[0m\n",
      "\u001b[34mStack trace:\n",
      "  [bt] (0) /miniconda3/xgboost/libxgboost.so(dmlc::LogMessageFatal::~LogMessageFatal()+0x24) [0x7f55885a4cb4]\n",
      "  [bt] (1) /miniconda3/xgboost/libxgboost.so(xgboost::obj::SoftmaxMultiClassObj::GetGradient(xgboost::HostDeviceVector<float> const&, xgboost::MetaInfo const&, int, xgboost::HostDeviceVector<xgboost::detail::GradientPairInternal<float> >*)+0xa26) [0x7f558879e846]\n",
      "  [bt] (2) /miniconda3/xgboost/libxgboost.so(xgboost::LearnerImpl::UpdateOneIter(int, xgboost::DMatrix*)+0x345) [0x7f558863e505]\n",
      "  [bt] (3) /miniconda3/xgboost/libxgboost.so(XGBoosterUpdateOneIter+0x35) [0x7f55885a1aa5]\n",
      "  [bt] (4) /miniconda3/lib/python3.7/lib-dynload/../../libffi.so.6(ffi_call_unix64+0x4c) [0x7f55b6f1eec0]\n",
      "  [bt] (5) /miniconda3/lib/python3.7/lib-dynload/../../libffi.so.6(ffi_call+0x22d) [0x7f55b6f1e87d]\n",
      "  [bt] (6) /miniconda3/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f55b739dede]\n",
      "  [bt] (7) /miniconda3/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12914) [0x7f55b739e914]\n",
      "  [bt] (8) /miniconda3/bin/python(_PyObject_FastCallKeywords+0x49b) [0x55b9177798fb]\n",
      "\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34m[04:02:53] /workspace/src/objective/multiclass_obj.cu:110: SoftmaxMultiClassObj: label must be in [0, num_class).\u001b[0m\n",
      "\u001b[34mStack trace:\n",
      "  [bt] (0) /miniconda3/xgboost/libxgboost.so(dmlc::LogMessageFatal::~LogMessageFatal()+0x24) [0x7f55885a4cb4]\n",
      "  [bt] (1) /miniconda3/xgboost/libxgboost.so(xgboost::obj::SoftmaxMultiClassObj::GetGradient(xgboost::HostDeviceVector<float> const&, xgboost::MetaInfo const&, int, xgboost::HostDeviceVector<xgboost::detail::GradientPairInternal<float> >*)+0xa26) [0x7f558879e846]\n",
      "  [bt] (2) /miniconda3/xgboost/libxgboost.so(xgboost::LearnerImpl::UpdateOneIter(int, xgboost::DMatrix*)+0x345) [0x7f558863e505]\n",
      "  [bt] (3) /miniconda3/xgboost/libxgboost.so(XGBoosterUpdateOneIter+0x35) [0x7f55885a1aa5]\n",
      "  [bt] (4) /miniconda3/lib/python3.7/lib-dynload/../../libffi.so.6(ffi_call_unix64+0x4c) [0x7f55b6f1eec0]\n",
      "  [bt] (5) /miniconda3/lib/python3.7/lib-dynload/../../libffi.so.6(ffi_call+0x22d) [0x7f55b6f1e87d]\n",
      "  [bt] (6) /miniconda3/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f55b739dede]\n",
      "  [bt] (7) /miniconda3/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0x12914) [0x7f55b739e914]\n",
      "  [bt] (8) /miniconda3/bin/python(_PyObject_FastCallKeywords+0x49b) [0x55b9177798fb]\n",
      "\n",
      "\u001b[0m\n"
     ]
    },
    {
     "ename": "UnexpectedStatusException",
     "evalue": "Error for Training job sagemaker-xgboost-2020-01-30-03-59-37-431: Failed. Reason: AlgorithmError: framework error: \nTraceback (most recent call last):\n  File \"/miniconda3/lib/python3.7/site-packages/sagemaker_xgboost_container/algorithm_mode/train.py\", line 192, in train_job\n    verbose_eval=False)\n  File \"/miniconda3/lib/python3.7/site-packages/xgboost/training.py\", line 216, in train\n    xgb_model=xgb_model, callbacks=callbacks)\n  File \"/miniconda3/lib/python3.7/site-packages/xgboost/training.py\", line 74, in _train_internal\n    bst.update(dtrain, i, obj)\n  File \"/miniconda3/lib/python3.7/site-packages/xgboost/core.py\", line 1109, in update\n    dtrain.handle))\n  File \"/miniconda3/lib/python3.7/site-packages/xgboost/core.py\", line 176, in _check_call\n    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\nxgboost.core.XGBoostError: [04:02:53] /workspace/src/objective/multiclass_obj.cu:110: SoftmaxMultiClassObj: label must be in [0, num_class).\nStack trace:\n  [bt] (0) /miniconda3/xgboost/libxgboost.so(dmlc::LogMessageFatal::~LogMessageFatal()+0x24) [0x7f55885a4cb4]\n  [bt] (1) /miniconda3/xg",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnexpectedStatusException\u001b[0m                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-351-7dc3b33471ff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0ms3_input_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msagemaker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ms3_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms3_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontent_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0ms3_input_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'validation'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0ms3_input_validation\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/sagemaker/estimator.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, inputs, wait, logs, job_name, experiment_config)\u001b[0m\n\u001b[1;32m    462\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest_training_job\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    463\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 464\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest_training_job\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    465\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    466\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_compilation_job_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/sagemaker/estimator.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, logs)\u001b[0m\n\u001b[1;32m   1059\u001b[0m         \u001b[0;31m# If logs are requested, call logs_for_jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1060\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlogs\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"None\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1061\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogs_for_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1062\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1063\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_for_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/sagemaker/session.py\u001b[0m in \u001b[0;36mlogs_for_job\u001b[0;34m(self, job_name, wait, poll, log_type)\u001b[0m\n\u001b[1;32m   2972\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2973\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2974\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_job_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdescription\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"TrainingJobStatus\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2975\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdot\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2976\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/sagemaker/session.py\u001b[0m in \u001b[0;36m_check_job_status\u001b[0;34m(self, job, desc, status_key_name)\u001b[0m\n\u001b[1;32m   2566\u001b[0m                 ),\n\u001b[1;32m   2567\u001b[0m                 \u001b[0mallowed_statuses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Completed\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Stopped\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2568\u001b[0;31m                 \u001b[0mactual_status\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2569\u001b[0m             )\n\u001b[1;32m   2570\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnexpectedStatusException\u001b[0m: Error for Training job sagemaker-xgboost-2020-01-30-03-59-37-431: Failed. Reason: AlgorithmError: framework error: \nTraceback (most recent call last):\n  File \"/miniconda3/lib/python3.7/site-packages/sagemaker_xgboost_container/algorithm_mode/train.py\", line 192, in train_job\n    verbose_eval=False)\n  File \"/miniconda3/lib/python3.7/site-packages/xgboost/training.py\", line 216, in train\n    xgb_model=xgb_model, callbacks=callbacks)\n  File \"/miniconda3/lib/python3.7/site-packages/xgboost/training.py\", line 74, in _train_internal\n    bst.update(dtrain, i, obj)\n  File \"/miniconda3/lib/python3.7/site-packages/xgboost/core.py\", line 1109, in update\n    dtrain.handle))\n  File \"/miniconda3/lib/python3.7/site-packages/xgboost/core.py\", line 176, in _check_call\n    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\nxgboost.core.XGBoostError: [04:02:53] /workspace/src/objective/multiclass_obj.cu:110: SoftmaxMultiClassObj: label must be in [0, num_class).\nStack trace:\n  [bt] (0) /miniconda3/xgboost/libxgboost.so(dmlc::LogMessageFatal::~LogMessageFatal()+0x24) [0x7f55885a4cb4]\n  [bt] (1) /miniconda3/xg"
     ]
    }
   ],
   "source": [
    "# This is a wrapper around the location of our train and validation data, to make sure that SageMaker\n",
    "# knows our data is in csv format.\n",
    "s3_input_train = sagemaker.s3_input(s3_data=train_location, content_type='csv')\n",
    "s3_input_validation = sagemaker.s3_input(s3_data=val_location, content_type='csv')\n",
    "\n",
    "xgb.fit({'train': s3_input_train, 'validation': s3_input_validation})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_multiclassXGB_predictor = xgb.estimator.deploy(initial_instance_count=1, \n",
    "                                                                     instance_type='ml.m4.xlarge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_metrics(balanced_multiclassXGB_predictor, test_features, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_mxnet_p36",
   "language": "python",
   "name": "conda_mxnet_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
